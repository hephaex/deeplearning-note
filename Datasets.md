##  “BELEBELE”라는 122개 언어에 대한 읽기 이해 평가를 위한 데이터셋을 공개

다국어 모델의 텍스트 이해 능력을 평가하기 위한 벤치마크 테스트셋으로, 언어마다 동일한 데이터셋이 있어 모델의 성능을 모든 언어에 대해 직접적으로 비교 할 수 있습니다. 단일 언어는 물론, 다국어 및 교차 언어 모델까지 평가가 가능하다고 합니다.
더불어, 균형잡힌 다국어 데이터를 이용해 사전 훈련된 언어 모델이 더 많은 언어를 이해하는 데 있어 큰 영어 중심의 언어 모델을 능가한다는 것을 발견했다고 하네요.
그동안 언어 모델들에 대해 다국어 평가, 특히 한국어에 대한 평가를 정확히 할 수 있는 평가셋이 없어서 성능 비교가 어려웠는데요. MRC 뿐이긴 해도, 이제 이 데이터셋을 이용해 한국어 모델들의 성능을 조금은 더 객관적으로 살펴 볼 수 있을 것 같습니다.

- 논문: https://arxiv.org/pdf/2308.16884.pdf
- 코드: https://github.com/facebookresearch/belebele


## CVPR 2022 datasets
 - https://cvpr2022.thecvf.com/dataset-contributions
