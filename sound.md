## ë©”íƒ€ì˜ Next Level ìŒì„± to ìŒì„± ë²ˆì—­ ì‹œìŠ¤í…œ ë°œí‘œ
ìŒì„±ì—ì„œ ë°”ë¡œ ìŒì„±ìœ¼ë¡œ ë²ˆì—­í•˜ëŠ” ë²ˆì—­ ì‹œìŠ¤í…œì˜ í•œë‹¨ê³„ ì§„ë³´í•œ ê¸°ìˆ ì¸ Seamless ì‹œë¦¬ì¦ˆë¥¼ ë©”íƒ€ì—ì„œ ë°œí‘œí•˜ì˜€ìŠµë‹ˆë‹¤.
êµ¬ê¸€ Gemini ì˜ ë°œí‘œì— ë­í˜€ íšŒìê°€ ì˜ ì•ˆë˜ê³  ìˆì§€ë§Œ, ëŒ€ë‹¨í•œ ë°œì „ì„ ì´ë£¬ ê¸°ìˆ ì¸ë°ìš”.
ì‚¬ìš©ìì˜ ìŒì„± ìŠ¤íƒ€ì¼ë¡œ, ê°ì • í‘œí˜„ì˜ ëŠ¬ì•™ìŠ¤ê¹Œì§€ ë°˜ì˜í•´ì„œ ìŒì„±ìœ¼ë¡œ ë°”ë¡œ ë²ˆì—­ í•´ ì£¼ëŠ” SeamlessExpressive, ê·¸ë¦¬ê³   2ì´ˆ ì´ë‚´ì˜ ì¤€ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„± ë²ˆì—­ì„ í•´ ì£¼ëŠ” SeamlessStreaming ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.
ì²¨ë¶€ ì˜ìƒì€ ì˜ì–´ë¡œ ì†ì‚­ì´ë“¯ì´ ë§í•˜ëŠ” ê²ƒì„ ìŠ¤í˜ì¸ì–´ ìŒì„± ì¶œë ¥ìœ¼ë¡œ ë³€í™˜í•œ ì˜ˆ ì…ë‹ˆë‹¤.
ë²ˆì—­ì€ SeamlessM4Të¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ì…ë ¥ì–¸ì–´ëŠ” ì•½ 100ê°œ, ì¶œë ¥ ì–¸ì–´ëŠ” 36ê°œë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì„¸ê³„ì ì¸ ëŒ€ì„¸ ì–¸ì–´ë‹µê²Œ í•œêµ­ì–´ë„ ì§€ì›í•©ë‹ˆë‹¤. ğŸ¤— (í•œêµ­ì–´ê°€ ëŒ€ì„¸ë¼ë‹ˆ í•œê¸€ í…ìŠ¤íŠ¸ ì…ì¶œë ¥ë„ ì•ˆë˜ë˜ ì‹œëŒ€ê°€ ì–¼ë§ˆì „ì¸ ê²ƒ ê°™ì€ë° ê²©ì„¸ì§€ê°ì´ë„¤ìš”. ğŸ˜­)
ë©”íƒ€ ê³µì‹ ì‚¬ì´íŠ¸ ğŸ‘‰ https://ai.meta.com/research/seamless-communication/
ì „ì„¸ê³„ë¥¼ ì—°ê²°í•˜ëŠ” ë©”íƒ€ë‹µê²Œ ì˜¤ë˜ì „ë¶€í„° ë²ˆì—­ ê¸°ìˆ ì— ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì´ê³  ìˆëŠ”ë°ìš”. ê·¼ë° ì™œ ì•„ì§ë„ í˜ì´ìŠ¤ë¶ì´ë‚˜ ì¸ìŠ¤íƒ€, ìŠ¤ë ˆë“œì—ëŠ” ì œëŒ€ë¡œ ì§€ì›ì„ ì•ˆí•´ì£¼ê³  ìˆëŠ”ì§€.. ğŸ˜… ë¹¨ë¦¬ ë©”íƒ€ì˜ í”Œë«í¼ì— ì ìš©ë˜ì–´ ì–¸ì–´ì˜ ì¥ë²½ ì—†ì´ ì „ ì„¸ê³„ ì‚¬ëŒë“¤ê³¼ ì‰½ê²Œ êµë¥˜ í•  ë‚ ì´ ì™”ìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.

## í…ìŠ¤íŠ¸(Text-to-Audio)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¼ë°˜ ì˜¤ë””ì˜¤ë¥¼ í•©ì„±í•´ì„œ ë§Œë“¤ì–´ì£¼ëŠ” "AudioGen: Textually Guided Audio Generation"ë„ ë“±ì¥í–ˆë„¤ìš”. 
"ë‚¨ìê°€ í‚¤ë³´ë“œë¡œ íƒ€ì´í•‘í•˜ë©´ì„œ ë§í•˜ê³  ìˆë‹¤" ì´ë ‡ê²Œë§Œ ì…ë ¥í•˜ë©´ ì´ëŸ° ì†Œë¦¬ê°€ ë§Œë“¤ì–´ì§„ë‹¤ëŠ”ê²Œ ë†€ëë„¤ìš”. 
paper: https://felixkreuk.github.io/text2audio_arxiv.../paper.pdf
sample: https://felixkreuk.github.io/text2audio_arxiv_samples/

## í™”ì ë¶„ë¦¬ë¥¼ í•˜ëŠ” ê´€ë ¨ ì—°êµ¬
Speaker Recognition: https://paperswithcode.com/task/speaker-recognition
Speaker Verification: https://paperswithcode.com/task/speaker-verification, https://paperswithcode.com/.../text-independent-speaker..., https://paperswithcode.com/.../text-dependent-speaker...
Speaker Identification: https://paperswithcode.com/task/speaker-identification
Speaker Separation: https://paperswithcode.com/task/speaker-separation,
Speaker Profiling: https://paperswithcode.com/task/speaker-profiling

## ìŒì„±ì¸ì‹ colab ì‹¤ìŠµ ì½”ë“œ ê³µìœ 
colab link: https://bit.ly/3qYVQeC

## SMART-Single_Emotional_TTS: https://github.com/SMART-TTS/SMART-Single_Emotional_TTS
Variable-length style embeddingì„ ì¶”ì¶œí•˜ì—¬ ë°˜ì˜í•˜ëŠ” Unsupervised Style TTS ëª¨ë¸
SMART-Multi-Speaker-Style-TTS: https://github.com/SMART-TTS/SMART-Multi-Speaker-Style-TTS
VITS ëª¨ë¸ ê¸°ë°˜ì˜ Multi-Speaker Style TTS ëª¨ë¸
SMART-G2P: https://github.com/SMART-TTS/SMART-G2P
ì˜ì–´, í•œë¬¸ ë“±ì„ í¬í•¨í•œ í•œêµ­ì–´ ë¬¸ì¥ì„ ìœ„í•œ ë°œìŒì—´ ë³€í™˜ ëª¨ë¸
SMART-Vocoder: https://github.com/SMART-TTS/SMART-Vocoder
Variational inference í•™ìŠµ ê¸°ë²•ì„ ì´ìš©í•œ ë‹¤í™”ì ë³´ì½”ë”
SMART-Long_Sentence_TTS: https://github.com/SMART-TTS/SMART-Long_Sentence_TTS
Curriculum learningì„ í™œìš©í•œ document-level í•œêµ­ì–´ ìŒì„±í•©ì„± ëª¨ë¸
SMART-NAR_Fast_TTS: https://github.com/SMART-TTS/SMART-NAR_Fast_TTS
FastSpeech ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ alignmentë¥¼ external duration label ì—†ì´ í•™ìŠµí•˜ëŠ” í•œêµ­ì–´ ìŒì„±í•©ì„± ëª¨ë¸
