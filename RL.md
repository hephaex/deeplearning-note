## RL (reinforce learning)
* dream cv2 https://github.com/danijar/dreamerv2

## Evidence of a predictive coding hierarchy in the human brain listening to speech 
https://www.nature.com/articles/s41562-022-01516-2
이 논문에 의하면 인간 뇌가 언어를 생성하는 방식과 트랜스포머 모델이 언어를 생성하는 방식이 큰 틀에선 비슷하지만 구체적으로는 다르다는 것이다.
인간의 뇌는 언어를 생성할 때 단순히 바로 다음에 올 단어를 순차적으로 예측하는 게 아니라 멀찍이는 좀 더 추상적인 의미론적인 개념을 예측하고 가까이는 개별 단어를 예측하는 식으로 계층적인 예측을 하는 식으로 작동한다는 것이다.

## VPT 
Blog: https://openai.com/blog/vpt/
Paper: https://arxiv.org/abs/2206.11795
Code & Model weights: https://github.com/openai/Video-Pre-T...

## Accelerating physics simulators for Robotics Reinforcement Learning - Erwin Coumans @ ICRA22 | 2/8
PyBullet을 만드신 분으로도 유명한 Erwin Coumans님의 ICRA 22 Tutorial
강화학습을 로봇에 적용할 때 가장 많이 고민하는 시뮬레이터에 관한 좋은 발표입니다. 
Website : https://araffin.github.io/tools-for-robotic-rl-icra2022/
Slides : https://drive.google.com/.../19ImRxp8SfbTLtMDdFwYY.../view
Youtube : https://youtu.be/WOwLquiFbPE## Interested in multiple object tracking and segmentation and self-driving?

## Connectomic comparison of mouse and human cortex

The analysis of the human brain is a central goal of neuroscience. However, for methodological reasons, research has largely focused on model organisms, in particular the mouse. Now, neuroscientists gained novel insights on human neural circuitry using tissue obtained from neurosurgical interventions. Three-dimensional electron microscope data revealed a novel expanded network of interneurons in humans compared to mouse. The discovery of this prominent network component in the human cortex encourages further detailed analysis of its function in health and disease.

http://sciencemission.com/site/index.php?page=news&type=view&id=technology%2Fconnectomic-comparison&filter=8%2C9%2C10%2C11%2C12%2C13%2C14%2C16%2C17%2C18%2C19%2C20%2C27
## I-cloth
https://min-tang.github.io/home/ICloth/

## dreamerv2

https://github.com/danijar/dreamerv2

카카오 팀에서 내부적으로 사용하던 강화학습 프레임워크를 JORLDY라는 이름의 오픈소스 강화학습 프레임워크로 공개하게 되었습니다!! 저희 JORLDY는 다음과 같은 특징들을 가지고 있습니다!
- 약 20개 이상의 강화학습 알고리즘을 제공하며 여러 강화학습 환경들의 사용을 지원
- 간단한 명령어를 통해 원하는 알고리즘과 환경을 연결하여 사용할 수 있음
- 알고리즘과 환경에 대한 추가 및 변경이 가능
- Ray를 이용한 분산강화학습 알고리즘 제공
- 구현한 알고리즘과 환경에 대한 성능 벤치마크 제공
JORLDY의 깃허브 링크는 다음과 같습니다. 
https://github.com/kakaoenterprise/JORLDY


## Deepmind에서 새로운 강화학습 적용 사례를 발표했습니다!
MuZero 알고리즘을 사용하여 유튜브의 비디오 압축 성능을 향상시킨 논문
* 블로그: https://deepmind.com/.../MuZeros-first-step-from-research...
* 논문: https://storage.googleapis.com/.../MuZero%20with%20self...
