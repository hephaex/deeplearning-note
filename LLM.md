## MS, íŠ¸ëœìŠ¤í¬ë¨¸ ì„±ëŠ¥ ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ LLM ì•„í‚¤í…ì²˜, Diff Transformer ê³µê°œ
'íŠ¸ëœìŠ¤í¬ë¨¸' ê¸°ë°˜ ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM)ì˜ ê¸´ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ê°€ ë‚˜ì™”ë‹¤. 
ë²¤ì²˜ë¹„íŠ¸ëŠ” 16ì¼(í˜„ì§€ì‹œê°„) ë§ˆì´í¬ë¡œì†Œí”„íŠ¸(MS)ì™€ ì¹­í™”ëŒ€í•™êµ ì—°êµ¬ì§„ì´ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì–´í…ì…˜(attention)ì„ ì¦í­í•˜ê³  ë…¸ì´ì¦ˆë¥¼ ê±¸ëŸ¬ë‚´ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ â€˜ì°¨ë“± íŠ¸ëœìŠ¤í¬ë¨¸(Diff Transformer)â€™ì— ê´€í•œ ë…¼ë¬¸ì„ ì•„ì¹´ì´ë¸Œì— ê²Œì¬í–ˆë‹¤ê³  ë³´ë„í–ˆë‹¤.
íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ëŠ” ëŒ€ë¶€ë¶„ LLMì˜ ê¸°ë°˜ì´ë‹¤. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•´ ì…ë ¥ í…ìŠ¤íŠ¸ ë‚´ í† í°ì´ ì¶œë ¥ ìƒì„±ì— ë¯¸ì¹˜ëŠ” ì¤‘ìš”ë„ë¥¼ í‰ê°€í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ ë²¡í„° ê°’ì„ í™•ë¥  ë¶„í¬ë¡œ ì •ê·œí™”í•˜ëŠ” 'ì†Œí”„íŠ¸ë§¥ìŠ¤(softmax)' í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ í† í°ì— ì–´í…ì…˜ ì ìˆ˜ë¥¼ í• ë‹¹í•œë‹¤.

## ì—”ë¹„ë””ì•„, ì˜¤í”ˆAIÂ·ì•¤íŠ¸ë¡œí”½ ëŠ¥ê°€í•˜ëŠ” LLM ê³µê°œ, Llama-3.1-Nemotron-70B-Instruct, ëª¨ë¸ ì¤‘ì‹¬ ìƒíƒœê³„ êµ¬ì¶•í•˜ë‚˜
ì´ë‹¬ ì´ˆ ëŒ€í˜•ë©€í‹°ëª¨ë‹¬ëª¨ë¸(LMM)ì„ ê³µê°œí•˜ë©° ì˜¤í”ˆAI ë“±ê³¼ ëª¨ë¸ ê²½ìŸì„ ì„ ì–¸í•œ ì—”ë¹„ë””ì•„ê°€ ì´ë²ˆì—ëŠ” ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM)ì„ ë‚´ë†“ì•˜ë‹¤. ì´ë²ˆì—ëŠ” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì˜¤í”ˆAIì˜ 'GPT-4o'ì™€ ì•¤íŠ¸ë¡œí”½ì˜ 'í´ë¡œë“œ 3.5 ì†Œë„¤íŠ¸'ë¥¼ ì œì¹˜ê³  ìµœê³  ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆë‹¤ê³  ë°í˜”ë‹¤.
ë²¤ì²˜ë¹„íŠ¸ëŠ” 16ì¼ ì—”ë¹„ë””ì•„ê°€ ë³„ í™ë³´ ì—†ì´ í—ˆê¹…í˜ì´ìŠ¤ë¥¼ í†µí•´ 'Llama-3.1-Nemotron-70B-Instruct'ë¥¼ ì¶œì‹œí–ˆë‹¤ê³  ë³´ë„í–ˆë‹¤. ì´ ëª¨ë¸ì€ ì—”ë¹„ë””ì•„ ì „ìš© í”Œë«í¼ì—ì„œ ë¬´ë£Œë¡œ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆë‹¤.
ì—”ë¹„ë””ì•„ëŠ” ëª¨ë¸ ê°œë°œì— ì¸ê°„ í”¼ë“œë°±ì„ í†µí•œ ê°•í™” í•™ìŠµ(RLHF)ê³¼ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì„ ì‚¬ìš©, ë¼ë§ˆ 3.1ì„ ë¯¸ì„¸ì¡°ì •í–ˆë‹¤ê³  ë°í˜”ë‹¤.
ì¶”ê°€ í”„ë¡¬í”„íŠ¸ë‚˜ íŠ¹ìˆ˜ í† í° ì—†ì´ ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ë„ ê°•ì¡°í–ˆë‹¤. ì„ ë³´ì¸ ë°ëª¨ì—ì„œëŠ” 'strawberryì—ëŠ” rì´ ëª‡ê°œ ìˆë‚˜ìš”'ë¼ëŠ” ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí–ˆë‹¤.
íŠ¹íˆ ì¸ê°„ ì„ í˜¸ë„ í‰ê°€ì¸ 'ì•„ë ˆë‚˜ í•˜ë“œë²¤ì¹˜'ì—ì„œ 85.0ì„ ê¸°ë¡í–ˆìœ¼ë©°, 'ì•ŒíŒŒì¹´ì´ë²¨ 2 LC(AlpacaEval 2 LC)'ì—ì„œ 57.6, 'GPT-4- í„°ë³´ MT-ë²¤ì¹˜'ì—ì„œ 8.98 ë“± ì£¼ìš” í‰ê°€ì—ì„œ ì˜¤í”ˆAIì˜ GPT-4oì™€ ì•¤íŠ¸ë¡œí”½ì˜ í´ë¡œë“œ 3.5 ì†Œë„¤íŠ¸ë¥¼ ì œì¹˜ê³  ìµœê³  ì ìˆ˜ë¥¼ ê¸°ë¡í–ˆë‹¤.
ì´ëŒ€ë¡œë¼ë©´ í˜„ì¡´ ìµœê°•ì˜ ì„±ëŠ¥ì„ ê°–ì¶˜ ëª¨ë¸ì´ë¼ëŠ” ë§ì´ë‹¤.
ì´ì— ì•ì„œ ì§€ë‚œ 1ì¼ì—ëŠ” 'NVLM-D-72B'ì´ë¼ëŠ” ì—”ë¹„ë””ì•„ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LMMì´ í™”ì œê°€ ëë‹¤. ì´ ëª¨ë¸ ì—­ì‹œ ëŒ€ë¶€ë¶„ ë²¤ì¹˜ë§ˆí¬ì—ì„œ GPT-4oë‚˜ í´ë¡œë“œ 3.5 ì†Œë„¤íŠ¸, 'ì œë¯¸ë‚˜ì´ 1.5 í”„ë¡œ', 'ë¼ë§ˆ 3-V 405B' ë“±ê³¼ ëŒ€ë“±í•˜ê±°ë‚˜ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì¸ ë°” ìˆë‹¤.
ì´ ë•Œë¬¸ì— ì—”ë¹„ë””ì•„ê°€ ë³¸ê²©ì ìœ¼ë¡œ í”„ë¡ í‹°ì–´ ëª¨ë¸ ê²½ìŸì— ë›°ì–´ë“œëŠ” ê²ƒì´ ì•„ë‹ˆëƒëŠ” ì¶”ì¸¡ë„ ë‚˜ì™”ë‹¤. ë¬¼ë¡  ì´ë²ˆì— ì¶œì‹œí•œ ëª¨ë¸ì€ ìì²´ ê°œë°œì´ ì•„ë‹ˆë¼, ë¼ë§ˆ 3.1ì„ ë² ì´ìŠ¤ë¡œ ì„±ëŠ¥ì„ ê°œì„ í•œ ëª¨ë¸ì´ë‹¤.
í•˜ì§€ë§Œ ì—”ë¹„ë””ì•„ì˜ ì¸í”„ë¼ì— ìµœì í™”ëœ ëª¨ë¸ì„ ë¬´ë£Œë¡œ ì œê³µí•˜ë©´, ì´ëŠ” CUDAë¥¼ í†µí•´ ìƒíƒœê³„ë¥¼ êµ¬ì¶•í•œ ê²ƒê³¼ ë¹„ìŠ·í•œ íš¨ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ë¶„ì„ì´ë‹¤. íŠ¹íˆ, ì—”ë¹„ë””ì•„ëŠ” ì„±ëŠ¥ê³¼ í•¨ê»˜ ë¹„ìš© íš¨ìœ¨ì ì¸ ë©´ë„ ê°•ì¡°í•˜ê³  ìˆë‹¤.
https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF


## CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos
https://go.fb.me/xiyc63
Demo on Hugging Face â¡ï¸ https://go.fb.me/yzuqd0

Building on the popular release of CoTracker, we're introducing CoTracker3, which includes a new tracking model and a new semi-supervised training recipe. Available in online and offline variants, the new model demonstrates impressive tracking results where points can be tracked for extended durations even when they are occluded or leave the field of view. CoTracker3 achieves state-of-the-art and outperforms all recent point tracking approaches on standard benchmarks â€” often by a substantial margin.
We've released the research paper, code and a demo on Hugging Face â€” along with models available under an A-NC license to support further research in this space.

## EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation

ì´ˆë¡
í˜„ì¬ì˜ ìë™ íšŒê·€ ë©”ì‹œ ìƒì„± ë°©ë²•ì€ ë¶ˆì™„ì „ì„±, ë¶ˆì¶©ë¶„í•œ ë””í…Œì¼, ë‚®ì€ ì¼ë°˜í™”ìœ¨ ë“±ì˜ ë¬¸ì œë¥¼ ì•ˆê³  ìˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” 512ì˜ ê³µê°„ í•´ìƒë„ì—ì„œ ìµœëŒ€ 4,000ê°œì˜ ë©´ì„ ê°€ì§„ ê³ í’ˆì§ˆ 3D ë©”ì‹œë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ìë™ íšŒê·€ ìë™ ì¸ì½”ë”(ArAE) ëª¨ë¸ì„ ì œì•ˆí•©ë‹ˆë‹¤. 

ìƒˆë¡œìš´ ë©”ì‹œ í† í°í™” ì•Œê³ ë¦¬ì¦˜ì„ ë„ì…í•˜ì—¬ ì‚¼ê°í˜• ë©”ì‹œë¥¼ 1D í† í° ì‹œí€€ìŠ¤ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ í›ˆë ¨ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë˜í•œ, ê°€ë³€ ê¸¸ì´ì˜ ì‚¼ê°í˜• ë©”ì‹œë¥¼ ê³ ì • ê¸¸ì´ì˜ ì ì¬ ê³µê°„ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì ì¬ í™•ì‚° ëª¨ë¸ì„ í›ˆë ¨í•¨ìœ¼ë¡œì¨ ì¼ë°˜í™”ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë° ì´ë¯¸ì§€ ì¡°ê±´ë¶€ ë©”ì‹œ ìƒì„± ì‘ì—… ëª¨ë‘ì—ì„œ ëª¨ë¸ì˜ ìš°ìˆ˜í•œ í’ˆì§ˆ, ë‹¤ì–‘ì„± ë° ì¼ë°˜í™” ê¸°ëŠ¥ì„ ì…ì¦í–ˆìŠµë‹ˆë‹¤.

í”„ë¡œì íŠ¸ https://research.nvidia.com/labs/dir/edgerunner/
ë…¼ë¬¸ https://arxiv.org/pdf/2409.18114

## OpenAI ìŒì„±ì¸ì‹ ì˜¤í”„ì†ŒìŠ¤ Whisper V3 Turbo ê³µê°œ.
Whisper Largeë³´ë‹¤ 8ë°°, Whisper Mediumë³´ë‹¤ 4ë°°, Whisper Small ëª¨ë¸ë³´ë‹¤ 2ë°° ë¹ ë¥¸ ì†ë„. ì†ë„ê°€ ë¹ ë¥´ë©´ì„œë„ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë˜ì§€ ì•ŠìŒ.
Whisper V3 TurboëŠ” 809Mì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ì¶”ê³  ìˆìœ¼ë©°, ë‹¤êµ­ì–´ ì§€ì›(í•œêµ­ì–´ í¬í•¨ 99ê°œ ì–¸ì–´).
https://huggingface.co/openai/whisper-large-v3-turbo
WhisperëŠ” ìë™ ìŒì„± ì¸ì‹(ASR) ë° ìŒì„± ë²ˆì—­ì„ ìœ„í•œ ìµœì²¨ë‹¨ ëª¨ë¸ë¡œ, OpenAIì˜ Alec Radford ë“±ì´ ì‘ì„±í•œ ë…¼ë¬¸ 'ëŒ€ê·œëª¨ ì•½í•œ ê°ë…ì„ í†µí•œ ê°•ë ¥í•œ ìŒì„± ì¸ì‹'ì—ì„œ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤. 5ë°±ë§Œ ì‹œê°„ ì´ìƒì˜ ë ˆì´ë¸”ì´ ì§€ì •ëœ ë°ì´í„°ë¡œ í•™ìŠµëœ WhisperëŠ” ì œë¡œ ìƒ· í™˜ê²½ì—ì„œ ë§ì€ ë°ì´í„° ì„¸íŠ¸ì™€ ë„ë©”ì¸ì— ì¼ë°˜í™”í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
Whisper large-v3-turboëŠ” ê¸°ì¡´ Whisper large-v3ì˜ ë¯¸ì„¸ ì¡°ì • ë²„ì „ì…ë‹ˆë‹¤. ì¦‰, ë””ì½”ë”© ë ˆì´ì–´ ìˆ˜ê°€ 32ê°œì—ì„œ 4ê°œë¡œ ì¤„ì–´ë“  ê²ƒì„ ì œì™¸í•˜ë©´ ì™„ì „íˆ ë™ì¼í•œ ëª¨ë¸ì…ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì´ ëª¨ë¸ì€ ì•½ê°„ì˜ í’ˆì§ˆ ì €í•˜ë¥¼ ê°ìˆ˜í•˜ê³ ë„ í›¨ì”¬ ë” ë¹¨ë¼ì¡ŒìŠµë‹ˆë‹¤.

## "Training Language Models to Self-Correct via Reinforcement Learning"
ì´ ë…¼ë¬¸ì€ LLMì´ ê°•í™” í•™ìŠµì„ ê¸°ë°˜ìœ¼ë¡œ ì™¸ë¶€ í”¼ë“œë°±ì—†ì´ ìì²´ì ìœ¼ë¡œ ì˜¤ë¥˜ë¥¼ ì¸ì‹í•˜ê³  ìˆ˜ì •í•˜ë©° í•™ìŠµí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

ğŸ”§ ì‚¬ìš© ëª¨ë¸: google/gemma-2-2B-it

ğŸ“Š ë°ì´í„°ì…‹: ì—°êµ¬ ëª©ì ì— ë§ì¶° ì§ì ‘ ì„¤ê³„ ë° ì œì‘

ì´ êµ¬í˜„ì„ í†µí•´ ê°•í™”í•™ìŠµì„ í™œìš©í•œ ì–¸ì–´ ëª¨ë¸ì˜ ìê¸° êµì • ëŠ¥ë ¥ í–¥ìƒ ê°€ëŠ¥ì„±ì„ ëŠê»´ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. runpodì—ì„œ ê°„ë‹¨í•˜ê²Œ í•™ìŠµí•´ë³´ì‹¤ ìˆ˜ ìˆë„ë¡ ì½”ë“œë‘ ë°ì´í„° ëª¨ë‘ ê³µê°œí•´ ë†“ì•˜ìŠµë‹ˆë‹¤.
ê¹ƒí—ˆë¸Œ ë§í¬ : [https://github.com/daje0601/Google_SCoRe](https://github.com/daje0601/Google_SCoRe)

# OpenAI Strawberry(o1) 

OpenAI Docs
- [https://platform.openai.com/docs/guides/reasoning](https://platform.openai.com/docs/guides/reasoning)
- <img src="https://github.com/user-attachments/assets/b165cb20-9202-4951-8783-6b2f7e0d6071" width="600px"> 

## Blogs
- [OpenAI] [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/)
- [OpenAI] [OpenAI o1-mini Advancing cost-efficient reasoning](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning)
- [OpenAI] [Finding GPT-4â€™s mistakes with GPT-4](https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/)
- [Tibor Blaho] [Summary of what we have learned during AMA hour with the OpenAI o1 team](https://twitter-thread.com/t/1834686946846597281)
- [Nathan Lambert] [OpenAIâ€™s Strawberry, LM self-talk, inference scaling laws, and spending more on inference](https://www.interconnects.ai/p/openai-strawberry-and-inference-scaling-laws)
- [Nathan Lambert] [Reverse engineering OpenAIâ€™s o1](https://www.interconnects.ai/p/reverse-engineering-openai-o1)

## Twitter
- [OpenAI Developers](https://x.com/OpenAIDevs/status/1834608585151594537)
- <img src="https://github.com/user-attachments/assets/4670514c-e6fa-474f-abea-c3f6ad01e41a" width="300px">
- <img src="https://github.com/user-attachments/assets/b390ccea-9773-4a96-ba02-40d917473402" width="300px">
- <img src="https://github.com/user-attachments/assets/88896f70-017d-4520-ac56-370a023cfe45" width="300px">
- <img src="https://github.com/user-attachments/assets/fbbf78e4-d34c-4b7b-8163-f8c7288f56a6" width="300px">
- <img src="https://github.com/user-attachments/assets/cb1cc1e6-35d4-4567-891a-4e5aca8fa175" width="300px">
- <img src="https://github.com/user-attachments/assets/d3fd109b-0c97-4a94-931e-919b3b2f75f4" width="300px">

### Relevant Paper from OpenAI o1 [contributors](https://openai.com/openai-o1-contributions/)
```
format:
- [title](paper link) [links]
  - author1, author2, and author3...
  - publisher
  - code
  - experimental environments and datasets
```

- [Training Verifiers to Solve Math Word Problems](https://arxiv.org/abs/2110.14168)
  - Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman
- [Generative Language Modeling for Automated Theorem Proving](https://arxiv.org/abs/2009.03393)
  - Stanislas Polu, Ilya Sutskever
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)
  - Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou
- [Let's Verify Step by Step](https://arxiv.org/abs/2305.20050)
  - Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, Karl Cobbe
- [LLM Critics Help Catch LLM Bugs](https://arxiv.org/abs/2407.00215)
  - Nat McAleese, Rai Michael Pokorny, Juan Felipe Ceron Uribe, Evgenia Nitishinskaya, Maja Trebacz, Jan Leike
- [Self-critiquing models for assisting human evaluators](https://arxiv.org/pdf/2206.05802) 
  - William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, Jan Leike
- [Scalable Online Planning via Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2109.15316)
  - Arnaud Fickinger, Hengyuan Hu, Brandon Amos, Stuart Russell, Noam Brown.

### 2024 : Relevant Paper from OpenAI o1
- [Planning In Natural Language Improves LLM Search For Code Generation](https://arxiv.org/abs/2409.03733)
  - Evan Wang, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, Hugh Zhang
- [An Empirical Analysis of Compute-OptimaInference for Problem-Solving with LanguageModels](https://arxiv.org/abs/2408.00724)
  - Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang
- [Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling](https://www.arxiv.org/abs/2408.16737)
  - Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, Mehran Kazemi
- [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314)
  - Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar
- [Generative Verifiers: Reward Modeling as Next-Token Prediction](https://arxiv.org/abs/2408.15240)
  - Lunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar, Rishabh Agarwal
- [Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers](https://arxiv.org/abs/2408.06195)
  - Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, Fan Yang, Mao Yang
- [Large Language Monkeys: Scaling Inference Compute with Repeated Sampling](https://arxiv.org/abs/2407.21787)
  - Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher RÃ©, Azalia Mirhoseini
- [Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning](https://arxiv.org/abs/2406.14283)
  - Chaojie Wang, Yanchen Deng, Zhiyi Lyu, Liang Zeng, Jujie He, Shuicheng Yan, Bo An
- [Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B](https://arxiv.org/abs/2406.07394)
  - Di Zhang, Xiaoshui Huang, Dongzhan Zhou, Yuqiang Li, Wanli Ouyang
- [Self-Rewarding Language Models](https://arxiv.org/abs/2401.10020)
  - Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Xian Li, Sainbayar Sukhbaatar, Jing Xu, Jason Weston
- [Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models](https://arxiv.org/abs/2402.03271)
  - Zhiyuan Hu, Chumin Liu, Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan Luu, Junxian He, Pang Wei Koh, Bryan Hooi
- [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/abs/2403.09629)
  - Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, Noah D. Goodman
  - https://github.com/ezelikman/quiet-star
- [Advancing LLM Reasoning Generalists with Preference Trees](https://arxiv.org/abs/2404.02078)
  - Lifan Yuan, Ganqu Cui, Hanbin Wang, Ning Ding, Xingyao Wang, Jia Deng, Boji Shan et al.
- [Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing](https://arxiv.org/abs/2404.12253)
  - Ye Tian, Baolin Peng, Linfeng Song, Lifeng Jin, Dian Yu, Haitao Mi, and Dong Yu.
- [AlphaMath Almost Zero: Process Supervision Without Process](https://arxiv.org/abs/2405.03553)
  - Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan.
- [ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search](https://arxiv.org/abs/2406.03816)
  - Dan Zhang, Sining Zhoubian, Yisong Yue, Yuxiao Dong, and Jie Tang.
- [Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning](https://arxiv.org/abs/2405.00451)
  - Yuxi Xie, Anirudh Goyal, Wenyue Zheng, Min-Yen Kan, Timothy P. Lillicrap, Kenji Kawaguchi, Michael Shieh.
- [Chain of Thought Empowers Transformers to Solve Inherently Serial Problems](https://arxiv.org/abs/2402.12875)
  - Zhiyuan Li, Hong Liu, Denny Zhou, Tengyu Ma.
- [ReFT: Reasoning with Reinforced Fine-Tuning](https://arxiv.org/abs/2401.08967)
  - Trung Quoc Luong, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, Hang Li
- [Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/pdf/2402.10200)
  - Xuezhi Wang, Denny Zhou
 
### 2023 : Relevant Paper from OpenAI o1
- [Training Chain-of-Thought via Latent-Variable Inference](https://arxiv.org/pdf/2312.02179)
  - Du Phan, Matthew D. Hoffman, David Dohan, Sholto Douglas, Tuan Anh Le, Aaron Parisi, Pavel Sountsov, Charles Sutton, Sharad Vikram, Rif A. Saurous
- [Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training](https://arxiv.org/abs/2309.17179)
  - Xidong Feng, Ziyu Wan, Muning Wen, Stephen Marcus McAleer, Ying Wen, Weinan Zhang, Jun Wang
- [Reasoning with Language Model is Planning with World Model](https://arxiv.org/abs/2305.14992)
  - Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu
- [Donâ€™t throw away your value model! Generating more preferable text with Value-Guided Monte-Carlo Tree Search decoding](https://arxiv.org/abs/2309.15028)
  - Liu, Jiacheng, Andrew Cohen, Ramakanth Pasunuru, Yejin Choi, Hannaneh Hajishirzi, and Asli Celikyilmaz.
- [Certified reasoning with language models](https://arxiv.org/pdf/2306.04031)
  - Gabriel Poesia, Kanishk Gandhi, Eric Zelikman, Noah D. Goodman     

### 2022 : Relevant Paper from OpenAI o1 
- [Chain of Thought Imitation with Procedure Cloning](https://arxiv.org/abs/2205.10816)
  - Mengjiao Yang, Dale Schuurmans, Pieter Abbeel, Ofir Nachum.
- [STaR: Bootstrapping Reasoning With Reasoning](https://arxiv.org/abs/2203.14465)
  - Eric Zelikman, Yuhuai Wu, Jesse Mu, Noah D. Goodman
    
### 2021 : Relevant Paper from OpenAI o1
- [Scaling Scaling Laws with Board Games](http://arxiv.org/abs/2104.03113)
  - Andy L. Jones.
- [Show Your Work: Scratchpads for Intermediate Computation with Language Models](https://arxiv.org/pdf/2112.00114)
  - Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, Augustus Odena
 
### 2017 : Relevant Paper from OpenAI o1
- [Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm](https://arxiv.org/abs/1712.01815v1)
  - David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis. 

### Evaluation of OpenAI o1
- [AryanDLuffy] [codeforces](https://codeforces.com/blog/entry/133962)

## LLM Evaluation / Benchmark
- [evals](https://github.com/openai/evals) (`OpenAI`) ![](https://img.shields.io/github/stars/openai/evals.svg?style=social) Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.

## LLM Training / Finetuning
- [xtuner](https://github.com/InternLM/xtuner) (`InternLM`) ![](https://img.shields.io/github/stars/InternLM/xtuner.svg?style=social) An efficient, flexible and full-featured toolkit for fine-tuning LLM (InternLM2, Llama3, Phi3, Qwen, Mistral, ...)

- [litGPT](https://github.com/Lightning-AI/litgpt) (`LightningAI`) ![](https://img.shields.io/github/stars/Lightning-AI/litgpt.svg?style=social) 20+ high-performance LLMs with recipes to pretrain, finetune and deploy at scale.

- [Megatron-LM](https://github.com/NVIDIA/Megatron-LM) (`NVIDIA`) ![](https://img.shields.io/github/stars/NVIDIA/Megatron-LM.svg?style=social) Ongoing research training transformer models at scale

- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) ![](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory.svg?style=social) A WebUI for Efficient Fine-Tuning of 100+ LLMs (ACL 2024)

- [nanoGPT](https://github.com/karpathy/nanoGPT) (`karpathy`) ![](https://img.shields.io/github/stars/karpathy/nanoGPT.svg?style=social) The simplest, fastest repository for training/finetuning medium-sized GPTs.
 
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) ![](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory.svg?style=social) A WebUI for Efficient Fine-Tuning of 100+ LLMs (ACL 2024)

- [evals](https://github.com/openai/evals) (`OpenAI`) ![](https://img.shields.io/github/stars/openai/evals.svg?style=social) Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.
  
- [nanotron](https://github.com/huggingface/nanotron) (`HuggingFace`) ![](https://img.shields.io/github/stars/huggingface/nanotron.svg?style=social) Minimalistic large language model 3D-parallelism training

## LLM Data Preprocessing
- [NeMo-Curator](https://github.com/NVIDIA/NeMo-Curator) (`NVIDIA`) ![](https://img.shields.io/github/stars/NVIDIA/NeMo-Curator.svg?style=social) Scalable toolkit for data curation

- [data-juicer](https://github.com/modelscope/data-juicer) (`ModelScope`) ![](https://img.shields.io/github/stars/modelscope/data-juicer.svg?style=social) A one-stop data processing system to make data higher-quality, juicier, and more digestible for (multimodal) LLMs!

- [datatrove](https://github.com/huggingface/datatrove) (`HuggingFace`) ![](https://img.shields.io/github/stars/huggingface/datatrove.svg?style=social) Freeing data processing from scripting madness by providing a set of platform-agnostic customizable pipeline processing blocks.

- [dataverse](https://github.com/UpstageAI/dataverse) (`Upstage`) ![](https://img.shields.io/github/stars/UpstageAI/dataverse.svg?style=social) The Universe of Data. All about data, data science, and data engineering

- [NeMo-Curator](https://github.com/NVIDIA/NeMo-Curator) (`NVIDIA`) ![](https://img.shields.io/github/stars/NVIDIA/NeMo-Curator.svg?style=social) Scalable toolkit for data curation

- [dps](https://github.com/EleutherAI/dps) (`EleutherAI`)![](https://img.shields.io/github/stars/EleutherAI/dps.svg?style=social) Data processing system for polyglot

## ì„œìš¸ê³¼ê¸°ëŒ€ MLP ì—°êµ¬ì‹¤ì—ì„œ Bllossom-405B previewë¥¼ ê³µê°œ
1. ì‚¬ì „í•™ìŠµì— ëŒ€í•œ ì˜í–¥ì´ ë¯¸ë¯¸í•¨: ì›Œë‚™ í° ëª¨ë¸ì´ë¼ ì•½ê°„ì˜ ì¶”ê°€ ì‚¬ì „í•™ìŠµì„ ì§„í–‰í•˜ë©´ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ í•˜ë½í•©ë‹ˆë‹¤. í•™ìŠµëŸ‰ì„ ëŠ˜ë¦¬ë©´ ì €í¬ì²˜ëŸ¼ ëˆì„ íƒœì›Œì•¼í•˜ëŠ”ë° ì„±ëŠ¥í–¥ìƒì´ ì•„ì£¼ ì‘ìŠµë‹ˆë‹¤.
2. 405Bì˜ ì‹¤ì œ ì„±ëŠ¥ (ë²¤ì¹˜ë§ˆí¬ ë§ê³ )ì´ ì •ë§ GPT4ì— ë²”ì ‘í•˜ëŠ”ê°€? ë„¤ ì‹¤ì œ ì‚¬ìš©í•´ë³´ë©´ ì´ˆê¸° GPT4 1ì›” ë²„ì „ê³¼ ê±°ì˜ í¡ì‚¬í•©ë‹ˆë‹¤. ìš”ì¦˜ ì¢‹ì€ ì†Œí˜•ëª¨ë¸ì˜ ì ìˆ˜ê°€ GPTì— ê·¼ì ‘í•˜ëŠ”ë°, ì‹¤ì œ ì‚¬ìš©í•´ë³´ë©´ ì‹¤ë§ìŠ¤ëŸ¬ìš¸ê²ë‹ˆë‹¤. ì´ê±´ ì „í˜€ ê·¸ë ‡ì§€ ì•ŠìŠµë‹ˆë‹¤.
3. Bllossom 405Bì˜ í•œêµ­ì–´ ë²¤ì¹˜ì„±ëŠ¥ì€? LogicKor 9ì ëŒ€, í•œêµ­ì–´ MT-Bench SOTA ë“±ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.

- Llama3.1-405B-Inst ëŒ€ë¹„ 5~10% í•œêµ­ì–´ ì„±ëŠ¥ì´ í–¥ìƒ ë˜ì—ˆìŠµë‹ˆë‹¤ (single turn ê¸°ì¤€).
- Llama3.1ì˜ ì˜ì–´ ì„±ëŠ¥ì„ ì „í˜€ ì†ìƒì‹œí‚¤ì§€ ì•Šì€ ì™„ì „í•œ Bilingual ëª¨ë¸ì…ë‹ˆë‹¤.
- ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ìì—°ìŠ¤ëŸ½ê³  ì¹œì ˆí•œ í•œêµ­ì–´ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.
- ì¸ê°„í‰ê°€, GPTí‰ê°€(MT-Bench, LogicKor 9ì  ë“±) ê²°ê³¼ GPT4ì™€ ìœ ì‚¬í•˜ê±°ë‚˜ ì•½ê°„ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B
https://huggingface.co/Bllossom/llama-3.1-Korean-Bllossom-405B-GGUF
https://huggingface.co/Bllossom/llama-3.1-Korean-Bllossom-405B

## ì¼ë³¸ì–´ LLM 22B
CyberAgentì—ì„œ ì¼ë³¸ì–´ LLM 22B ì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤. 

ê¸°ì¡´ ëª¨ë¸ì„ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê°œë°œí•œ 225ì–µ íŒŒë¼ë¯¸í„°ì˜ CyberAgentLM3-22B-Chatì…ë‹ˆë‹¤.

LLMì˜ ì¼ë³¸ì–´ ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” ì¼ë³¸ì–´LLM ë¦¬ë”ë³´ë“œì—ì„œ 70B íŒŒë¼ë¯¸í„°ì˜ Meta-Llama-3-70B-Instructì™€ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì˜€ê³ , ê·¸ë˜ì„œ ì˜¤í”ˆ ì¼ë³¸ì–´ LLMìœ¼ë¡œëŠ” í†±í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ì…ë‹ˆë‹¤

ëª¨ë¸ì€ ìƒìš© ì´ìš© ê°€ëŠ¥í•œ Apache License 2.0ì…ë‹ˆë‹¤. 

ë§í¬ : https://huggingface.co/cyberagent/calm3-22b-chat

## í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° Kiwi
Kiwiê°€ 0.18.0ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. 
ì´ë²ˆ ì—…ë°ì´íŠ¸ì—ì„œëŠ” ì™¸êµ­ì–´ ë¬¸ìì™€ ì´ëª¨ì§€ ì§€ì› ë“± ë¹„ í•œêµ­ì–´ í…ìŠ¤íŠ¸ì— ëŒ€í•œ í¸ì˜ì„± ê¸°ëŠ¥ì´ ì£¼ë¡œ ê°•í™”ë˜ì—ˆìŠµë‹ˆë‹¤.
https://github.com/bab2min/Kiwi/

# NYPL

## CM3leon ëª¨ë¸ì˜ weightë¥¼ ê³µê°œ
https://ai.meta.com/blog/meta-fair-research-new-releases/

### CM3leon ëª¨ë¸ ì†Œê°œ.
https://ai.meta.com/blog/generative-ai-text-images-cm3leon/
GPT-4o ê°™ì€ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ì— ê±¸ì¹œ ë©€í‹°ëª¨ë‹¬ íˆ¬ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì´ë‹¤. 
í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒí˜¸ ìƒì„± ë¶€ë¶„ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì„ í† í¬ë‚˜ì´ì € ë ˆë²¨ì—ì„œ í†µí•©í•´ì„œ, 
ë©€í‹°ëª¨ë‹¬ë¡œ ë„£ê³  ëª¨ë¸ì—ì„œ í•œ ë²ˆì— ë©€í‹°ëª¨ë‹¬ë¡œ ë¹¼ëŠ” ì‹ìœ¼ë¡œ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë©€í‹°ëª¨ë‹¬ íƒœìŠ¤í¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤. 

## Toy Models of Superposition
https://transformer-circuits.pub/2022/toy_model/index.html

## Open Synthetic Data Generation Pipeline for Training Large Language Models
The Nemotron-4 340B instruct model lets you generate high-quality data and then the reward model (also released) can filter out data on several attributes.

https://blogs.nvidia.com/.../nemotron-4-synthetic-data.../

Research paper: https://research.nvidia.com/publi.../2024-06_nemotron-4-340b
arXiv : https://arxiv.org/abs/2406.08673

## Nemotron4_340B
2ì›”ì— ê³µê°œë˜ì—ˆë˜ NVIDIA Nemotron-4ì˜ 340B ë²„ì „ì´ Base ëª¨ë¸, Instruct ëª¨ë¸ ê·¸ë¦¬ê³  Reward ëª¨ë¸ì´ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ ê·œì•½ ê´€ì ì—ì„œ ëª¨ë¸ ìˆ˜ì •, ë°°í¬, ê²°ê³¼ë¬¼ í™œìš©ê¹Œì§€ í­ë„“ê²Œ í™œìš© ê°€ëŠ¥í•œ í˜•íƒœì…ë‹ˆë‹¤. 
8ì¡°ê°œ í† í°ì— pretraining í›„ 1ì¡°ê°œë¥¼ continued training í•´ì„œ ì´ 9ì¡°ê°œ í† í°ì— í•™ìŠµ í–ˆë„¤ìš”. Alignment ë¥¼ ìœ„í•œ ë°ì´í„°ëŠ” ëŒ€ë¶€ë¶„ (98% ë„˜ê²Œ) í•©ì„±ì„ í†µí•´ì„œ ë§Œë“¤ì–´ ëƒˆë‹¤ê³  í•©ë‹ˆë‹¤.
FP8ë¡œ ì¸í¼ëŸ°ìŠ¤ í• ë•ŒëŠ” 8xH100 DGX 1 ë…¸ë“œë¡œ ëŒì•„ê°€ê²Œ ë§Œë“¤ì—ˆë‹¤ê³  í•˜ë„¤ìš”. BF16ìœ¼ë¡œ í•œë‹¤ë©´ H200 1ë…¸ë“œ, H100 ì´ë‘ A100ì€ 2ë…¸ë“œë¼ê³  í•©ë‹ˆë‹¤. 
ì˜ˆì‹œë¡œ ë°ì´í„° ì¦ê°•ìš©ìœ¼ë¡œ ë§ì´ í™œìš©í•˜ë¼ê³  í•˜ëŠ”ë° ìµœëŒ€ í† í°ê¸¸ì´ë„ 4K ë°–ì— ë˜ì§€ ì•Šì•„ ë­”ê°€ ì„œë¹„ìŠ¤ ì–´í”Œë¦¬ì¼€ì´ì…˜ í–¥ìœ¼ë¡œ ì“°ê¸°ì—” ë¶€ë‹´ìŠ¤ëŸ½ê¸´ í•˜ë„¤ìš”. 340Bë¥¼ ë¦¬ì–¼íƒ€ì„ì— ì“°ê¸°ë„ ì–´ë µê² êµ¬ìš”.
ê·¸ë˜ë„ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì˜ ë‹¤ì–‘ì„±ì´ ëŠ˜ì–´ë‚˜ëŠ” ë¶€ë¶„ì€ ì˜ë¯¸ê°€ ìˆê² ìŠµë‹ˆë‹¤. 
í”„ë¡œì íŠ¸ í˜ì´ì§€: https://research.nvidia.com/publi.../2024-06_nemotron-4-340b
í—ˆê¹…í˜ì´ìŠ¤: https://huggingface.co/nvidia/Nemotron-4-340B-Base

## Teaching LLMs to Express Confidence
https://x.com/omarsar0/status/1797682549608833477
https://arxiv.org/abs/2405.20974

##  Advancing Multimodal Medical Capabilities of Gemini

### ìš”ì•½: 
ë§ì€ ì„ìƒ ì‘ì—…ì—ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë²”ìš© ëŒ€í˜• ë‹¤ì¤‘ ëª¨ë“œ ëª¨ë¸ì—ì„œëŠ” ë³¼ ìˆ˜ ì—†ëŠ” ì˜ë£Œ ì´ë¯¸ì§€, ìœ ì „ì²´í•™ê³¼ ê°™ì€ íŠ¹ìˆ˜ ë°ì´í„°ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤.

Geminiì˜ ë‹¤ì¤‘ ëª¨ë“œ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ Geminiì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ê³„ìŠ¹í•˜ê³  2D ë° 3D ë°©ì‚¬ì„ í•™, ì¡°ì§ë³‘ë¦¬í•™, ì•ˆê³¼í•™, í”¼ë¶€ê³¼ ë° ê²Œë†ˆ ë°ì´í„°ë¥¼ í†µí•œ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ ì˜ë£Œìš©ìœ¼ë¡œ ìµœì í™”ëœ ìƒˆë¡œìš´ Med-Gemini ì œí’ˆêµ° ë‚´ì˜ ì—¬ëŸ¬ ëª¨ë¸ì„ ê°œë°œí•©ë‹ˆë‹¤. 

Med-Gemini-2DëŠ” ì „ë¬¸ê°€ í‰ê°€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ê¸°ë°˜ í‰ë¶€ ì—‘ìŠ¤ë ˆì´(CXR) ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ ìƒˆë¡œìš´ í‘œì¤€ì„ ì„¤ì •í•©ë‹ˆë‹¤.

ì´ëŠ” ë‘ ê°œì˜ ê°œë³„ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ì´ì „ ìµœê³  ê²°ê³¼ë¥¼ 1%ì™€ 12%ì˜ ì ˆëŒ€ ë§ˆì§„ìœ¼ë¡œ ì´ˆê³¼í•©ë‹ˆë‹¤. 

ì—¬ê¸°ì„œ 57%ì™€ 12% ì •ìƒ ì‚¬ë¡€ì— ëŒ€í•œ AI ë³´ê³ ì„œì˜ 96%, ë¹„ì •ìƒ ì‚¬ë¡€ì— ëŒ€í•œ 43%, 65%ê°€ ì›ë˜ ë°©ì‚¬ì„  ì „ë¬¸ì˜ì˜ ë³´ê³ ì„œì™€ "ë™ë“±í•˜ê±°ë‚˜ ë” ë‚˜ì€" ê²ƒìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” Med-Gemini-3Dë¥¼ ì‚¬ìš©í•˜ì—¬ 3D ì»´í“¨í„° ë‹¨ì¸µì´¬ì˜(CT) ë³¼ë¥¨ì— ëŒ€í•œ ìµœì´ˆì˜ ëŒ€ê·œëª¨ ë‹¤ì¤‘ ëª¨ë“œ ëª¨ë¸ ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„±ì„ ì‹œì—°í•©ë‹ˆë‹¤.

AI ë³´ê³ ì„œì˜ 53%ëŠ” ì„ìƒì ìœ¼ë¡œ í—ˆìš© ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼ë˜ì§€ë§Œ ì „ë¬¸ ë°©ì‚¬ì„  ì „ë¬¸ì˜ ë³´ê³  í’ˆì§ˆì„ ì¶©ì¡±í•˜ë ¤ë©´ ì¶”ê°€ ì—°êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.

ë³´ê³ ì„œ ìƒì„± ì™¸ì—ë„ Med-Gemini-2DëŠ” CXR ì‹œê°ì  ì§ˆë¬¸ ë‹µë³€(VQA)ì—ì„œ ì´ì „ ìµœê³  ì„±ëŠ¥ì„ ëŠ¥ê°€í•˜ê³  CXR ë¶„ë¥˜ ë° ë°©ì‚¬ì„ í•™ VQAì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ì—¬ 20ê°œ ì‘ì—… ì¤‘ 17ê°œ ì‘ì—…ì—ì„œ SoTA ë˜ëŠ” ê¸°ì¤€ì„ ì„ ì´ˆê³¼í•©ë‹ˆë‹¤. 

ì¡°ì§ë³‘ë¦¬í•™, ì•ˆê³¼í•™, í”¼ë¶€ê³¼ ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ Med-Gemini-2DëŠ” 20ê°œ ì‘ì—… ì¤‘ 18ê°œ ì‘ì—…ì—ì„œ ê¸°ì¤€ì„ ì„ ëŠ¥ê°€í•˜ê³  ì‘ì—…ë³„ ëª¨ë¸ ì„±ëŠ¥ì— ì ‘ê·¼í•©ë‹ˆë‹¤.

ì˜ìƒ ì´¬ì˜ ì™¸ì—ë„ Med-Gemini-Polygenicì€ ì§ˆë³‘ ìœ„í—˜ ì˜ˆì¸¡ì„ ìœ„í•œ í‘œì¤€ ì„ í˜• ë‹¤ìœ ì „ì„± ìœ„í—˜ ì ìˆ˜ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ë©°, í›ˆë ¨ëœ ì ì´ ì—†ëŠ” ìœ ì „ì ìœ¼ë¡œ ì—°ê´€ëœ ì§ˆë³‘ì„ ì¼ë°˜í™”í•©ë‹ˆë‹¤. 

ì•ˆì „ì´ ì¤‘ìš”í•œ ì˜ë£Œ ì˜ì—­ì—ì„œëŠ” ì¶”ê°€ ê°œë°œê³¼ í‰ê°€ê°€ í•„ìš”í•˜ì§€ë§Œ, ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ê´‘ë²”ìœ„í•œ ì˜ë£Œ ì‘ì—…ì— ê±¸ì³ Med-Geminiì˜ ì ì¬ë ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤.

### link
arXiv: https://arxiv.org/abs/2405.03162
Browse: https://browse.arxiv.org/pdf/2405.03162.pdf

PDF: https://arxiv.org/pdf/2405.03162.pdf  

arXiv-vanity: https://www.arxiv-vanity.com/papers/2405.03162 
Paper page: https://huggingface.co/papers/2405.03162

## Visual Language Intelligence and Edge AI 2.0 VILA 1.5
https://developer.nvidia.com/.../visual-language-models.../

Deploy on Jetson Orin/RTX 4090:
- Paper: https://arxiv.org/abs/2312.07533
- Repo: https://github.com/Efficient-Large-Model/VILA
- HF-repo: https://huggingface.co/Efficient-Large-Model

## TELA: Text to 3D Clothed Humans
GitHub_Link (https://github.com/DongJT1996/TELA)

## Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods
https://twitter.com/fly51fly/status/1785423963243647156
https://arxiv.org/abs/2404.18655

## MedSegDiff: Medical Image Segmentation with Diffusion Model
GitHub_Link (https://github.com/KidsWithTokens/MedSegDiff)

## Photoswap : Personalized Subject Swapping in Images
GitHub_Link (https://github.com/eric-ai-lab/photoswap)

## Meta, Llama 3 ê³µê°œ

### Llama 3ì˜ ì²« ë‘ ê°€ì§€ ëª¨ë¸(ì‚¬ì „í•™ìŠµ ë° ëª…ë ¹ì–´ ë¯¸ì„¸ì¡°ì •ëœ 8Bì™€ 70B ëª¨ë¸)ì„ ê³µê°œ
ê´‘ë²”ìœ„í•œ ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ë“¤ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, í–¥ìƒëœ ì¶”ë¡  ë“± ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì œê³µ
í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœê³ ì˜ ë…ì  ëª¨ë¸ê³¼ ë™ë“±í•œ ìˆ˜ì¤€ì˜ ìµœê³ ì˜ ì˜¤í”ˆ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³ ì í•¨. ê°œë°œì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ê³ , ë¹ ë¥´ê²Œ ìì£¼ ë¦´ë¦¬ì¦ˆí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨

### Llama Guard 2, Code Shield, CyberSec Eval 2 ë“±ì˜ ìƒˆë¡œìš´ ì‹ ë¢° ë° ì•ˆì „ ë„êµ¬ ë„ì…
í–¥í›„ ëª‡ ë‹¬ ë‚´ì— ìƒˆë¡œìš´ ê¸°ëŠ¥, ë” ê¸´ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°, ì¶”ê°€ ëª¨ë¸ í¬ê¸°, í–¥ìƒëœ ì„±ëŠ¥ ë“±ì„ ë„ì…í•  ì˜ˆì •ì´ë©°, Llama 3 ì—°êµ¬ ë…¼ë¬¸ë„ ê³µìœ í•  ì˜ˆì •
AWS, Databricks, Google Cloud, Hugging Face, Kaggle, IBM WatsonX, Microsoft Azure, NVIDIA NIM, Snowflake ë“±ì—ì„œ ê³§ ì‚¬ìš© ê°€ëŠ¥í•´ì§ˆ ì˜ˆì •ì´ë©°, AMD, AWS, Dell, Intel, NVIDIA, Qualcomm ë“±ì˜ í•˜ë“œì›¨ì–´ í”Œë«í¼ì—ì„œë„ ì§€ì›ë  ì˜ˆì •
Llama 3 ê¸°ìˆ ë¡œ êµ¬ì¶•ëœ Meta AIëŠ” ì´ì œ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì¤‘ í•˜ë‚˜ë¡œ, ì‚¬ìš©ìì˜ ì§€ëŠ¥ì„ ë†’ì´ê³  ë¶€ë‹´ì„ ëœì–´ì¤„ ìˆ˜ ìˆìŒ

### Llama 3ì˜ ì„±ëŠ¥
8Bì™€ 70B íŒŒë¼ë¯¸í„° Llama 3 ëª¨ë¸ì€ Llama 2ì— ë¹„í•´ í° ë„ì•½ì„ ì´ë£¨ì—ˆìœ¼ë©°, í•´ë‹¹ ê·œëª¨ì—ì„œ LLM ëª¨ë¸ì˜ ìƒˆë¡œìš´ ìµœê³  ìˆ˜ì¤€ì„ ë‹¬ì„±
ì‚¬ì „ í•™ìŠµ ë° ì‚¬í›„ í•™ìŠµì˜ ê°œì„  ë•ë¶„ì— ì‚¬ì „ í•™ìŠµë˜ê³  ëª…ë ¹ì–´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ 8Bì™€ 70B íŒŒë¼ë¯¸í„° ê·œëª¨ì—ì„œ í˜„ì¡´í•˜ëŠ” ìµœê³ ì˜ ëª¨ë¸ì„
ì‚¬í›„ í•™ìŠµ ì ˆì°¨ì˜ ê°œì„ ìœ¼ë¡œ ê±°ì§“ ê±°ë¶€ìœ¨ì´ ìƒë‹¹íˆ ê°ì†Œí•˜ê³ , ì •ë ¬ì´ ê°œì„ ë˜ì—ˆê³ , ëª¨ë¸ ì‘ë‹µì˜ ë‹¤ì–‘ì„±ì´ ì¦ê°€í•¨
ë˜í•œ ì¶”ë¡ , ì½”ë“œ ìƒì„±, ëª…ë ¹ì–´ ë”°ë¥´ê¸° ë“±ì˜ ê¸°ëŠ¥ì´ í¬ê²Œ ê°œì„ ë˜ì–´ Llama 3ê°€ ë” ì¡°ì¢… ê°€ëŠ¥í•´ì§(Steerable)
Llama 3 ê°œë°œ ê³¼ì •ì—ì„œ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ì—ì„œì˜ ëª¨ë¸ ì„±ëŠ¥ì„ ì‚´í´ë³´ê³ , ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì„±ëŠ¥ ìµœì í™”ë„ ì¶”êµ¬í•¨
ì´ë¥¼ ìœ„í•´ 12ê°€ì§€ í•µì‹¬ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ë‹¤ë£¨ëŠ” 1,800ê°œì˜ í”„ë¡¬í”„íŠ¸ê°€ í¬í•¨ëœ ìƒˆë¡œìš´ ê³ í’ˆì§ˆ ì¸ê°„ í‰ê°€ ì„¸íŠ¸ë¥¼ ê°œë°œí•¨
ì´ í‰ê°€ ì„¸íŠ¸ë¥¼ í†µí•´ 70B ëª…ë ¹ì–´-ì¶”ì¢… ëª¨ë¸ì´ ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìœ ì‚¬í•œ í¬ê¸°ì˜ ê²½ìŸ ëª¨ë¸ì— ë¹„í•´ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¨
ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë˜í•œ í•´ë‹¹ ê·œëª¨ì—ì„œ LLM ëª¨ë¸ì˜ ìƒˆë¡œìš´ ìµœì²¨ë‹¨ ê¸°ìˆ ì„ ë‹¬ì„±
í›Œë¥­í•œ ì–¸ì–´ ëª¨ë¸ì„ ê°œë°œí•˜ê¸° ìœ„í•´ì„œëŠ” í˜ì‹ , í™•ì¥, ë‹¨ìˆœì„± ìµœì í™”ê°€ ì¤‘ìš”í•˜ë‹¤ê³  ë¯¿ìŒ
Llama 3 í”„ë¡œì íŠ¸ ì „ë°˜ì— ê±¸ì³ ëª¨ë¸ ì•„í‚¤í…ì²˜, ì‚¬ì „ í•™ìŠµ ë°ì´í„°, ì‚¬ì „ í•™ìŠµ í™•ì¥, ëª…ë ¹ì–´ ë¯¸ì„¸ ì¡°ì •ì˜ ë„¤ ê°€ì§€ í•µì‹¬ ìš”ì†Œì— ì´ˆì ì„ ë§ì¶”ì–´ ì´ ì„¤ê³„ ì² í•™ì„ ì±„íƒí•¨

### ëª¨ë¸ ì•„í‚¤í…ì²˜
Llama 3ì—ì„œëŠ” ë¹„êµì  í‘œì¤€ì ì¸ ë””ì½”ë” ì „ìš© íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ ì„ íƒí•¨
Llama 2ì™€ ë¹„êµí•˜ì—¬ ëª‡ ê°€ì§€ ì£¼ìš” ê°œì„  ì‚¬í•­ì´ ìˆìŒ
Llama 3ëŠ” ì–¸ì–´ë¥¼ í›¨ì”¬ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì¸ì½”ë”©í•˜ëŠ” 128K í† í°ì˜ ì–´íœ˜ë¥¼ ê°€ì§„ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ìƒë‹¹íˆ ê°œì„ í•¨
Llama 3 ëª¨ë¸ì˜ ì¶”ë¡  íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ 8Bì™€ 70B í¬ê¸° ëª¨ë‘ì— ê±¸ì³ ê·¸ë£¹í™”ëœ ì¿¼ë¦¬ ì£¼ì˜(GQA)ë¥¼ ì±„íƒí•¨
ì…€í”„ ì–´í…ì…˜ì´ ë¬¸ì„œ ê²½ê³„ë¥¼ ë„˜ì§€ ì•Šë„ë¡ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ 8,192ê°œì˜ í† í° ì‹œí€€ìŠ¤ë¡œ ëª¨ë¸ì„ í›ˆë ¨

### í•™ìŠµ ë°ì´í„°
ìµœê³ ì˜ ì–¸ì–´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ëŒ€ê·œëª¨ ê³ í’ˆì§ˆ í•™ìŠµ ë°ì´í„°ì…‹ì˜ íë ˆì´ì…˜ì´ ê°€ì¥ ì¤‘ìš”í•¨
Llama 3ëŠ” ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘ëœ 15T ì´ìƒì˜ í† í°ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµë¨
í•™ìŠµ ë°ì´í„°ì…‹ì€ Llama 2ì— ì‚¬ìš©ëœ ê²ƒë³´ë‹¤ 7ë°° ë” í¬ë©°, 4ë°° ë” ë§ì€ ì½”ë“œë¥¼ í¬í•¨í•¨
í–¥í›„ ë‹¤êµ­ì–´ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì¤€ë¹„í•˜ê¸° ìœ„í•´ Llama 3 ì‚¬ì „ í•™ìŠµ ë°ì´í„°ì…‹ì˜ 5% ì´ìƒì´ 30ê°œ ì´ìƒì˜ ì–¸ì–´ë¥¼ ë‹¤ë£¨ëŠ” ê³ í’ˆì§ˆ ë¹„ì˜ì–´ ë°ì´í„°ë¡œ êµ¬ì„±ë¨

### ì‚¬ì „ í•™ìŠµ í™•ì¥
Llama 3 ëª¨ë¸ì—ì„œ ì‚¬ì „ í•™ìŠµ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ ì‚¬ì „ í•™ìŠµ í™•ì¥ì— ìƒë‹¹í•œ ë…¸ë ¥ì„ ê¸°ìš¸ì„
íŠ¹íˆ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ë¥¼ ìœ„í•œ ì¼ë ¨ì˜ ìƒì„¸í•œ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì„ ê°œë°œí•¨
ì´ëŸ¬í•œ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ì„ í†µí•´ ìµœì ì˜ ë°ì´í„° ë¯¹ìŠ¤ë¥¼ ì„ íƒí•˜ê³  í•™ìŠµ ì»´í“¨íŒ…ì„ ìµœìƒìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì •ë³´ì— ì…ê°í•œ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆìŒ

### ëª…ë ¹ì–´ ë¯¸ì„¸ ì¡°ì •
ì±„íŒ… ì‚¬ìš© ì‚¬ë¡€ì—ì„œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ì ì¬ë ¥ì„ ì™„ì „íˆ ë°œíœ˜í•˜ê¸° ìœ„í•´ ëª…ë ¹ì–´ ì¡°ì • ì ‘ê·¼ ë°©ì‹ì— ëŒ€í•´ì„œë„ í˜ì‹ ì„ ì´ë£¸
ì‚¬í›„ í•™ìŠµì— ëŒ€í•œ ì ‘ê·¼ ë°©ì‹ì€ ì§€ë„ í•™ìŠµ ë¯¸ì„¸ ì¡°ì •(SFT), ê±°ë¶€ ìƒ˜í”Œë§, ê·¼ì ‘ ì •ì±… ìµœì í™”(PPO), ì§ì ‘ ì •ì±… ìµœì í™”(DPO)ì˜ ì¡°í•©ì„
SFTì— ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆê³¼ PPO ë° DPOì— ì‚¬ìš©ë˜ëŠ” ì„ í˜¸ë„ ìˆœìœ„ëŠ” ì •ë ¬ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ê³¼ë„í•œ ì˜í–¥ì„ ë¯¸ì¹¨

### Llama 3ë¡œ êµ¬ì¶•í•˜ê¸°
Metaì˜ ë¹„ì „ì€ ê°œë°œìê°€ Llama 3ì„ ë§ì¶¤ ì„¤ì •í•˜ì—¬ ê´€ë ¨ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì§€ì›í•˜ê³  ëª¨ë²” ì‚¬ë¡€ë¥¼ ì‰½ê²Œ ì±„íƒí•˜ê³  ê°œë°©í˜• ìƒíƒœê³„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì„
ì´ë²ˆ ë¦´ë¦¬ìŠ¤ì—ì„œëŠ” Llama Guard 2 ë° Cybersec Eval 2ì™€ í•¨ê»˜ ì—…ë°ì´íŠ¸ëœ êµ¬ì„± ìš”ì†Œë¥¼ í¬í•¨í•œ ìƒˆë¡œìš´ ì‹ ë¢° ë° ì•ˆì „ ë„êµ¬ì™€ LLMì—ì„œ ìƒì„±í•œ ì•ˆì „í•˜ì§€ ì•Šì€ ì½”ë“œë¥¼ í•„í„°ë§í•˜ê¸° ìœ„í•œ ì¶”ë¡  ì‹œê°„ ê°€ë“œë ˆì¼ì¸ Code Shieldë¥¼ ë„ì…í•¨
ë˜í•œ Llama 3ì„ LLMì„ ì‰½ê²Œ ì‘ì„±, ë¯¸ì„¸ ì¡°ì • ë° ì‹¤í—˜í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ PyTorch ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ torchtuneê³¼ í•¨ê»˜ ê°œë°œí•¨
ì±…ì„ê° ìˆëŠ” ê°œë°œê³¼ ë°°í¬ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ ìˆ˜ì¤€ ì ‘ê·¼ë²•
Llama 3 ëª¨ë¸ì€ ìµœëŒ€í•œ ë„ì›€ì´ ë˜ë©´ì„œë„ ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì±…ì„ê° ìˆëŠ” ë°°í¬ ì ‘ê·¼ ë°©ì‹ì„ ë³´ì¥í•˜ë„ë¡ ì„¤ê³„ë¨
ì´ë¥¼ ìœ„í•´ Llamaì˜ ì±…ì„ê° ìˆëŠ” ê°œë°œê³¼ ë°°í¬ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ìˆ˜ì¤€ ì ‘ê·¼ë²•ì„ ì±„íƒí•¨
Llama ëª¨ë¸ì„ ê°œë°œìê°€ ê³ ìœ í•œ ìµœì¢… ëª©í‘œë¥¼ ì—¼ë‘ì— ë‘ê³  ì„¤ê³„í•˜ëŠ” ì‹œìŠ¤í…œì˜ ê¸°ë³¸ ìš”ì†Œë¡œ ê°„ì£¼í•¨
ëª…ë ¹ì–´ ë¯¸ì„¸ ì¡°ì •ì€ ëª¨ë¸ì˜ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•¨
ëª…ë ¹ì–´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì€ ë‚´ë¶€ ë° ì™¸ë¶€ ë…¸ë ¥ì„ í†µí•´ ì•ˆì „ì„±ì— ëŒ€í•´ ë ˆë“œíŒ€(í…ŒìŠ¤íŠ¸)ì„ ê±°ì¹¨
ì´ëŸ¬í•œ ë…¸ë ¥ì€ ë°˜ë³µì ì´ë©° ë¦´ë¦¬ìŠ¤ë˜ëŠ” ëª¨ë¸ì˜ ì•ˆì „ì„± ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©ë¨
Llama Guard ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ ë° ì‘ë‹µ ì•ˆì „ì˜ ê¸°ë°˜ì´ ë˜ë©° ì• í”Œë¦¬ì¼€ì´ì…˜ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ìƒˆë¡œìš´ ë¶„ë¥˜ë¥¼ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŒ
ìƒˆë¡œìš´ Llama Guard 2ëŠ” ì—…ê³„ í‘œì¤€ ì§€ì›ì„ ìœ„í•´ ìµœê·¼ ë°œí‘œëœ MLCommons ë¶„ë¥˜ë²•ì„ ì‚¬ìš©í•¨
CyberSecEval 2ëŠ” LLMì˜ ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì•…ìš© ì„±í–¥, ê³µê²©ì ì¸ ì‚¬ì´ë²„ ë³´ì•ˆ ê¸°ëŠ¥, í”„ë¡¬í”„íŠ¸ ì£¼ì… ê³µê²©ì— ëŒ€í•œ ì·¨ì•½ì„± ì¸¡ì •ì„ ì¶”ê°€í•˜ì—¬ ì´ì „ ë²„ì „ì„ í™•ì¥í•¨
Code ShieldëŠ” LLMì—ì„œ ìƒì„±ëœ ì•ˆì „í•˜ì§€ ì•Šì€ ì½”ë“œì— ëŒ€í•œ ì¶”ë¡  ì‹œê°„ í•„í„°ë§ì„ ì§€ì›í•˜ì—¬ ì•ˆì „í•˜ì§€ ì•Šì€ ì½”ë“œ ì œì•ˆ, ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì•…ìš© ë°©ì§€, ë³´ì•ˆ ëª…ë ¹ ì‹¤í–‰ê³¼ ê´€ë ¨ëœ ìœ„í—˜ì„ ì™„í™”í•¨

### Llama 3ì˜ ëŒ€ê·œëª¨ ë°°í¬
Llama 3ëŠ” í´ë¼ìš°ë“œ ì œê³µì—…ì²´, ëª¨ë¸ API ì œê³µì—…ì²´ ë“± ì£¼ìš” í”Œë«í¼ì—ì„œ ê³§ ì‚¬ìš© ê°€ëŠ¥í•´ì§ˆ ì˜ˆì •ì„
ë²¤ì¹˜ë§ˆí¬ì— ë”°ë¥´ë©´ í† í¬ë‚˜ì´ì €ëŠ” Llama 2ì— ë¹„í•´ ìµœëŒ€ 15% ì ì€ í† í°ì„ ìƒì„±í•˜ì—¬ í† í° íš¨ìœ¨ì„±ì´ í–¥ìƒë¨
ë˜í•œ ê·¸ë£¹ ì¿¼ë¦¬ ì£¼ì˜ë ¥(GQA)ì´ Llama 3 8Bì—ë„ ì¶”ê°€ë¨

### Llama 3ì˜ í–¥í›„ ê³„íš
Llama 3 8B ë° 70B ëª¨ë¸ì€ Llama 3 ì¶œì‹œ ê³„íšì˜ ì‹œì‘ì— ë¶ˆê³¼í•¨
í–¥í›„ ëª‡ ë‹¬ ë™ì•ˆ ë©€í‹°ëª¨ë‹¬, ë‹¤êµ­ì–´ ëŒ€í™” ëŠ¥ë ¥, í›¨ì”¬ ë” ê¸´ ë§¥ë½ ì°½, ì „ë°˜ì ìœ¼ë¡œ ë” ê°•ë ¥í•œ ê¸°ëŠ¥ ë“± ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ê°–ì¶˜ ì—¬ëŸ¬ ëª¨ë¸ì„ ì¶œì‹œí•  ì˜ˆì •ì„
Llama 3 í•™ìŠµì´ ì™„ë£Œë˜ë©´ ìƒì„¸í•œ ì—°êµ¬ ë…¼ë¬¸ë„ ê²Œì¬í•  ì˜ˆì •ì„

### Llama-3-400B+ will mark the watershed moment that the community gains open-weight access to a GPT-4-class model.
https://github.com/openai/simple-evals

## Garment3DGen : 3D Garment Stylization and Texture Generation (2403, Meta)

site : https://nsarafianos.github.io/garment3dgen
paper : https://arxiv.org/abs/2403.18816
code : comimg 


## NEW EULER SMEA DYN SAMPLER!!! ]

A1111 , ComfyUI ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ê³  í•©ë‹ˆë‹¤.

git : https://github.com/Koishi-Star/Euler-Smea-Dyn-Sampler

ì£¼ìš”ë‚´ìš© >
ìš°ìˆ˜í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ëœ ì˜¤ì¼ëŸ¬ì˜ ì ‘ê·¼ ë°©ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ìƒ˜í”Œë§ ë°©ë²•ì…ë‹ˆë‹¤.
SMEA ìƒ˜í”ŒëŸ¬ëŠ” ëŒ€í˜• ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ ë°œìƒí•˜ëŠ” êµ¬ì¡°ì  ë° ì‚¬ì§€ ë¶•ê´´ë¥¼ í¬ê²Œ ì™„í™”í•  ìˆ˜ ìˆìœ¼ë©°, ìƒë‹¹ ë¶€ë¶„ ìš°ìˆ˜í•œ ì† ë¬˜ì‚¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì™„ë²½í•˜ì§€ëŠ” ì•Šì§€ë§Œ ê¸°ì¡´ ìƒ˜í”Œë§ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•¨).
SMEA ìƒ˜í”ŒëŸ¬ëŠ” ëŒ€ë¶€ë¶„ì˜ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ìˆ˜ìš©í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©° íŠ¹íˆ í° ì´ë¯¸ì§€ì—ì„œ íƒì›”í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ë˜í•œ í›ˆë ¨ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ìƒ‰ë‹¤ë¥¸ í¬ê¸°ì˜ ì´ë¯¸ì§€ ìƒì„±ë„ ì§€ì›í•©ë‹ˆë‹¤(ì˜ˆ: SDXLì—ì„œ 512x512 ì‹¤í–‰, SD1.5ì—ì„œ 823x1216 ì‹¤í–‰, 640x960 ì‹¤í–‰ ë“±).
SMEA ìƒ˜í”ŒëŸ¬ëŠ” SD1.5ì—ì„œ ë§¤ìš° ì˜ ì‘ë™í•˜ì§€ë§Œ SDXLì—ì„œëŠ” ê·¸ íš¨ê³¼ê°€ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ê³„ì‚° ë¦¬ì†ŒìŠ¤ ì†Œë¹„ ì¸¡ë©´ì—ì„œ Euler dyëŠ” Euler aì™€ ê±°ì˜ ë™ì¼í•˜ì§€ë§Œ Euler SMEA Dy ìƒ˜í”ŒëŸ¬ëŠ” ì•½ 1.25ë°° ë” ë§ì€ ê³„ì‚° ë¦¬ì†ŒìŠ¤ë¥¼ ì†Œë¹„í•©ë‹ˆë‹¤.

This is really good, isn't it? Just using the sampler update, you can get good results at non-standard resolutions with SD15. It's available for use in A1111 and ComfyUI.
git : https://github.com/Koishi-Star/Euler-Smea-Dyn-Sampler

A sampling method based on Euler's approach, designed to generate superior imagery.
The SMEA sampler can significantly mitigate the structural and limb collapse that occurs when generating large images, and to a great extent, it can produce superior hand depictions (not perfect, but better than existing sampling methods).
The SMEA sampler is designed to accommodate the majority of image sizes, with particularly outstanding performance on larger images. It also supports the generation of images in unconventional sizes that lack sufficient training data (for example, running 512x512 in SDXL, 823x1216 in SD1.5, as well as 640x960, etc.).
The SMEA sampler performs very well in SD1.5, but the effects are not as pronounced in SDXL.
In terms of computational resource consumption, the Euler dy is approximately equivalent to the Euler a, while the Euler SMEA Dy sampler will consume more computational resources, approximately 1.25 times more.

## gpt-prompt-engineer
https://github.com/mshumer/gpt-prompt-engineer

## WonderJourney: Going from Anywhere to Everywhere
GitHub_Link (https://github.com/KovenYu/WonderJourney)

## StructLDM: Structured Latent Diffusion for 3D Human Generation 
(2404, S-Lab Nanyang Technological University)
site : https://taohuumd.github.io/projects/StructLDM/
paper : https://arxiv.org/abs/2404.01241

## Llama2, Mistral ëª¨ë¸ì˜ FP8
Friendli AI ì—ì„œ Llama2, Mistral ëª¨ë¸ì˜ FP8 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ê³µê°œí–ˆìŠµë‹ˆë‹¤. 
[https://huggingface.co/FriendliAI/Mistral-7B-Instruct-v0.2-fp8](https://huggingface.co/FriendliAI/Mistral-7B-Instruct-v0.2-fp8)
[https://huggingface.co/FriendliAI/Llama-2-7b-chat-hf-fp8](https://huggingface.co/FriendliAI/Llama-2-7b-chat-hf-fp8)
[https://huggingface.co/FriendliAI/Llama-2-13b-chat-hf-fp8](https://huggingface.co/FriendliAI/Llama-2-13b-chat-hf-fp8)
[https://huggingface.co/FriendliAI/Llama-2-70b-chat-hf-fp8](https://huggingface.co/FriendliAI/Llama-2-70b-chat-hf-fp8)

## Retrieval-based-Voice-Conversion
https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/tree/main

ìê¸°ë“¤ ëª©ì†Œë¦¬ anime girlë¡œ ë°”ê¾¸ê³  ì‹¶ì–´ì„œ ë§Œë“ ê²ƒ.

## GPT beats diffusion
GitHub_Link (https://github.com/FoundationVision/VAR)

## InstantID : Zero-shot Identity-Preserving Generation in Seconds
gitHub_Link (https://github.com/InstantID/InstantID)

## InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction
https://twitter.com/arankomats.../status/1774618885494342119
https://arxiv.org/abs/2403.19652

## Google announces Streaming Dense Video Captioning
https://twitter.com/_akhaliq/status/1775176791772008825
https://huggingface.co/papers/2404.01297

## Large Language Models Are Effective Temporal Learners
https://twitter.com/_akhaliq/status/1775179607920017806
https://huggingface.co/papers/2404.00308

## ComfyUI
Node : https://github.com/chaojie/ComfyUI-AniPortrait 

## Tokenizer Choice For LLM Training: Negligible or Crucial?
https://arxiv.org/pdf/2310.08754.pdf
- ë‹¨ì¼ ì–¸ì–´ í† í¬ë‚˜ì´ì €ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œë°œëœ LLMì˜  ë‹¤êµ­ì–´ ì„±ëŠ¥ì´ ë¹„êµì  ë‚®ì€ ì , ì½”ë”© íŠ¹í™” í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ LLMì˜ ì½”ë”© ëŠ¥ë ¥ì„ ê°œì„ í•œ ì  ë“±ì˜ ì‚¬ë¡€ë¥¼ í†µí•´ í† í¬ë‚˜ì´ì €ê°€ LLMì˜ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì´ ë‹¤ì‹œê¸ˆ í™•ì¸ ë˜ì—ˆìŠµë‹ˆë‹¤.
- í† í¬ë‚˜ì´ì €ì˜ vocab sizeëŠ” ë¬´ì‘ì • ëŠ˜ë¦¬ëŠ” ê²ƒì´ ì¢‹ë‹¤ê¸°ë³´ë‹¨ ì¶”ë¡  ì†ë„ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ ìµœì ì˜ ê°’ì„ ì°¾ëŠ” ê²Œ ì¤‘ìš”í•©ë‹ˆë‹¤.
- í† í¬ë‚˜ì´ì € ìì²´ë¥¼ í‰ê°€í•˜ëŠ” ì§€í‘œ(fertility, parity)ì™€ LLMì˜ ì„±ëŠ¥ ì§€í‘œ ê°„ì— ê°•í•œ ê´€ê³„ëŠ” ì—†ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
- 50B ì´ìƒì˜ ëª¨ë¸ë“¤ì„ íŒŒì¸íŠœë‹í•  ë•ŒëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ë°”ê¾¸ëŠ” ê²ƒì´ LLMì˜ ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šì•˜ë‹¤ê³  í•©ë‹ˆë‹¤.
(Abstract translated with Claude Opus)
- í† í°í™”ëŠ” í˜„ëŒ€ LLMì˜ ê³¼ì†Œ ì—°êµ¬ë˜ê³  ì¢…ì¢… ê°„ê³¼ë˜ëŠ” êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ë°œí‘œëœ ì—°êµ¬ëŠ” í† í°í™”ë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•œ ì ˆì œ(ablation)ë‚˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³ , ì¢…ì¢… ë‹¤ë¥¸ ëª¨ë¸ì—ì„œ ì°¨ìš©í•œ ë‹¨ì¼ í† í¬ë‚˜ì´ì €ë¥¼ ëª¨ë“  ì‹¤í—˜ì— ì‚¬ìš©í•©ë‹ˆë‹¤. ë˜í•œ, ê¸°ë³¸ ëª¨ë¸ì„ fine-tuningí•  ë•Œ í† í¬ë‚˜ì´ì €ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë³€ê²½ë˜ì§€ ì•Šì€ ìƒíƒœë¡œ ìœ ì§€ë©ë‹ˆë‹¤. 
- ì´ ë…¼ë¬¸ì—ì„œëŠ” í† í¬ë‚˜ì´ì €ì˜ í¬ê¸°, ì‚¬ì „ í† í°í™” ì •ê·œ í‘œí˜„ì‹ ë° í•™ìŠµ ë°ì´í„°ê°€ ëª¨ë¸ì˜ ìƒì„± ì†ë„, ìœ íš¨ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë° ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì„±ëŠ¥ì— ìƒë‹¹í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. 
- ìš°ë¦¬ëŠ” ì „ë¬¸í™”ëœ Byte-Pair Encoding ì½”ë“œ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµì‹œí‚¤ê³ , HumanEval ë° MBPPì™€ ê°™ì€ ì½”ë“œ ìƒì„± ì‘ì—…ì— ëŒ€í•œ LLMì˜ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” í† í¬ë‚˜ì´ì € ì„¤ê³„ì˜ ì˜í–¥ì— ëŒ€í•´ ê´‘ë²”ìœ„í•œ ì ˆì œ(ablation)ë¥¼ ìˆ˜í–‰í•˜ë©°, í† í¬ë‚˜ì´ì € í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„ íƒ ë° ì‚¬ì „ í•™ìŠµëœ LLMì—ì„œì˜ í† í¬ë‚˜ì´ì € ì „í™˜ì— ëŒ€í•œ ê¶Œì¥ ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤. 
- ìš°ë¦¬ëŠ” ì²˜ìŒë¶€í„° í•™ìŠµí•œ ëª¨ë¸ê³¼ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì—ì„œ ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ì—¬ ê´‘ë²”ìœ„í•œ ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•œ ì ìš© ê°€ëŠ¥ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” 500ì–µ ê°œ ì´ìƒì˜ í† í°ìœ¼ë¡œ fine-tuningí•  ë•Œ, ì‚¬ì „ í•™ìŠµëœ LLMì˜ í† í¬ë‚˜ì´ì €ë¥¼ ì „ë¬¸í™”í•˜ì—¬ ìƒì„± ì†ë„ì™€ ìœ íš¨ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°ì—ì„œ í° ì´ë“ì„ ì–»ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

## Mesh2NeRF: Direct Mesh Supervision for Neural Radiance Field Representation and Generation
https://twitter.com/fly51fly/status/1773835840709697889
https://arxiv.org/abs/2403.19319

## ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ê²©íˆ¬ì¥
ìŠ¤íŠ¸ë¦¬íŠ¸ íŒŒì´í„° IIIì—ì„œ LLMì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„œë¡œ ì‹¸ìš°ê²Œ í–ˆë‹µë‹ˆë‹¤.
ì–´ë–¤ LLMì´ ìµœê³ ì˜ íŒŒì´í„°ê°€ ë ê¹Œìš”?
ê¹ƒí—ˆë¸Œ https://github.com/OpenGenerativeAI/llm-colosseum

## Boosting LLMs with Novel Iterative Data Enhancement
https://huggingface.co/papers/2403.15042

## DE-Net: Dynamic Text-guided Image Editing Adversarial Networks
GitHub_Link (https://github.com/tobran/DE-Net)

## AutoRecon: Automated 3D Object Discovery and Reconstruction
GitHub_Link (https://github.com/zju3dv/AutoRecon)
## Mixing Expert LLMs into a Mixture-of-Experts LLM
https://huggingface.co/papers/2403.07816

## Visual Style Prompting with Swapping Self-Attention
Official Pytorch implementation of "Visual Style Prompting with Swapping Self-Attention"
GitHub_Link (https://github.com/naver-ai/Visual-Style-Prompting)

## Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU
https://twitter.com/_akhaliq/status/1767393991727657262
https://huggingface.co/papers/2403.06504

## Domain Expansion of Image Generators
Domain Expansion of Image Generators offers a groundbreaking perspective on enhancing pretrained generative models. The ability to seamlessly integrate numerous new domains while preserving the original knowledge presents a transformative approach to model versatility and efficiency, potentially reshaping the landscape of generative model applications.
GitHub_Link (https://github.com/adobe-research/domain-expansion)

## DreamCraft3D
GitHub_Link (https://github.com/deepseek-ai/DreamCraft3D)

DreamCraft3D pioneers a groundbreaking approach to 3D content generation, overcoming consistency challenges with innovative techniques like score distillation and Bootstrapped Score Distillation. The alternating optimization strategy showcases a synergistic relationship between 3D scene representation and diffusion models, resulting in remarkable photorealistic renderings and a noteworthy leap in the state-of-the-art.

## Intel Extension for Transformers
Intel Extension for Transformers (https://github.com/intel/intel-extension-for-transformers) supports INT4 and low-bit inference on both CPUs and GPUs!
ğŸ“”Simple usage guide: https://github.com/intel/intel-extension-for-transformers/blob/main/docs/weightonlyquant.md 
ğŸ”¥All your need is to get an Intel GPU and run LLMs @huggingface
 
 https://github.com/intel/intel-extension-for-transformers

## Byte-gpt 
https://byte-gpt.github.io/
https://arxiv.org/abs/2402.19155
byte level transformer (bGPT)
tokenize ì—†ì´ byte ì •ë³´ë¥¼ ë°”ë¡œ ëª¨ë¸ì´ ë„£ê³  prediction í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ëª¨ë¸.. ê·¸ë˜ì„œ vocab sizeëŠ” 256 + 1.
ê³µê°œëœ ì½”ë“œ ìƒìœ¼ë¡œëŠ” sequence lengthëŠ” 512ì— ë¶ˆê³¼í•˜ì§€ë§Œ multimodalë¡œ ê°€ëŠ” ê³¼ì •

## Keyframer (Apple) 
 LLM ì˜ ì½”ë“œ ìƒì„± ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ SVG ë²¡í„° ì´ë¯¸ì§€ë¥¼ ì½”ë“œë¡œ ë³€ê²½í•˜ì—¬ ì• ë‹ˆë©”ì´ì…˜í™”. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ì˜ìƒì„ ìƒì„±í•˜ëŠ” ê¸°ì¡´ ìƒì„± ëª¨ë¸ê³¼ëŠ” ë‹¤ë¥´ê²Œ, ìì—°ì–´ì™€ ì´ë¯¸ì§€(SVG) ì„ ë„£ì–´ì£¼ë©´ LLM ì½”ë“œ ìƒì„± ê¸°ëŠ¥ í™œìš©í•˜ì—¬ ì• ë‹ˆë©”ì´íŠ¸ ìƒì„± 

Keyframer: Empowering Animation Design using Large Language Models (2402, Apple)

paper : https://arxiv.org/abs/2402.06071

 ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë‹¤ì–‘í•œ í¬ë¦¬ì—ì´í‹°ë¸Œ ì˜ì—­ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆì§€ë§Œ, ì• ë‹ˆë©”ì´ì…˜ì— LLMì„ ì ìš©í•˜ëŠ” ê²ƒì€ ì˜ ì•Œë ¤ì§€ì§€ ì•Šì•˜ìœ¼ë©° ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ë™ì‘ì„ íš¨ê³¼ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ë°©ë²•ê³¼ ê°™ì€ ìƒˆë¡œìš´ ê³¼ì œë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ì •ì  ì´ë¯¸ì§€(SVG)ë¥¼ ìì—°ì–´ë¡œ ì• ë‹ˆë©”ì´ì…˜í™”í•˜ëŠ” ë””ìì¸ ë„êµ¬ì¸ Keyframerë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì „ë¬¸ ì• ë‹ˆë©”ì´ì…˜ ë””ìì´ë„ˆ ë° ì—”ì§€ë‹ˆì–´ì™€ì˜ ì¸í„°ë·°ë¥¼ í†µí•´ ì–»ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ KeyframerëŠ” ìƒì„±ëœ ê²°ê³¼ë¬¼ì˜ í”„ë¡¬í”„íŠ¸ì™€ ì§ì ‘ í¸ì§‘ì„ ê²°í•©í•˜ì—¬ ì• ë‹ˆë©”ì´ì…˜ì„ íƒìƒ‰í•˜ê³  ë‹¤ë“¬ì„ ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ë˜í•œ ì‚¬ìš©ìê°€ ë””ìì¸ ë³€í˜•ì„ ìš”ì²­í•  ìˆ˜ ìˆì–´ ë¹„êµì™€ ì•„ì´ë””ì–´ ë„ì¶œì„ ì§€ì›í•©ë‹ˆë‹¤. 13ëª…ì˜ ì°¸ê°€ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ì‚¬ìš©ì ì—°êµ¬ë¥¼ í†µí•´ ëª¨ì…˜ì„ ì„¤ëª…í•˜ëŠ” ì˜ë¯¸ë¡ ì  í”„ë¡¬í”„íŠ¸ ìœ í˜• ë¶„ë¥˜ì™€ ì‚¬ìš©ìê°€ ìƒì„±ëœ ì¶œë ¥ì— ë”°ë¼ ì§€ì†ì ìœ¼ë¡œ ëª©í‘œë¥¼ ì¡°ì •í•˜ëŠ” 'ë¶„í•´ëœ' í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ì„ í¬í•¨í•œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì „ëµì˜ íŠ¹ì„±ì„ ë¶„ì„í•˜ê³ , í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì§ì ‘ í¸ì§‘ì„ í†µí•´ ì˜¤ëŠ˜ë‚  ìƒì„± ë„êµ¬ì—ì„œ í”íˆ ì‚¬ìš©ë˜ëŠ” ë‹¨ë°œì„± í”„ë¡¬í”„íŠ¸ ì¸í„°í˜ì´ìŠ¤ ì´ìƒì˜ ë°˜ë³µì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë°©ë²•ì„ ê³µìœ í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì„ í†µí•´ ë‹¤ì–‘í•œ ì‹œì²­ìê°€ ì• ë‹ˆë©”ì´ì…˜ ì œì‘ì— ì°¸ì—¬í•  ìˆ˜ ìˆë„ë¡ LLMì„ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤.

 
##  Audio2Video ëª¨ë¸ì¸ EMO ê²°ê³¼ë¬¼ ê³µê°œ
https://humanaigc.github.io/emote-portrait-alive
ì´ë¯¸ì§€ì™€ ìŒì„± ì˜¤ë””ì˜¤ë¥¼ ì´ìš©í•˜ì—¬ ì˜ìƒì„ ìƒì„±í•˜ëŠ” ëª¨ë¸ì˜ ê²°ê³¼ë¬¼ì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤. 
ê²°ê³¼ë¥¼ ë³´ë©´ ìƒë‹¹íˆ í€„ë¦¬í‹°ê°€ ì¢‹ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆëŠ”ë°ìš”. 
ì´ë¯¸ì§€ í•œ ì¥ìœ¼ë¡œ ì´ëŸ° ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤ëŠ”ê²Œ ì‹ ê¸°í•˜ë„¤ìš”.

##  nvnv-bianca
3ì–µí† í°ìœ¼ë¡œ í•™ìŠµì‹œí‚¨ í•œêµ­ì–´ ì†Œì„¤ AIì…ë‹ˆë‹¤.
https://huggingface.co/instructkr/nvnv-bianca
10.8b ì•¼ë†€ìì˜ EEVE ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì œì‘ë˜ì—ˆìœ¼ë©°, 8k ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
ì—¬ëŸ¬ ë²ˆ ì‚¬ìš© í•´ë³¸ ê²°ê³¼ ë§¥ë½ì„ ì˜ ì‡ê³  ë¬˜ì‚¬ ëŠ¥ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.
eos í† í° ë¹„í™œì„±í™” ì‹œí‚¨ í›„ ì‚¬ìš©í•´ì•¼ ë”ìš± í¸ë¦¬í•©ë‹ˆë‹¤.

## Phind-70B ê³µê°œ - GPT-4 Turboì™€ ì½”ë“œ í’ˆì§ˆ ê²©ì°¨ë¥¼ ì¤„ì´ë©´ì„œ 4ë°° ë¹ ë¥¸ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª¨ë¸ 
- ì´ˆë‹¹ ìµœëŒ€ 80ê°œì˜ í† í°ì„ ì²˜ë¦¬(GPT-4 TurboëŠ” ì´ˆë‹¹ ~20í† í°)
32K í† í° ìœˆë„ìš°ë¥¼ ì§€ì›
CodeLlama-70B ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ì ì¸ 50B í† í°ìœ¼ë¡œ íŒŒì¸íŠœë‹ë¨
HumanEval ì—ì„œ 82.3%ë¥¼ ê¸°ë¡í•´ì„œ 81%ì¸ GPT-4 Turbo(gpt-3-0125-preview)ë¥¼ ìƒíšŒí•¨
Metaì˜ CRUXEval ì—ì„œëŠ” 59%ë¡œ GPT-4ì˜ 62%ì— ì¡°ê¸ˆ ëª» ë¯¸ì¹¨
ì½”ë“œìƒì„± ì¸¡ë©´ì—ì„œëŠ” ê±°ì˜ GPT-4 Turboì™€ ë™ì¼í•˜ê±°ë‚˜ ì¼ë¶€ ì‘ì—…ì—ì„œëŠ” ì´ë¥¼ ëŠ¥ê°€
GPT-4 Turbo ë³´ë‹¤ ëœ "Lazy" í•´ì„œ ìƒì„¸í•œ ì½”ë“œ ì˜ˆì œë¥¼ ìƒì„±í•˜ëŠ”ë° ì£¼ì €í•˜ì§€ ì•ŠìŒ
phind.com
## Lumiere is a space-time diffusion research model 
generates video from various inputs, including image-to-video. The model generates videos that start with the desired first frame & exhibit intricate coherent motion across the entire video duration.
Website: https://lumiere-video.github.io/
Paper: https://arxiv.org/abs/2401.12945
YouTube: https://www.youtube.com/watch?v=wxLr02Dz2Sc

## STMC can generate 3D human motion from text with multi-track timeline control!
https://twitter.com/dreamingtulpa/status/1749778661517959324
https://mathis.petrovich.fr/stmc/?ref=aiartweekly

## The usual RAG approach struggles with retrieval accuracy when faced with massive indistinguishable documents comprising text, tables, and images.
- https://arxiv.org/pdf/2402.01767.pdf
- https://github.com/TebooNok/HiQA

## MetaVoice-1B
MetaVoice-1B is a 1.2B parameter base model trained on 100K hours of speech for TTS (text-to-speech). It has been built with the following priorities:
https://github.com/metavoiceio/metavoice-src 

## CodeLlama-70B PostgreSQLã€SQLCoder-70Bã€‚
https://huggingface.co/defog/sqlcoder-70b-alpha

## Argmax presents WhisperKit
https://huggingface.co/argmaxinc/whisperkit-coreml

## Awesome-Graph-LLM
ê·¸ë˜í”„ ê¸°ë°˜ ê¸°ë²•ê³¼ LLMê³¼ ê´€ë ¨ëœ ì—°êµ¬ ë…¼ë¬¸ì˜ íë ˆì´ì…˜ ëª©ë¡ ì €ì¥ì†Œ.
https://github.com/XiaoxinHe/Awesome-Graph-LLM

## codelaama2
quantized CodeLlama 70b Instruct to 4-bit with MLX
[https://huggingface.co/.../CodeLlama-70b-Instruct-hf-4bit...
](https://huggingface.co/mlx-community/CodeLlama-70b-Instruct-hf-4bit-MLX?fbclid=IwAR0KYHovfFxB87OvVg55RLkIre4N0JfQbi0fPYbemZDJQ3K8Ka-fZnKM4sA)
## Towards Conversational Diagnostic AI

ì˜ë£Œì˜ í•µì‹¬ì€ ì˜ì‚¬ì™€ í™˜ì ê°„ì˜ ëŒ€í™”ì´ë©°, ìˆ™ë ¨ëœ ë³‘ë ¥ ì²­ì·¨ëŠ” ì •í™•í•œ ì§„ë‹¨, íš¨ê³¼ì ì¸ ê´€ë¦¬, ì§€ì†ì ì¸ ì‹ ë¢°ì˜ í† ëŒ€ê°€ ë©ë‹ˆë‹¤. 
ì§„ë‹¨ ëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥(AI) ì‹œìŠ¤í…œì€ ì ‘ê·¼ì„±, ì¼ê´€ì„±, ì¹˜ë£Œì˜ ì§ˆì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
í•˜ì§€ë§Œ ì„ìƒì˜ì˜ ì „ë¬¸ ì§€ì‹ì— ê·¼ì ‘í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. 
ì—¬ê¸°ì—ì„œëŠ” ì§„ë‹¨ ëŒ€í™”ì— ìµœì í™”ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ AI ì‹œìŠ¤í…œì¸ AMIE(Articulate Medical Intelligence Explorer)ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. 
AMIEëŠ” ë‹¤ì–‘í•œ ì§ˆë³‘ ìƒíƒœ, ì „ë¬¸ ë¶„ì•¼ ë° ìƒí™©ì— ë”°ë¼ í•™ìŠµì„ í™•ì¥í•˜ê¸° ìœ„í•´ ìë™í™”ëœ í”¼ë“œë°± ë©”ì»¤ë‹ˆì¦˜ì„ ê°–ì¶˜ ìƒˆë¡œìš´ ì…€í”„ í”Œë ˆì´ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 
ë³‘ë ¥ ì²­ì·¨, ì§„ë‹¨ ì •í™•ë„, ê´€ë¦¬ ì¶”ë¡ , ì˜ì‚¬ì†Œí†µ ê¸°ìˆ , ê³µê° ëŠ¥ë ¥ ë“± ì„ìƒì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì„±ê³¼ ì¶•ì„ í‰ê°€í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤. 
ê°ê´€ì  êµ¬ì¡°í™” ì„ìƒì‹œí—˜(OSCE) ë°©ì‹ìœ¼ë¡œ ê²€ì¦ëœ í™˜ì í–‰ìœ„ìì™€ì˜ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒë‹´ì— ëŒ€í•œ ë¬´ì‘ìœ„ ì´ì¤‘ë§¹ê²€ êµì°¨ ì—°êµ¬ë¥¼ í†µí•´ AMIEì˜ ì„±ê³¼ë¥¼ 1ì°¨ ì§„ë£Œ ì˜ì‚¬(PCP)ì˜ ì„±ê³¼ì™€ ë¹„êµí–ˆìŠµë‹ˆë‹¤.
ì´ ì—°êµ¬ì—ëŠ” ìºë‚˜ë‹¤, ì˜êµ­, ì¸ë„ì˜ ì„ìƒ ì œê³µìê°€ ì œê³µí•œ 149ê°œì˜ ì‚¬ë¡€ ì‹œë‚˜ë¦¬ì˜¤, AMIEì™€ ë¹„êµí•˜ê¸° ìœ„í•œ 20ê°œì˜ PCP, ì „ë¬¸ ì˜ì‚¬ì™€ í™˜ì ë°°ìš°ì˜ í‰ê°€ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.
ì „ë¬¸ ì˜ì‚¬ê°€ í‰ê°€í•œ 32ê°œ ì¶• ì¤‘ 28ê°œ ì¶•, í™˜ì í–‰ìœ„ìê°€ í‰ê°€í•œ 26ê°œ ì¶• ì¤‘ 24ê°œ ì¶•ì—ì„œ AMIEê°€ ë” ë†’ì€ ì§„ë‹¨ ì •í™•ë„ì™€ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.
ì´ë²ˆ ì—°êµ¬ì—ëŠ” ëª‡ ê°€ì§€ í•œê³„ê°€ ìˆìœ¼ë¯€ë¡œ ì ì ˆí•œ ì£¼ì˜ë¥¼ ê¸°ìš¸ì—¬ í•´ì„í•´ì•¼ í•©ë‹ˆë‹¤. 
ì„ìƒì˜ë“¤ì€ ìµìˆ™í•˜ì§€ ì•Šì€ ë™ê¸°ì‹ í…ìŠ¤íŠ¸ ì±„íŒ…ìœ¼ë¡œ ì œí•œë˜ì—ˆìœ¼ë©°, ì´ëŠ” ëŒ€ê·œëª¨ì˜ LLM-í™˜ì ìƒí˜¸ì‘ìš©ì„ í—ˆìš©í•˜ì§€ë§Œ ì¼ë°˜ì ì¸ ì„ìƒ ì‹¤ìŠµì„ ëŒ€í‘œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
AMIEë¥¼ ì‹¤ì œ í™˜ê²½ì— ì ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë” ë§ì€ ì—°êµ¬ê°€ í•„ìš”í•˜ì§€ë§Œ, ì´ë²ˆ ì—°êµ¬ ê²°ê³¼ëŠ” ëŒ€í™”í˜• ì§„ë‹¨ AIë¥¼ í–¥í•œ ì´ì •í‘œê°€ ë  ê²ƒì…ë‹ˆë‹¤.
- Blog: https://blog.research.google/2024/01/amie-research-ai-system-for-diagnostic_12.html
- arXiv: https://arxiv.org/abs/2401.05654
- Browse: https://browse.arxiv.org/pdf/2401.05654.pdf
- PDF: https://arxiv.org/pdf/2401.05654.pdf  
- arXiv-vanity: https://www.arxiv-vanity.com/papers/2401.05654 
- Paper page: https://huggingface.co/papers/2401.05654 
- HTML : https://browse.arxiv.org/html/2401.05654v1 
- Papers with code: https://paperswithcode.com/paper/towards-conversational-diagnostic-ai

## Introducing DeepSeekMoE
https://github.com/deepseek-ai/DeepSeek-MoE

## Transformers are Multi-State RNNs
ë…¼ë¬¸ ì´ˆë¡
íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì´ì „ ì„¸ëŒ€ì˜ ìµœì²¨ë‹¨ ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸ì¸ ìˆœí™˜ ì‹ ê²½ë§(RNN)ê³¼ ë¹„êµí–ˆì„ ë•Œ ê°œë…ì ìœ¼ë¡œ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤. 
ì´ ì—°êµ¬ì—ì„œëŠ” ë””ì½”ë” ì „ìš© íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì‹¤ì œë¡œ ë¬´í•œ ë‹¤ì¤‘ ìƒíƒœ RNN, ì¦‰ ìˆ¨ê²¨ì§„ ìƒíƒœ í¬ê¸°ê°€ ë¬´ì œí•œì¸ RNN ë³€í˜•ìœ¼ë¡œ ê°œë…í™”ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. 
ë˜í•œ ìˆ¨ê²¨ì§„ ìƒíƒœì˜ í¬ê¸°ë¥¼ ê³ ì •í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ìœ í•œ ë‹¤ì¤‘ ìƒíƒœ RNNìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. 
ê¸°ì¡´ì˜ ì—¬ëŸ¬ íŠ¸ëœìŠ¤í¬ë¨¸ ìºì‹œ ì••ì¶• ê¸°ë²•ì´ ì´ëŸ¬í•œ ë³€í™˜ ì •ì±…ìœ¼ë¡œ êµ¬ì„±ë  ìˆ˜ ìˆìŒì„ ê´€ì°°í•˜ê³ , ì´ëŸ¬í•œ ì •ì±…ê³¼ ë¹„êµí•˜ì—¬ ë” ê°„ë‹¨í•œ ìƒˆë¡œìš´ ì •ì±…ì¸ TOVAë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. 
ëª‡ ê°€ì§€ ì¥ê±°ë¦¬ ì‘ì—…ì— ëŒ€í•œ ì‹¤í—˜ ê²°ê³¼, TOVAëŠ” ë‹¤ë¥¸ ëª¨ë“  ê¸°ë³¸ ì •ì±…ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë©´ì„œë„ ì „ì²´(ë¬´í•œ) ëª¨ë¸ê³¼ ê±°ì˜ ë™ë“±í•˜ê³  ê²½ìš°ì— ë”°ë¼ì„œëŠ” ì›ë˜ ìºì‹œ í¬ê¸°ì˜ 18ê°œë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. 
ì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´ íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” LLMì´ ì‹¤ì œë¡œëŠ” RNNì²˜ëŸ¼ ì‘ë™í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. 
ë˜í•œ ê°€ì¥ ê³¨ì¹˜ ì•„í”ˆ ê³„ì‚° ë³‘ëª© í˜„ìƒ ì¤‘ í•˜ë‚˜ì¸ ìºì‹œ ë©”ëª¨ë¦¬ í¬ê¸°ë¥¼ ì™„í™”í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ë„ ì œì‹œí•©ë‹ˆë‹¤.
ë…¼ë¬¸ https://arxiv.org/abs/2401.06104

## ì—…ìŠ¤í…Œì´ì§€ì˜ ì†”ë¼ ë…¼ë¬¸
32ì¸µ ê¸°ë³¸ ëª¨ë¸ì—ì„œ ì‹œì‘í•˜ì—¬, ì´ ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ë³µì œí•˜ì—¬ ì—°ê²°í•¨ìœ¼ë¡œì¨ 48ì¸µì˜ í™•ì¥ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ (Depth Up-Scaling ë¼ê³  ëª…ëª…)

[ëª¨ë¸ êµ¬ì¡°]
1. 32 layer Llama 2 architecture with Mistral 7B pretrained weights
2. ë‹¨ìˆœ ë³µì œí•˜ì—¬ 2ê°œ ì„¸íŠ¸ ìƒì„±
3. ì²«ë²ˆì§¸ ì„¸íŠ¸ì˜ ë 8 layer, ë‘ë²ˆì§¸ ì„¸íŠ¸ì˜ ì²˜ìŒ 8 layerë¥¼ ì˜ë¼ëƒ„ -> 24 layer * 2 model
4. í•©ì³ì„œ 48 layer (10.7 billion parameters)

[í•™ìŠµ ë°©ë²•]
1. Instruction Tuning: QA í¬ë§· í•™ìŠµ (ì˜¤í”ˆì†ŒìŠ¤ + í•©ì„± math QA ë°ì´í„°)
2. Alignment Tuning: DPO ê¸°ë°˜ íŠœë‹ ( {prompt, chosen, rejected} tupleë¡œ ë§Œë“¤ì–´ì„œ DPO ì§„í–‰)
3. Model Merging: ë‹¨ìˆœ weight í‰ê· ê³¼ SLERP í™œìš©
 
## Starling-7b-alpha (@BanghuaZet al.) is a new 7B LLM 
uses a brand-new reward model and policy optimization method. 
it approaches GPT-4 in perf on MT Bench, MMLU, and more (beating Claude, 3.5, etc.)
https://twitter.com/jerryjliu0/status/1735842203241759099
[https://docs.llamaindex.ai/models/llms.html
](https://docs.llamaindex.ai/en/latest/module_guides/models/llms.html?fbclid=IwAR3QgJYKlQ7cINcA5xHh4P9fue8jNPEs1f0w99ocizRV2bLupnCDn-zS4lA#open-source-llms)

## Local RAG on Windows
https://twitter.com/llama_index/status/1736429047956349058
https://github.com/marklysze/LlamaIndex-RAG-WSL-CUDA

## Towards LangChain 0.1: LangChain-Core and LangChain-Community
https://twitter.com/LangChainAI/status/1734641665556857148
[https://blog.langchain.dev/the-new-langchain.../
](https://blog.langchain.dev/the-new-langchain-architecture-langchain-core-v0-1-langchain-community-and-a-path-to-langchain-v0-1/?fbclid=IwAR2DDz1sTB97NaUt2PX-0nJuDG4g0oQ6LdBbJeww4BN8QRc51uSCmCyMvCY)

## MLC LLM

Documentation | Blog | Discord

Machine Learning Compilation for Large Language Models (MLC LLM) is a high-performance universal deployment solution that allows native deployment of any l
arge language models with native APIs with compiler acceleration. The mission of this project is to enable everyone to develop, optimize and deploy AI models natively on everyone's devices with ML compilation techniques.

https://github.com/mlc-ai/mlc-llm

## Pipegoose: end-to-end framework for training multi-modal MoE in a decentralized way. (DiLoCo)[https://arxiv.org/abs/2311.08105]ë¥¼ replicateí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸
Repo: https://github.com/xrsrke/pipegoose

## MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers

ë“œë””ì–´ ë‚˜ì˜¬ ê²Œ ë‚˜ì˜¤ëŠ”êµ°ìš”.

3D ë©”ì‰¬ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. GPTì²˜ëŸ¼ Transformer ì˜ ë””ì½”ë“œ ë¶€ë¶„ë§Œ ì‚¬ìš©í–ˆë‹µë‹ˆë‹¤.

"MeshGPTëŠ” í•™ìŠµëœ ê¸°í•˜í•™ì  ì–´íœ˜ì—ì„œ í† í°ì„ ìƒì„±í•˜ë„ë¡ í›ˆë ¨ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì—ì„œ ìë™íšŒê·€ì ìœ¼ë¡œ ìƒ˜í”Œë§í•˜ì—¬ ì‚¼ê°í˜• ë©”ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ëŸ¬í•œ í† í°ì„ íŠ¸ë¼ì´ì•µê¸€ ë©”ì‹œì˜ ë©´ìœ¼ë¡œ ë””ì½”ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì„ ëª…í•œ ëª¨ì„œë¦¬ì™€ ë†’ì€ ì¶©ì‹¤ë„ê°€ íŠ¹ì§•ì¸ ê¹¨ë—í•˜ê³  ì¼ê´€ì„± ìˆìœ¼ë©° ì»´íŒ©íŠ¸í•œ ë©”ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."

í”„ë¡œì íŠ¸ https://nihalsid.github.io/mesh-gpt/
## Gemini 

Welcome to the Gemini era
https://deepmind.google/technologies/gemini
Introducing Gemini: our largest and most capable AI model
https://blog.google/technology/ai/google-gemini-ai/
Enabling next-generation AI workloads: Announcing TPU v5p and AI Hypercomputer
https://cloud.google.com/.../introducing-cloud-tpu-v5p...
1. Testing Gemini: Finding connections: https://www.youtube.com/watch?v=Rn30RMhEBTs
2. Hands-on with Gemini: Interacting with multimodal AI: https://www.youtube.com/watch?v=UIZAiXYceBI
3. Gemini: Googleâ€™s newest and most capable AI model: https://www.youtube.com/watch?v=jV1vkHv4zq8
4. Testing Gemini: Turning images into code: https://www.youtube.com/watch?v=NHLnjWTEZps
5. Testing Gemini: Emoji Kitchen: https://www.youtube.com/watch?v=ki8kRJPXCW0
6. Gemini: All you need to know in 90 seconds: https://www.youtube.com/watch?v=_TVnM9dmUSk
7. Testing Gemini: Understanding environments: https://www.youtube.com/watch?v=JPwU1FNhMOA
8. Gemini: Explaining reasoning in math and physics: https://www.youtube.com/watch?v=K4pX1VAxaAI
9. Gemini: Excelling at competitive programming: https://www.youtube.com/watch?v=LvGmVmHv69s
10. Testing Gemini: Fit check: https://www.youtube.com/watch?v=HP2pNdCRT5M
11. Gemini: Processing and understanding raw audio: https://www.youtube.com/watch?v=D64QD7Swr3s
12. Testing Gemini: Guess the movie: https://www.youtube.com/watch?v=aRyuMNwn02w
13. Mark Rober takes Bard with Gemini Pro for a test flight: https://www.youtube.com/watch?v=mHZSrtl4zX0
14. Gemini: Safety and responsibility at the core: https://www.youtube.com/watch?v=gi6J_WjjNhE
15. Gemini: Reasoning about user intent to generate bespoke experiences: https://www.youtube.com/watch?v=v5tRc_5-8G4
16. Gemini: Unlocking insights in scientific literature: https://www.youtube.com/watch?v=sPiOP_CB54A
17. Using AI to Improve Students writing skills Quill.org x Google.org: https://www.youtube.com/watch?v=f0pMe4aFXx0

## Information Retrieval:  Who wins, GPT-4-Turbo or a RAG based on GPT4?
https://github.com/A-Roucher/LLM_vs_RAG_NeedleInAHaystack

## MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers

ë“œë””ì–´ ë‚˜ì˜¬ ê²Œ ë‚˜ì˜¤ëŠ”êµ°ìš”.

3D ë©”ì‰¬ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. GPTì²˜ëŸ¼ Transformer ì˜ ë””ì½”ë“œ ë¶€ë¶„ë§Œ ì‚¬ìš©í–ˆë‹µë‹ˆë‹¤.

"MeshGPTëŠ” í•™ìŠµëœ ê¸°í•˜í•™ì  ì–´íœ˜ì—ì„œ í† í°ì„ ìƒì„±í•˜ë„ë¡ í›ˆë ¨ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì—ì„œ ìë™íšŒê·€ì ìœ¼ë¡œ ìƒ˜í”Œë§í•˜ì—¬ ì‚¼ê°í˜• ë©”ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ëŸ¬í•œ í† í°ì„ íŠ¸ë¼ì´ì•µê¸€ ë©”ì‹œì˜ ë©´ìœ¼ë¡œ ë””ì½”ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì„ ëª…í•œ ëª¨ì„œë¦¬ì™€ ë†’ì€ ì¶©ì‹¤ë„ê°€ íŠ¹ì§•ì¸ ê¹¨ë—í•˜ê³  ì¼ê´€ì„± ìˆìœ¼ë©° ì»´íŒ©íŠ¸í•œ ë©”ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."

í”„ë¡œì íŠ¸ https://nihalsid.github.io/mesh-gpt/

## Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis
ìš”ì•½: 
ëŒ€ê·œëª¨ ê¸°ë°˜ ëª¨ë¸ì— í˜ì…ì–´ ì¸ê³µì§€ëŠ¥ì˜ ê°œë°œì€ ìµœê·¼ ì—„ì²­ë‚œ ì§„ì „ì„ ì´ë£¨ì—ˆìœ¼ë©°, ëŒ€ì¤‘ì˜ ê´€ì‹¬ì´ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” íŠ¹íˆ ë©€í‹°ëª¨ë‹¬ ì˜ë£Œ ì§„ë‹¨ ì˜ì—­ì—ì„œ OpenAIì˜ ìµœì‹  ëª¨ë¸ì¸ GPT-4V(ision)ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. í‰ê°€ ëŒ€ìƒì€ ì¤‘ì¶”ì‹ ê²½ê³„, ë‘ê²½ë¶€, ì‹¬ì¥, í‰ë¶€, í˜ˆì•¡í•™, ê°„ë‹´ë„, ìœ„ì¥, ë¹„ë‡¨ìƒì‹ê¸°, ë¶€ì¸ê³¼, ì‚°ë¶€ì¸ê³¼, ìœ ë°©, ê·¼ê³¨ê²©ê³„, ì²™ì¶”, í˜ˆê´€, ì¢…ì–‘í•™, ì™¸ìƒ, ì†Œì•„ê³¼ ë“± 17ê°œ ì¸ì²´ ì‹œìŠ¤í…œìœ¼ë¡œ, ì¼ìƒì ì¸ ì„ìƒì—ì„œ ì‚¬ìš©ë˜ëŠ” 8ê°œ ëª¨ë‹¬ë¦¬í‹°ì—ì„œ ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤, ì—‘ìŠ¤ë ˆì´, ì»´í“¨í„° ë‹¨ì¸µ ì´¬ì˜(CT), ìê¸° ê³µëª… ì˜ìƒ(MRI), ì–‘ì „ì ë°©ì¶œ ë‹¨ì¸µ ì´¬ì˜(PET), ë””ì§€í„¸ ê°ì‚° í˜ˆê´€ ì¡°ì˜ìˆ (DSA), ìœ ë°© ì¡°ì˜ìˆ , ì´ˆìŒíŒŒ ë° ë³‘ë¦¬í•™. ìš°ë¦¬ëŠ” ì˜ìƒ ì–‘ì‹ ë° í•´ë¶€í•™ ì¸ì‹, ì§ˆë³‘ ì§„ë‹¨, ë³´ê³ ì„œ ìƒì„±, ì§ˆë³‘ ìœ„ì¹˜ íŒŒì•… ë“± ë‹¤ì–‘í•œ ì„ìƒ ì‘ì—…ì—ì„œ íŠ¹í—ˆ ì´ë ¥ ì œê³µ ì—¬ë¶€ì— ê´€ê³„ì—†ì´ GPT-4Vì˜ ëŠ¥ë ¥ì„ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤.
ì—°êµ¬ ê²°ê³¼ì— ë”°ë¥´ë©´ GPT-4VëŠ” ì˜ë£Œ ì˜ìƒ ì–‘ì‹ê³¼ í•´ë¶€í•™ì„ êµ¬ë¶„í•˜ëŠ” ë°ëŠ” ëŠ¥ìˆ™í•˜ì§€ë§Œ ì§ˆë³‘ ì§„ë‹¨ê³¼ ì¢…í•©ì ì¸ ë³´ê³ ì„œ ìƒì„±ì—ëŠ” ìƒë‹¹í•œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì´ ì»´í“¨í„° ë¹„ì „ê³¼ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ìƒë‹¹í•œ ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ì‹¤ì œ ì˜ë£Œ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ì„ìƒ ì˜ì‚¬ ê²°ì •ì„ íš¨ê³¼ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ë°ëŠ” ì•„ì§ ë©€ì—ˆë‹¤ëŠ” ì ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
arXiv: https://arxiv.org/abs/2310.09909
Browse: https://browse.arxiv.org/pdf/2310.09909.pdf
PDF: https://arxiv.org/pdf/2310.09909.pdf  
Paper page: https://huggingface.co/papers/2310.09909 
Papers with code: https://huggingface.co/papers/2310.09909
GitHub: https://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation

##  A Survey of Large Language Models in Medicine: Progress, Application, and Challenge
ìš”ì•½: 
ChatGPTì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¸ìƒì ì¸ ì¸ê°„ ì–¸ì–´ ì´í•´ ë° ìƒì„± ëŠ¥ë ¥ìœ¼ë¡œ ì¸í•´ ìƒë‹¹í•œ ì£¼ëª©ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì˜ì‚¬ì™€ í™˜ì ì¹˜ë£Œë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ ì˜ë£Œ ë¶„ì•¼ì—ì„œ LLMì„ ì ìš©í•˜ëŠ” ê²ƒì€ ì¸ê³µì§€ëŠ¥ê³¼ ì„ìƒì˜í•™ ëª¨ë‘ì—ì„œ ìœ ë§í•œ ì—°êµ¬ ë°©í–¥ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë³¸ ì¡°ì‚¬ ì—°êµ¬ì—ì„œëŠ” ì˜í•™ ë¶„ì•¼ì—ì„œì˜ ì¸ê³µì‹ ê²½ë§ì˜ í˜„ì¬ ì§„í–‰ ìƒí™©, ì‘ìš© ë¶„ì•¼, ì§ë©´í•œ ê³¼ì œì— ëŒ€í•œ í¬ê´„ì ì¸ ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„ ë‹¤ë£¨ê³ ì í•©ë‹ˆë‹¤: 1) LLMì´ë€ ë¬´ì—‡ì´ë©° ì˜ë£Œìš© LLMì€ ì–´ë–»ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ”ê°€? 2) ì˜ë£Œìš© LLMì˜ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì„±ê³¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”? 3) ì˜ë£Œìš© LLMì€ ì‹¤ì œ ì„ìƒì—ì„œ ì–´ë–»ê²Œ í™œìš©ë  ìˆ˜ ìˆë‚˜ìš”? 4) ì˜ë£Œìš© LLMì„ ì‚¬ìš©í•  ë•Œ ì–´ë–¤ ë¬¸ì œê°€ ë°œìƒí•˜ë‚˜ìš”? 5) ì–´ë–»ê²Œ í•˜ë©´ ì˜ë£Œìš© LLMì„ ë” ì˜ êµ¬ì¶•í•˜ê³  í™œìš©í•  ìˆ˜ ìˆì„ê¹Œìš”? ê²°ê³¼ì ìœ¼ë¡œ ì´ ì¡°ì‚¬ ì—°êµ¬ëŠ” ì˜í•™ ë¶„ì•¼ì—ì„œ LLMì˜ ê¸°íšŒì™€ ë„ì „ ê³¼ì œì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ê³  ì‹¤ìš©ì ì´ê³  íš¨ê³¼ì ì¸ ì˜í•™ LLMì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ê·€ì¤‘í•œ ë¦¬ì†ŒìŠ¤ë¡œ í™œìš©ë˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ì •ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ì˜ë£Œ LLMì˜ ì‹¤ìš©ì ì¸ ê°€ì´ë“œ ë¦¬ì†ŒìŠ¤ ëª©ë¡ì€ ë‹¤ìŒ https URLì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

arXiv: https://arxiv.org/abs/2311.05112
Browse: https://browse.arxiv.org/pdf/2311.05112.pdf
PDF: https://arxiv.org/pdf/2311.05112.pdf  

## KoLLM-LogBook 
 í° ì£¼ëª©ì„ ë°›ê³  ìˆëŠ” "OpenHermes-2-Mistral-7B" ëª¨ë¸ì„ ê°œë°œí•œ tekniumì˜ "LLM-Logbook" í”„ë¡œì íŠ¸ì˜ í•œêµ­ì–´ ë²„ì „ì…ë‹ˆë‹¤.
 ì£¼ìš” ëª©í‘œëŠ” Multiple-Choice Question Answering (MCQA)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì–¸ì–´ëª¨ë¸ í‰ê°€ ë°©ë²•ë¡ ì„ ë„˜ì–´ì„œ, ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì–¸ì–´ëª¨ë¸ì˜ ìƒì„±ê²°ê³¼ë¥¼ ì§ì ‘ ë¹„êµí•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ 100ê°œì˜ í”„ë¡¬í”„íŠ¸ì™€ ì„œë¡œ ë‹¤ë¥¸ ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ë‹µë³€ì„ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.
KoLLM-LogBookì—ëŠ” ê¸ˆìœµ, ìˆ˜í•™, ì˜í•™, í”„ë¡œê·¸ë˜ë°, ì°½ì‘ ê¸€ì“°ê¸° ë“± ì´ 15ê°œ ë¶„ì•¼ì—ì„œ ì œì‘í•œ 100ê°œì˜ í”„ë¡¬í”„íŠ¸ì™€ ë‹¤ì–‘í•œ ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ì‘ë‹µì´ ìˆ˜ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
í˜„ì¬ í”„ë¡œì íŠ¸ì—ëŠ” ë‹¤ìŒ 4ê°œì˜ ëª¨ë¸ ê²°ê³¼ê°€ í¬í•¨
amphora/small-instruct
kyujinpy/KoR-Orca-Platypus-13B
krevas/LDCC-Instruct-Llama-2-ko-13B-v4
gpt-3.5-turbo-0613
Compare Models í˜ì´ì§€ ì—ì„œëŠ” ë™ì¼ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì˜ ë‹µë³€ì„ ë¹„êµí•˜ì‹¤ ìˆ˜ ìˆê³ 
Model Reports í˜ì´ì§€ì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ ì „ì²´ì— ëŒ€í•œ ê°œë³„ ëª¨ë¸ì˜ ë‹µë³€ì„ ëª¨ì•„ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶”ê°€í•˜ê³  ì‹¶ìœ¼ì‹  ëª¨ë¸ì´ ìˆìœ¼ì‹œê±°ë‚˜ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ í¸í•˜ê²Œ ì—°ë½ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
github: https://github.com/guijinSON/KoLLM-LogBook/tree/main
streamlit: https://kollm-logbook-qqw6uzf89xizxjilkihjsh.streamlit.app/

## í•´ë¦¬í¬í„°ê°€ ëˆ„êµ¬? MS, AI í•™ìŠµ ë°ì´í„° ì¤‘ íŠ¹ì • ì •ë³´ ì‚­ì œ ê¸°ìˆ  ê³µê°œ
ì €ì‘ê¶Œ ë¬¸ì œ ë“±ì— í° í•´ê²°ì±… ë  ê²ƒ
ì¸ê³µì§€ëŠ¥(AI)ì´ í•™ìŠµí•œ ë°ì´í„° ì¤‘ ë¬¸ì œê°€ ìˆëŠ” ì¼ë¶€ë¶„ë§Œ ì‚­ì œí•  ìˆ˜ ìˆëŠ” ê¸°ìˆ  ê³µê°œ. ë°ì´í„° ì €ì‘ê¶Œ ë¬¸ì œë¡œ ê³¨ë¨¸ë¦¬ë¥¼ ì•“ëŠ” ë¹…í…Œí¬ì— ëŒíŒŒêµ¬ê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ë¶„ì„.
ë²¤ì²˜ë¹„íŠ¸ëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸(MS) ì—°êµ¬ì§„ì´ ëŒ€í˜•ì–¸ì–´ëª¨ë¸(LLM)ì—ì„œ íŠ¹ì • ì •ë³´ë¥¼ ì‚­ì œí•˜ëŠ” ë°©ë²•ì„ ì˜¨ë¼ì¸ ë…¼ë¬¸ ì‚¬ì´íŠ¸ ì•„ì¹´ì´ë¸Œ(arXiv)ì— ê²Œì¬í–ˆë‹¤ê³  ì†Œê°œ
MS ì• ì € ì—°êµ¬ì›ì€ ë©”íƒ€ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ LLM 'ë¼ë§ˆ 2 7B' ëª¨ë¸ì— í¬í•¨ëœ í•´ë¦¬í¬í„°ì— ëŒ€í•œ ëª¨ë“  ì§€ì‹ì„ ì‚­ì œí•˜ëŠ” ë° ì„±ê³µ. ë…¼ë¬¸ì˜ ì œëª©ë„ 'í•´ë¦¬ í¬í„°ê°€ ëˆ„êµ¬? ëŒ€ëµì ì¸  LLMì˜ í•™ìŠµ ì·¨ì†Œë²•(Whoâ€™s Harry Potter? Approximate Unlearning in LLMs)'

ë…¼ë¬¸ : https://arxiv.org/abs/2310.02238

## LAVIE: HIGH-QUALITY VIDEO GENERATION WITH CASCADED LATENT DIFFUSION MODELS (2309, Shanghai AI Lab, Nanyang Technological University ì™¸)

ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸-ë¹„ë””ì˜¤(T2V, Text-to-Video) ìƒì„± ëª¨ë¸ë¥¼ ê¸°ë³¸ T2V ëª¨ë¸, ì‹œê°„ ë³´ê°„ ëª¨ë¸, ë¹„ë””ì˜¤ ì´ˆê³ í•´ìƒë„ ëª¨ë¸ë¡œ êµ¬ì„±ëœ ê³„ë‹¨ì‹ ë¹„ë””ì˜¤ ì ë³µ í™•ì‚° ëª¨ë¸ì—ì„œ ì‘ë™í•˜ëŠ” í†µí•© ë¹„ë””ì˜¤ ìƒì„± í”„ë ˆì„ì›Œí¬ ì œì•ˆ, ì‹¤í—˜ì„ í†µí•´ LaVieê°€ ì–‘ì , ì§ˆì ìœ¼ë¡œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ë‹¬ì„±

project : [https://vchitect.github.io/LaVie-project/](https://vchitect.github.io/LaVie-project/?fbclid=IwAR2_AuNSz7ZqIklzCoNqoS1J2mWqf-E8q3Ox4ybcVyEtZGuVh3EiNOYKPnk)

## 2.6ì¡° í† í°ìœ¼ë¡œ í›ˆë ¨ëœ 130ì–µ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ë‹¤êµ­ì–´ ëª¨ë¸ 'Baichuan 2'
Baichuan 2: Open Large-scale Language Models : https://arxiv.org/abs/2309.10305v2 , Baichuan

```
ë³¸ ì—°êµ¬ì—ì„œëŠ” ë‹¤êµ­ì–´ë¥¼ ì§€ì›í•˜ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ Baichuan 2ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. Baichuan 2ëŠ” 7B(70ì–µ ë§¤ê°œë³€ìˆ˜)ì™€ 13B(130ì–µ ë§¤ê°œë³€ìˆ˜)ì˜ ë‘ ê°€ì§€ ëª¨ë¸ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ì „ë¡€ ì—†ëŠ” ê·œëª¨ì¸ 2.6ì¡° í† í°ì— ì˜í•´ í›ˆë ¨ë˜ê³  ìˆë‹¤.
ì´ ëŒ€ëŸ‰ì˜ í›ˆë ¨ ë°ì´í„° ë•ë¶„ì— Baichuan 2ëŠ” ì¼ë°˜ì ì¸ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë¡œ ì´ì „ ë²„ì „ì¸ Baichuan 1ë³´ë‹¤ ì•½ 30% ë†’ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.
íŠ¹íˆ Baichuan 2ëŠ” ìˆ˜í•™ ë° í”„ë¡œê·¸ë˜ë° ë¬¸ì œì—ì„œë„ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©° ì˜ë£Œ ë° ë²•ë¥ ê³¼ ê°™ì€ ì „ë¬¸ ì˜ì—­ì—ì„œë„ ìš°ìˆ˜í•œ ì„±ì ì„ ë‹¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. Baichuan 2-7B-Chatê³¼ Baichuan 2-13B-Chatì´ë¼ëŠ” ì¸ê°„ì˜ ì§€ì‹œì— ë”°ë¼ ìµœì í™”ëœ ì±„íŒ… ëª¨ë¸ë„ ê³µê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ìƒí˜¸ ì‘ìš©ê³¼ ì»¨í…ìŠ¤íŠ¸ ì´í•´ì— íŠ¹íˆ ìš°ìˆ˜í•©ë‹ˆë‹¤.
ì´ ëª¨ë¸ì€ ê³µê°œëœ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸(MMLU, CMMLU, GSM8K, HumanEval ë“±)ì—ì„œ ê°™ì€ ê·œëª¨ì˜ ë‹¤ë¥¸ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸ê³¼ ë¹„êµí•˜ì—¬ ë™ë“±í•˜ê±°ë‚˜ ê·¸ ì´ìƒì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ ì˜ë£Œ ë° ë²•ë¥  ë“± ì „ë¬¸ ë¶„ì•¼ì—ì„œë„ ë†’ì€ ì„±ì ì„ ì˜¬ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.
ì´ í‰ê°€ ê²°ê³¼ì—ì„œ Baichuan 2ëŠ” ë‹¤êµ­ì–´ ì§€ì›ì´ì§€ë§Œ ë†’ì€ ì„±ëŠ¥ê³¼ ê´‘ë²”ìœ„í•œ ì ìš© ê°€ëŠ¥ì„±ì„ ê°€ì§€ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

## Dense Text-to-Image Generation with Attention Modulation (2308, naver)
ë„¤ì´ë²„, ì´ë¯¸ì§€ ë ˆì´ì•„ì›ƒì„ ë§Œë“¤ê³  ê° í•´ë‹¹ ì˜ì—­ì— í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ í‘œì‹œí•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
 - (ì˜ˆ background: beach, blue skt,  segment1: girl, segment2: chair)
 - ë…¼ë¬¸ : https://arxiv.org/abs/2308.12964
 - ì†ŒìŠ¤ : https://github.com/naver-ai/DenseDiffusion
 - ë‚´ìš©:ë²ˆì—­
```
ê¸°ì¡´ì˜ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ì€ ê° í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ê°€ íŠ¹ì • ì´ë¯¸ì§€ ì˜ì—­ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ê³ ë°€ë„ ìº¡ì…˜ì´ ì£¼ì–´ì§€ë©´ ì‚¬ì‹¤ì ì¸ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.
ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ì‚¬ì „ í•™ìŠµëœ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ì„ ì¡°ì •í•˜ì—¬ ì¥ë©´ ë ˆì´ì•„ì›ƒì„ ì œì–´í•˜ë©´ì„œ ì´ëŸ¬í•œ ê³ ë°€ë„ ìº¡ì…˜ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í•™ìŠµì´ í•„ìš” ì—†ëŠ” ë°©ë²•ì¸ DenseDiffusionì„ ì œì•ˆí•©ë‹ˆë‹¤.
ë¨¼ì € ìƒì„±ëœ ì´ë¯¸ì§€ì˜ ë ˆì´ì•„ì›ƒê³¼ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì˜ ì¤‘ê°„ ì£¼ì˜ë„ ë§µ ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
ê·¸ëŸ° ë‹¤ìŒ ë ˆì´ì•„ì›ƒ ì•ˆë‚´ì— ë”°ë¼ íŠ¹ì • ì˜ì—­ì— ê°ì²´ê°€ ë‚˜íƒ€ë‚˜ë„ë¡ ì•ˆë‚´í•˜ëŠ” ì£¼ì˜ ë³€ì¡° ë°©ë²•ì„ ê°œë°œí•©ë‹ˆë‹¤.
ì¶”ê°€ì ì¸ ë¯¸ì„¸ ì¡°ì •ì´ë‚˜ ë°ì´í„° ì„¸íŠ¸ ì—†ì´ë„ ìë™ ë° ì¸ê°„ í‰ê°€ ì ìˆ˜ ëª¨ë‘ì— ëŒ€í•´ ì¡°ë°€í•œ ìº¡ì…˜ì´ ì£¼ì–´ì¡Œì„ ë•Œ ì´ë¯¸ì§€ ìƒì„± ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤. ë˜í•œ ë ˆì´ì•„ì›ƒ ì¡°ê±´ì— ë”°ë¼ íŠ¹ë³„íˆ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬í•œ í’ˆì§ˆì˜ ì‹œê°ì  ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```

## VideoComposer: Compositional Video Synthesis with Motion Controllability (2306, Alibaba/Ant) 
ì¤‘êµ­ ì•Œë¦¬ë°”ë°”(modelscope)  Image to video , video to video 
ë…¼ë¬¸ : https://arxiv.org/abs/2306.02018
ì‚¬ì´íŠ¸ : https://modelscope.cn/models/damo/Image-to-Video/summary
       https://modelscope.cn/models/damo/Video-to-Video/summary
```
(ë‚´ìš©:ë²ˆì—­) ì‹œê°ì  ì½˜í…ì¸  ì œì‘ì˜ ë†’ì€ ê¸°ì¤€ìœ¼ë¡œ ì œì–´ ê°€ëŠ¥ì„±ì„ ì¶”êµ¬í•˜ë©´ì„œ ë§ì¶¤í˜• ì´ë¯¸ì§€ í•©ì„± ë¶„ì•¼ì—ì„œ ê´„ëª©í•  ë§Œí•œ ë°œì „ì´ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì œì–´ ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ í•©ì„±ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒì€ ì‹œê°„ì  ì—­ë™ì„±ì˜ í° ë³€í™”ì™€ í”„ë ˆì„ ê°„ ì‹œê°„ì  ì¼ê´€ì„±ì˜ ìš”êµ¬ ì‚¬í•­ìœ¼ë¡œ ì¸í•´ ì—¬ì „íˆ ì–´ë ¤ìš´ ê³¼ì œì…ë‹ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” í•©ì„± ìƒì„± íŒ¨ëŸ¬ë‹¤ì„ì— ê¸°ë°˜í•˜ì—¬ í…ìŠ¤íŠ¸ ì¡°ê±´, ê³µê°„ ì¡°ê±´, ë” ë‚˜ì•„ê°€ ì‹œê°„ì  ì¡°ê±´ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ì˜ìƒì„ í•©ì„±í•  ìˆ˜ ìˆëŠ” ë¹„ë””ì˜¤ ì»´í¬ì €(VideoComposer)ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. íŠ¹íˆ, ë¹„ë””ì˜¤ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ ì••ì¶•ëœ ë¹„ë””ì˜¤ì˜ ëª¨ì…˜ ë²¡í„°ë¥¼ ëª…ì‹œì  ì œì–´ ì‹ í˜¸ë¡œ ë„ì…í•˜ì—¬ ì‹œê°„ì  ë™ì—­í•™ì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ ìˆœì°¨ì  ì…ë ¥ì˜ ê³µê°„ì , ì‹œê°„ì  ê´€ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ê¸° ìœ„í•œ í†µí•© ì¸í„°í˜ì´ìŠ¤ ì—­í• ì„ í•˜ëŠ” ì‹œê³µê°„ ì¡°ê±´ ì¸ì½”ë”(STC-encoder)ë¥¼ ê°œë°œí•˜ì—¬ ëª¨ë¸ì´ ì‹œê°„ì  ì¡°ê±´ì„ ë” ì˜ í™œìš©í•˜ê³  í”„ë ˆì„ ê°„ ì¼ê´€ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ ê²°ê³¼ì— ë”°ë¥´ë©´ VideoComposerëŠ” í…ìŠ¤íŠ¸ ì„¤ëª…, ìŠ¤ì¼€ì¹˜ ì‹œí€€ìŠ¤, ì°¸ì¡° ë¹„ë””ì˜¤ ë˜ëŠ” ë‹¨ìˆœíˆ ì†ìœ¼ë¡œ ë§Œë“  ëª¨ì…˜ê³¼ ê°™ì€ ë‹¤ì–‘í•œ í˜•íƒœë¡œ í•©ì„±ëœ ë¹„ë””ì˜¤ ë‚´ì—ì„œ ê³µê°„ ë° ì‹œê°„ íŒ¨í„´ì„ ë™ì‹œì— ì œì–´í•  ìˆ˜ ìˆëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
```

*ì´ì œ ì¤‘êµ­ ì•Œë¦¬ë°”ë°”ëŠ” text to image Zeroscope ì— ì´ì–´ image to video, video to video ëª¨ë‘ ê°–ì¶”ê²Œ ë˜ì—ˆë„¤ìš”

## Meta, SeamlessM4T : ìµœì´ˆ, ì˜¬ì¸ì›, ìŒì„±/í…ìŠ¤íŠ¸ multimodal ë²ˆì—­ ëª¨ë¸
ìµœì²¨ë‹¨ ìµœê³ (state-of-the-art) ê²°ê³¼ë¬¼ë¡œ ì´ì „ ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ìŒì„±/í…ìŠ¤íŠ¸ ë²ˆì—­ ë° íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ëª¨ë¸.
ì—¬ëŸ¬ ì–¸ì–´ê°„ êµì°¨ speech-to-text, speech-to-speech, text-to-speech, text-to-text, and speech recognition.  (ì˜ˆ:ì˜ì–´ ìŒì„±ì„ ëŸ¬ì‹œì•„ í…ìŠ¤íŠ¸ë¡œ, ì˜ì–´ ìŒì„±ì„ ëŸ¬ì‹œì•„ ìŒì„±ìœ¼ë¡œ, ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ëŸ¬ì‹œì•„ ìŒì„±ìœ¼ë¡œ, ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ëŸ¬ì‹œì•„ í…ìŠ¤íŠ¸ë¡œ...).
OpenAIì˜ Whisper ì„±ëŠ¥ì„ ì•ì„œ ìµœì²¨ë‹¨ ìµœê³ (state-of-the-art) ë‹¬ì„±.

- 101 languages for speech input.
- 96 Languages for text input/output.
- 35 languages for speech output.

ì†Œê°œ : https://ai.meta.com/blog/seamless-m4t/
      https://ai.meta.com/resources/models-and-libraries/seamless-communication/
  
ë…¼ë¬¸ : https://dl.fbaipublicfiles.com/seamless/seamless_m4t_paper.pdf
ë°ëª¨ : https://seamless.metademolab.com/
      https://huggingface.co/spaces/facebook/seamless_m4t 
github : https://github.com/facebookresearch/seamless_communication

## ì—”ì”¨ì†Œí”„íŠ¸, ìì²´ LLM VARCO ë° ìƒì„± AI VARCO Studio ë°œí‘œ
ì¶œì²˜ : https://ncsoft.github.io/ncresearch/varco-llm/

VARCO LLM
23ë…„8.16 ì¤‘í˜•ëª¨ë¸ 1.3B, 6.4B,13B ì˜¤í”ˆ, í˜„ì¬ê¹Œì§€ ê³µê°œëœ ìœ ì‚¬í•œ í¬ê¸° í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸ë³´ë‹¤ ìµœê³  ì„±ëŠ¥
- 9ì›” ì˜ˆì • 13B í•œêµ­ì–´/ì˜ì–´ ë™ì‹œ í•™ìŠµ ëª¨ë¸, í˜ë¥´ì†Œë‚˜ ê°ì •/ì˜ë„, ë‚´ëŸ¬í‹°ë¸Œ/ê²Œì„ í€˜ìŠ¤íŠ¸ ìƒì„± ì§€ì› ëª¨ë¸
- 11ì›” ì˜ˆì • 52B
- 24ë…„3ì›” ì˜ˆì • 100B ë©€í‹°ëª¨ë‹¬ í…ìŠ¤íŠ¸/ê·¸ë¦¼ ì´í•´ ì‘ë‹µ ì´ˆê±°ëŒ€ ëª¨ë¸
NCìì²´ ì¸í”„ë¼ í™œìš© ì„œë¹„ìŠ¤ ë° AWS í´ë¼ìš°ë“œ SageMaker ì¸í”„ë¼ ì„œë¹„ìŠ¤ ì œê³µ
VARCO Studio
ê±°ëŒ€ ì–¸ì–´ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ìƒì„± AIë¥¼ ë³´ë‹¤ ì‰½ê²Œ í™œìš©í•˜ê¸° ìœ„í•œ ë„
í…ìŠ¤íŠ¸ ìƒì„± ë° ê´€ë¦¬íˆ´(VARCO Text), ì´ë¯¸ì§€ ìƒì„±íˆ´(VARCO Art),ë””ì§€í„¸íœ´ë¨¼ ìƒì„± ë° í¸ì§‘, ìš´ì˜íˆ´(VARCO Human) ë¡œ êµ¬ì„±
í˜„ì¬ ê²Œì„ ì½˜í…ì¸  ê°œë°œì„ ìœ„í•œ ë„êµ¬ë¡œ ì‚¬ìš©ì¤‘ì´ë©°, í–¥í›„ ì¼ë°˜ì¸ë“¤ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•  ì˜ˆì •
VARCO ì†Œê°œ ì„¤ëª… ë™ì˜ìƒ https://youtu.be/sCv4jql5URY

## StabilityAI ì½”ë”© ì§€ì› AI StableCode
```
Stability AIê°€ ì½”ë”©ì„ ìœ„í•œ LLM ìƒì„± AI ì œí’ˆì¸ StableCodeì˜ ì¶œì‹œë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. 
ì´ ì œí’ˆì€ í”„ë¡œê·¸ë˜ë¨¸ì˜ ì¼ìƒ ì—…ë¬´ë¥¼ ì§€ì›í•˜ëŠ” ë™ì‹œì— ê¸°ìˆ ì„ í•œ ë‹¨ê³„ ë” ë°œì „ì‹œí‚¬ ì¤€ë¹„ê°€ ëœ ì‹ ê·œ ê°œë°œìì—ê²Œ í›Œë¥­í•œ í•™ìŠµ ë„êµ¬ë¥¼ ì œê³µí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
StableCodeëŠ” ê°œë°œìì˜ ì½”ë”©ì„ ë•ê¸° ìœ„í•´ ì„¸ ê°€ì§€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°œë°œìì˜ íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ë…íŠ¹í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. 
ê¸°ë³¸ ëª¨ë¸ì€ ë¨¼ì € BigCodeì˜ ìŠ¤íƒ ë°ì´í„°ì„¸íŠ¸(v1.2)ì—ì„œ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì„¸íŠ¸ë¥¼ í•™ìŠµí•œ ë‹¤ìŒ Python, Go, Java, Javascript, C, ë§ˆí¬ë‹¤ìš´, C++ì™€ ê°™ì€ ì¸ê¸° ì–¸ì–´ë¡œ ì¶”ê°€ í•™ìŠµì„ ê±°ì³¤ìŠµë‹ˆë‹¤.
ì´ 560ì–µ ê°œì˜ ì½”ë“œ í† í°ì— ëŒ€í•´ HPC í´ëŸ¬ìŠ¤í„°ì—ì„œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤.
ê¸°ë³¸ ëª¨ë¸ì´ í™•ë¦½ëœ í›„ì—ëŠ” ë³µì¡í•œ í”„ë¡œê·¸ë˜ë° ì‘ì—…ì„ í•´ê²°í•˜ëŠ” ë° ë„ì›€ì´ ë˜ë„ë¡ íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ëª…ë ¹ì–´ ëª¨ë¸ì„ ì¡°ì •í–ˆìŠµë‹ˆë‹¤. 
ì•ŒíŒŒì¹´ í˜•ì‹ì˜ ì•½ 120,000ê°œì˜ ì½”ë“œ ëª…ë ¹ì–´/ì‘ë‹µ ìŒì„ ê¸°ë³¸ ëª¨ë¸ì— í•™ìŠµì‹œì¼œ ì´ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.
StableCodeëŠ” ì½”ë”©ì— ëŒ€í•´ ë” ë§ì´ ë°°ìš°ê³  ì‹¶ì€ ë¶„ë“¤ì—ê²Œ ì´ìƒì ì¸ ë¹Œë”© ë¸”ë¡ì´ë©°, ê¸´ ì»¨í…ìŠ¤íŠ¸ ì°½ ëª¨ë¸ì€ ì‚¬ìš©ìê°€ í•œ ì¤„ ë° ì—¬ëŸ¬ ì¤„ ìë™ ì™„ì„± ì œì•ˆì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì™„ë²½í•œ ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤.
ì´ ëª¨ë¸ì€ í•œ ë²ˆì— í›¨ì”¬ ë” ë§ì€ ì½”ë“œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì–´(ì»¨í…ìŠ¤íŠ¸ ì°½ì´ 16,000í† í°ì¸ ì´ì „ì— ì¶œì‹œëœ ê°œë°©í˜• ëª¨ë¸ë³´ë‹¤ 2~4ë°° ë” ë§ìŒ) ì‚¬ìš©ìê°€ ë™ì‹œì— ìµœëŒ€ 5ê°œì˜ í‰ê·  í¬ê¸° Python íŒŒì¼ì„ ê²€í† í•˜ê±°ë‚˜ í¸ì§‘í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë” í° ë„ì „ì— ë‚˜ì„œê³ ì í•˜ëŠ” ì´ˆë³´ìì—ê²Œ ì´ìƒì ì¸ í•™ìŠµ ë„êµ¬ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ë¹„ìŠ·í•œ ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ì™€ í›ˆë ¨ëœ í† í° ìˆ˜ë¥¼ ê°€ì§„ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. 
ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” HumanEval ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œì¤€ pass@1 ë° pass@10 ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
Stability AIëŠ” ê¸°ìˆ ì˜ ì ‘ê·¼ì„±ì„ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ë©°, StableCodeëŠ” ì´ ëª©í‘œë¥¼ í–¥í•œ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤. 
ëª¨ë“  ë°°ê²½ì„ ê°€ì§„ ì‚¬ëŒë“¤ì´ ê³§ AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ìƒì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‚¶ì„ ê°œì„ í•˜ëŠ” ì½”ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ ë  ê²ƒì´ë©°, ì €í¬ëŠ” ì´ë¥¼ ì‹¤í˜„í•˜ëŠ” ë° ë„ì›€ì´ ë˜ê³ ì í•©ë‹ˆë‹¤.
StableCodeë¥¼ í†µí•´ í–¥í›„ 10ì–µ ëª…ì˜ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œìê°€ ì½”ë”©ì„ ë°°ìš°ëŠ” ë™ì‹œì— ì „ ì„¸ê³„ ëª¨ë“  ì‚¬ëŒë“¤ì´ ê¸°ìˆ ì— ë” ê³µì •í•˜ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤.
```
https://huggingface.co/stabi.../stablecode-instruct-alpha-3b

## Denoising MCMC for Accelerating Diffusion-Based Generative Models
Conference: ICML 2023 (Oral Paper)

Author: Beomsu Kim (KAIST AI), Jong Chul Ye (KAIST AI)
```
í•œêµ­ì–´ ê°œìš”: Diffusion modelì€ ë†’ì€ í€„ë¦¬í‹°ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë‚˜ ìƒì„± ì†ë„ê°€ ëŠë¦¬ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” Markov Chain Monte Carloì™€ diffusion modelì„ í•©ì¹¨ìœ¼ë¡œì¨ ìƒì„± ë°ì´í„°ì˜ í€„ë¦¬í‹°ë¥¼ ë³´ì¡´í•˜ë©° ìƒì„± ì†ë„ë¥¼ ë¹„ì•½ì ìœ¼ë¡œ ë†’ì¼ ìˆ˜ ìˆìŒì„ ë³´ì˜€ë‹¤. ì œì•ˆí•œ ë°©ë²•ë¡ ì„ í†µí•´ CIFAR10ê³¼ CelebA-HQ-256 ë°ì´í„° ìƒì„±ì—ì„œ SOTA ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ìœ¼ë©°, FFHQ-1024ì™€ ê°™ì€ ê³ í™”ì§ˆ ì´ë¯¸ì§€ ìƒì„± ê°€ì†ë„ ê°€ëŠ¥í•¨ì„ ì‹¤í—˜ì ìœ¼ë¡œ ë³´ì˜€ë‹¤.
Abstract : The sampling process of diffusion models can be interpreted as solving the reverse stochastic differential equation (SDE) or the ordinary differential equation (ODE) of the diffusion process, which often requires up to thousands of discretization steps to generate a single image. This has sparked a great interest in developing efficient integration techniques for reverse-S/ODEs. Here, we propose an orthogonal approach to accelerating score-based sampling: Denoising MCMC (DMCMC). DMCMC first uses MCMC to produce initialization points for reverse-S/ODE in the product space of data and diffusion time. Then, a reverse-S/ODE integrator is used to denoise the initialization points. Since MCMC traverses close to the data manifold, the cost of producing a clean sample for DMCMC is much less than that of producing a clean sample from noise. Denoising Langevin Gibbs, an instance of DMCMC, successfully accelerates all six reverse-S/ODE integrators considered in this work, and achieves state-of-the-art results: in the limited number of score function evaluation (NFE) setting on CIFAR10, we have 3.25 FID with 10 NFE and 2.49 FID with 16 NFE. On CelebA-HQ-256, we have 6.99 FID with 160 NFE, which beats the current best record of Kim et al. (2022) among score-based models, 7.16 FID with 4000 NFE.
```
Slides: https://www.slideshare.net/.../denoising-mcmc-for...
Code: https://github.com/1202kbs/DMCMC
Source: https://arxiv.org/abs/2209.14593

## SDXL 1.0 
Stability AI íŒ€ì€ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì˜ ì§„í™”ì—ì„œ ë‹¤ìŒ ë°˜ë³µì¸ ê°œë°©í˜• ëª¨ë¸ SDXL 1.0ìœ¼ë¡œ ì¶œì‹œí•˜ê²Œ ëœ ê²ƒì„ ìë‘ìŠ¤ëŸ½ê²Œ ìƒê°í•©ë‹ˆë‹¤. SDXL 0.9ì˜ ì œí•œëœ ì—°êµ¬ ì „ìš© ë¦´ë¦¬ìŠ¤ì— ì´ì–´ SDXLì˜ ì •ì‹ ë²„ì „ì€ ì„¸ê³„ ìµœê³ ì˜ ê°œë°©í˜• ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ë¡œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
- Stability AIì˜ ìµœê³ ì˜ ì´ë¯¸ì§€ ëª¨ë¸
SDXLì€ ê±°ì˜ ëª¨ë“  ì•„íŠ¸ ìŠ¤íƒ€ì¼ì—ì„œ ê³ í’ˆì§ˆì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë©° í¬í† ë¦¬ì–¼ë¦¬ì¦˜ì„ ìœ„í•œ ìµœê³ ì˜ ì˜¤í”ˆ ëª¨ë¸ì…ë‹ˆë‹¤. ëª¨ë¸ì— íŠ¹ì •í•œ 'ëŠë‚Œ'ì„ ë¶€ì—¬í•˜ì§€ ì•Šê³ ë„ ëšœë ·í•œ ì´ë¯¸ì§€ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆì–´ ìŠ¤íƒ€ì¼ì— ëŒ€í•œ ì ˆëŒ€ì ì¸ ììœ ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. íŠ¹íˆ SDXL 1.0ì€ ê¸°ë³¸ 1024x1024 í•´ìƒë„ì—ì„œ ì´ì „ ë²„ì „ë³´ë‹¤ ë” ë‚˜ì€ ì½˜íŠ¸ë¼ìŠ¤íŠ¸, ì¡°ëª… ë° ê·¸ë¦¼ìë¥¼ í†µí•´ ìƒìƒí•˜ê³  ì •í™•í•œ ìƒ‰ìƒì„ êµ¬í˜„í•˜ë„ë¡ ì˜ ì¡°ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
ë˜í•œ SDXLì€ ì†ê³¼ í…ìŠ¤íŠ¸ ë˜ëŠ” ê³µê°„ì ìœ¼ë¡œ ë°°ì¹˜ëœ êµ¬ë„(ì˜ˆ: ì „ê²½ì˜ ê°œë¥¼ ì«“ëŠ” ë°°ê²½ì˜ ì—¬ì„±)ì™€ ê°™ì´ ì´ë¯¸ì§€ ëª¨ë¸ë¡œ ë Œë”ë§í•˜ê¸° ì–´ë ¤ìš´ ì»¨ì…‰ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
-ë„ì „ì ì¸ ì»¨ì…‰ê³¼ ìŠ¤íƒ€ì¼ì„ ìœ„í•œ ë” ë‚˜ì€ ì•„íŠ¸ì›Œí¬
SDXLì€ ë³µì¡í•˜ê³  ë””í…Œì¼í•˜ë©° ë¯¸í•™ì ìœ¼ë¡œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ë¥¼ ëª‡ ë§ˆë””ë§Œ ì…ë ¥í•˜ë©´ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë” ì´ìƒ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ì–»ê¸° ìœ„í•´ 'ê±¸ì‘'ê³¼ ê°™ì€ í•œì •ì–´ë¥¼ í˜¸ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ë˜í•œ SDXLì€ 'ë¶‰ì€ ê´‘ì¥'(ìœ ëª…í•œ ì¥ì†Œ)ê³¼ 'ë¶‰ì€ ì‚¬ê°í˜•'(ë„í˜•)ê³¼ ê°™ì€ ê°œë… ê°„ì˜ ì°¨ì´ì ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë” ê°„ë‹¨í•œ ì–¸ì–´ë¡œ ì§€ëŠ¥í™”
SDXLì€ ë³µì¡í•˜ê³  ë””í…Œì¼í•˜ë©° ë¯¸í•™ì ìœ¼ë¡œ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ë¥¼ ëª‡ ë§ˆë””ë§Œ ì…ë ¥í•˜ë©´ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë” ì´ìƒ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ì–»ê¸° ìœ„í•´ 'ê±¸ì‘'ê³¼ ê°™ì€ í•œì •ì–´ë¥¼ í˜¸ì¶œí•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ë˜í•œ SDXLì€ 'ë¶‰ì€ ê´‘ì¥'(ìœ ëª…í•œ ì¥ì†Œ)ê³¼ 'ë¶‰ì€ ì‚¬ê°í˜•'(ë„í˜•)ê³¼ ê°™ì€ ê°œë… ê°„ì˜ ì°¨ì´ì ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê°€ì¥ í° ì˜¤í”ˆ ì´ë¯¸ì§€ ëª¨ë¸
SDXL 1.0ì€ 35ì–µ ê°œì˜ íŒŒë¼ë¯¸í„° ê¸°ë³¸ ëª¨ë¸ê³¼ 66ì–µ ê°œì˜ íŒŒë¼ë¯¸í„° ë¦¬íŒŒì´ë„ˆë¡œ êµ¬ì„±ëœ í˜ì‹ ì ì¸ ìƒˆ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ ì´ë¯¸ì§€ ëª¨ë¸ ì¤‘ ê°€ì¥ ë§ì€ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ì²´ ëª¨ë¸ì€ ì ì¬ì  í™•ì‚°ì„ ìœ„í•œ ì „ë¬¸ê°€ í˜¼í•© íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤: ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ê¸°ë³¸ ëª¨ë¸ì´ (ë…¸ì´ì¦ˆê°€ ìˆëŠ”) ì ìƒì„ ìƒì„±í•œ ë‹¤ìŒ ìµœì¢… ë…¸ì´ì¦ˆ ì œê±° ë‹¨ê³„ì— íŠ¹í™”ëœ ì •ì œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ì€ ë…ë¦½í˜• ëª¨ë“ˆë¡œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ 2ë‹¨ê³„ ì•„í‚¤í…ì²˜ëŠ” ì†ë„ ì €í•˜ë‚˜ ê³¼ë„í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ë¥¼ ìš”êµ¬í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ê°•ë ¥í•œ ì´ë¯¸ì§€ ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. SDXL 1.0ì€ 8GB VRAMì´ íƒ‘ì¬ëœ ì†Œë¹„ììš© GPU ë˜ëŠ” ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ í´ë¼ìš°ë“œ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.
- ë¯¸ì„¸ ì¡°ì • ë° ê³ ê¸‰ ì œì–´
SDXL 1.0ì„ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ì ì§€ì • ë°ì´í„°ì— ë§ê²Œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì´ ê·¸ ì–´ëŠ ë•Œë³´ë‹¤ ì‰¬ì›Œì§‘ë‹ˆë‹¤. ë°ì´í„° ë­ê¸€ë§ ì—†ì´ë„ ì‚¬ìš©ì ì§€ì • LoRA ë˜ëŠ” ì²´í¬í¬ì¸íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Stability AI íŒ€ì€ SDXLì— íŠ¹í™”ëœ T2I / ControlNetì„ í†µí•´ ì°¨ì„¸ëŒ€ ì‘ì—…ë³„ êµ¬ì¡°, ìŠ¤íƒ€ì¼ ë° êµ¬ì„± ì œì–´ë¥¼ êµ¬ì¶•í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ í˜„ì¬ ë² íƒ€ í”„ë¦¬ë·° ë²„ì „ì´ì§€ë§Œ ë¯¸ì„¸ ì¡°ì •ì— ëŒ€í•œ ì—…ë°ì´íŠ¸ë¥¼ ê³„ì† ì§€ì¼œë´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
SDXLì˜ ì´ë¯¸ì§€ ì œì–´ ê¸°ëŠ¥ì€ ê³§ ì¶œì‹œë  ì˜ˆì •ì…ë‹ˆë‹¤.

### Get started with SDXL
There are several ways to get started with SDXL 1.0:
-SDXL 1.0 is live on Clipdrop. Follow this link.
-The weights of SDXL 1.0 and the associated source code have been released on the Stability AI GitHub page.
https://github.com/Stability-AI/generative-models
-SDXL 1.0 is also being released for API on the Stability AI Platform.
-SDXL 1.0 is available on AWS Sagemaker and AWS Bedrock.
-The Stable Foundation Discord is open for live testing of SDXL models.
-DreamStudio has SDXL 1.0 available for image generation as well.

https://stability.ai/.../stable-diffusion-sdxl-1...

ì¶”ê°€ : ë°”ë¡œ ë‹¤ìš´ë¡œë“œ ë°›ì„ ìˆ˜ ìˆëŠ” ê³³
SDXL 1.0 base
https://huggingface.co/stabi.../stable-diffusion-xl-base-1.0
SDXL 1.0 refiner
https://huggingface.co/.../stable-diffusion-xl-refiner-1.0

## FABRIC: Personalizing Diffusion Models with Iterative Feedback (23.7, ETH ZÃ¼rich, Switzerland)
ë””í“¨ì „ ì´ë¯¸ì§€ ìƒì„±ì—ì„œ í›ˆë ¨ì—†ì´ ì‚¬ìš©ìì˜ í”¼ë“œë°±(ì¢‹ì•„ìš”,ì‹«ì–´ìš”)ìœ¼ë¡œ ì¶œë ¥ ê²°ê³¼ë¥¼ ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥
1. Image Gen. ->
2. Result Images Like/Unlike check ->
3. Re-Gen.(same prompt) ->
4. liked style Imgaes Gen.
- Paper: https://arxiv.org/abs/2307.10159
- Project: https://sd-fabric.github.io
- code: https://github.com/sd-fabric/fabric
(deepl ë²ˆì—­) ì´ ì—°êµ¬ì—ì„œëŠ” ì‚¬ìš©ì ê²½í—˜ê³¼ ì¶œë ¥ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ë°˜ë³µì ì¸ ì¸ê°„ í”¼ë“œë°±ì„ í™•ì‚° ê¸°ë°˜ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë´…ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ í™•ì‚° ëª¨ë¸ì— ì ìš©í•  ìˆ˜ ìˆëŠ” í”¼ë“œë°± ì´ë¯¸ì§€ ì„¸íŠ¸ì— ëŒ€í•œ í™•ì‚° í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ê±´í™”í•˜ëŠ” í›ˆë ¨ì´ í•„ìš” ì—†ëŠ” ì ‘ê·¼ ë°©ì‹ì¸ FABRIC(ì£¼ì˜ ê¸°ë°˜ ì°¸ì¡° ì´ë¯¸ì§€ ì»¨ë””ì…”ë‹ì„ í†µí•œ í”¼ë“œë°±)ì„ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì„ ì—„ê²©í•˜ê²Œ í‰ê°€í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ í‰ê°€ ë°©ë²•ë¡ ì„ ì œì•ˆí•˜ê³ , ì—¬ëŸ¬ ì°¨ë¡€ì˜ ë°˜ë³µì ì¸ í”¼ë“œë°±ì„ í†µí•´ ìƒì„± ê²°ê³¼ê°€ ê°œì„ ë˜ì–´ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ìµœì í™”í•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì…ì¦í•©ë‹ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê°œì¸í™”ëœ ì½˜í…ì¸  ì œì‘ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•ì— ì ì¬ì ìœ¼ë¡œ ì ìš©ë˜ì–´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„± ì—°êµ¬ì˜ ë°œì „ì— ê¸°ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## TokenFlow: Consistent Diffusion Features for Consistent Video Editing (23.7, Weizmann institute of science)
ì¼ê´€ëœ ë¹„ë””ì˜¤ í¸ì§‘ì„ ìœ„í•œ ì¼ê´€ëœ í™•ì‚°(Diffusion) ê¸°ëŠ¥

(deeplë²ˆì—­) 
```
ì œë„ˆë ˆì´í‹°ë¸Œ AI í˜ëª…ì€ ìµœê·¼ ë™ì˜ìƒìœ¼ë¡œ í™•ì¥ë˜ê³  ìˆìŠµë‹ˆë‹¤.
ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  í˜„ì¬ì˜ ìµœì²¨ë‹¨ ë¹„ë””ì˜¤ ëª¨ë¸ì€ ì‹œê°ì  í’ˆì§ˆê³¼ ìƒì„±ëœ ì½˜í…ì¸ ì— ëŒ€í•œ ì‚¬ìš©ì ì œì–´ ì¸¡ë©´ì—ì„œ ì´ë¯¸ì§€ ëª¨ë¸ì— ë¹„í•´ ì—¬ì „íˆ ë’¤ì³ì ¸ ìˆìŠµë‹ˆë‹¤.
ì´ ì—°êµ¬ì—ì„œëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¹„ë””ì˜¤ í¸ì§‘ ì‘ì—…ì„ ìœ„í•´ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ì˜ í˜ì„ í™œìš©í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
êµ¬ì²´ì ìœ¼ë¡œ, ì†ŒìŠ¤ ë¹„ë””ì˜¤ì™€ íƒ€ê²Ÿ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ê°€ ì£¼ì–´ì§€ë©´ ì…ë ¥ ë¹„ë””ì˜¤ì˜ ê³µê°„ ë ˆì´ì•„ì›ƒê³¼ ëª¨ì…˜ì„ ìœ ì§€í•˜ë©´ì„œ íƒ€ê²Ÿ í…ìŠ¤íŠ¸ì— ë§ëŠ” ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.
ì´ ë°©ë²•ì€ í™•ì‚° íŠ¹ì§• ê³µê°„ì— ì¼ê´€ì„±ì„ ì ìš©í•¨ìœ¼ë¡œì¨ í¸ì§‘ëœ ë¹„ë””ì˜¤ì˜ ì¼ê´€ì„±ì„ ì–»ì„ ìˆ˜ ìˆë‹¤ëŠ” í•µì‹¬ ê´€ì°°ì— ê¸°ë°˜í•©ë‹ˆë‹¤.
ëª¨ë¸ì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ ê°„ ëŒ€ì‘ì„ ê¸°ë°˜ìœ¼ë¡œ í™•ì‚° íŠ¹ì§•ì„ ëª…ì‹œì ìœ¼ë¡œ ì „íŒŒí•¨ìœ¼ë¡œì¨ ì´ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.
ë”°ë¼ì„œ í”„ë ˆì„ì›Œí¬ëŠ” ë³„ë„ì˜ êµìœ¡ì´ë‚˜ ë¯¸ì„¸ ì¡°ì •ì´ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©°, ê¸°ì„± í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í¸ì§‘ ë°©ë²•ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë‹¤ì–‘í•œ ì‹¤ì œ ë™ì˜ìƒì— ëŒ€í•œ ìµœì²¨ë‹¨ í¸ì§‘ ê²°ê³¼ë¥¼ ì‹œì—°í•©ë‹ˆë‹¤.
```
- project : https://diffusion-tokenflow.github.io/
- paper: https://arxiv.org/abs/2307.10373
- code : https://github.com/omerbt/TokenFlow (comming soon)

## HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models (23.7,  google)

ë“œë¦¼ë¶€ìŠ¤ë³´ë‹¤ 25ë°°, í…ìŠ¤íŠ¸ ë°˜ì „(Textual Inversion)ë³´ë‹¤ 125ë°° ë¹ ë¥¸ ì•½ 20ì´ˆ ë§Œì— ë‹¨ í•˜ë‚˜ì˜ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë“œë¦¼ë¶€ìŠ¤ì™€ ë™ì¼í•œ í’ˆì§ˆê³¼ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ì–¼êµ´ì— ê°œì¸í™”ë¥¼ êµ¬í˜„, ì¼ë°˜ ë“œë¦¼ë¶€ìŠ¤ ëª¨ë¸ë³´ë‹¤ 10000ë°° ë” ì‘ì€ ëª¨ë¸

```
(deepl ë²ˆì—­)
ê°œì¸í™”ëŠ” ë‹¤ì–‘í•œ ìƒí™©ê³¼ ìŠ¤íƒ€ì¼ì˜ ê°œì¸ì„ ë‹¤ì–‘í•œ ë§¥ë½ê³¼ ìŠ¤íƒ€ì¼ë¡œ í•©ì„±í•˜ë©´ì„œë„ ì •ì²´ì„±ì„ ì¶©ì‹¤í•˜ê²Œ ìœ ì§€í•  ìˆ˜ ìˆëŠ” ì œë„ˆë ˆì´í‹°ë¸Œ AI ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì¸¡ë©´ìœ¼ë¡œ ë¶€ìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê·¸ëŸ¬ë‚˜ ê°œì¸í™” í”„ë¡œì„¸ìŠ¤ì—ëŠ” ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì´ë¼ëŠ” ë³¸ì§ˆì ì¸ ê³¼ì œê°€ ìˆìŠµë‹ˆë‹¤.
ê° ê°œì¸í™” ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ë ¤ë©´ ìƒë‹¹í•œ GPU ì‹œê°„ì„ íˆ¬ìí•´ì•¼ í•˜ë©°, í”¼ì‚¬ì²´ë³„ë¡œ ê°œì¸í™” ëª¨ë¸ì„ ì €ì¥í•˜ë ¤ë©´ ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ì´ ë§ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ì‚¬ëŒì˜ ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ê°œì¸í™”ëœ ê°€ì¤‘ì¹˜ ì„¸íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆëŠ” í•˜ì´í¼ë„¤íŠ¸ì›Œí¬ì¸ í•˜ì´í¼ë“œë¦¼ë¶€ìŠ¤(HyperDreamBooth)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ë¥¼ í™•ì‚° ëª¨ë¸ì— êµ¬ì„±í•˜ê³  ë¹ ë¥¸ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ HyperDreamBoothëŠ” ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ê³¼ ì˜ë¯¸ì  ìˆ˜ì •ì— ëŒ€í•œ ëª¨ë¸ì˜ ì¤‘ìš”í•œ ì§€ì‹ì„ ë³´ì¡´í•˜ë©´ì„œ í”¼ì‚¬ì²´ ë””í…Œì¼ì´ ë†’ì€ ë‹¤ì–‘í•œ ì»¨í…ìŠ¤íŠ¸ì™€ ìŠ¤íƒ€ì¼ì˜ ì¸ë¬¼ ì–¼êµ´ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ìš°ë¦¬ì˜ ë°©ì‹ì€ ë“œë¦¼ë¶€ìŠ¤ë³´ë‹¤ 25ë°°, í…ìŠ¤íŠ¸ ë°˜ì „(Textual Inversion)ë³´ë‹¤ 125ë°° ë¹ ë¥¸ ì•½ 20ì´ˆ ë§Œì— ë‹¨ í•˜ë‚˜ì˜ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë“œë¦¼ë¶€ìŠ¤ì™€ ë™ì¼í•œ í’ˆì§ˆê³¼ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ì–¼êµ´ì— ê°œì¸í™”ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë˜í•œ ì´ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ ì¼ë°˜ ë“œë¦¼ë¶€ìŠ¤ ëª¨ë¸ë³´ë‹¤ 10000ë°° ë” ì‘ì€ ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
```

- paper : https://arxiv.org/abs/2307.06949
- project : https://hyperdreambooth.github.io/
  
## Do We Still Need Clinical Language Models?
ì‘ì€ ì–¸ì–´ ëª¨ë¸ì„ íŠ¹ì • ë„ë©”ì¸(ì˜ë£Œ ë¶„ì•¼)ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œìœ¼ë¡œ ë°”ë‹¥ë¶€í„° í•™ìŠµí•œ ê²Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ë‹¤ëŠ” ì—°êµ¬ì…ë‹ˆë‹¤.
ëŒ€ê·œëª¨ì˜ ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ì‚¬ì „ í•™ìŠµëœ ì´ë¥¸ë°” íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì„ íŠ¹ì • ë„ë©”ì¸ì˜ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹í•´ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì´ ì¼ì¢…ì˜ í‘œì¤€ì´ ëœ ê²ƒì— ë°˜í•˜ëŠ” ì—°êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤. 
  - ë…¼ë¬¸ https://arxiv.org/abs/2302.08091

## Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration

```
ë…¼ë¬¸ ì´ˆë¡
ì¸ê°„ì˜ ì§€ëŠ¥ì€ ì„œë¡œ ë‹¤ë¥¸ ì¸ì§€ ê³¼ì • ê°„ì˜ í˜‘ì—…ê³¼ ì •ë³´ í†µí•©ì´ ê°œë³„ì ì¸ ì¸ì§€ ê³¼ì •ì˜ ê³ ë¦½ì— ë¹„í•´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë‚³ëŠ” ì¸ì§€ ì‹œë„ˆì§€ ê°œë…ì„ ë°”íƒ•ìœ¼ë¡œ ë²ˆì°½í•©ë‹ˆë‹¤. ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ì¼ë°˜ì ì¸ ê³¼ì œ í•´ê²° ì—ì´ì „íŠ¸ë¡œì„œ ìœ ë§í•œ ì„±ëŠ¥ì„ ì…ì¦í–ˆì§€ë§Œ, ì§‘ì¤‘ì ì¸ ë„ë©”ì¸ ì§€ì‹ê³¼ ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš”í•œ ê³¼ì œì—ì„œëŠ” ì—¬ì „íˆ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤. ì´ ì—°êµ¬ì—ì„œëŠ” ë‹¨ì¼ LLMì„ ì—¬ëŸ¬ í˜ë¥´ì†Œë‚˜ì™€ ë©€í‹°í„´ ì…€í”„ í˜‘ì—…ì— ì°¸ì—¬ì‹œì¼œ ì¸ì§€ì  ì‹œë„ˆì§€ íš¨ê³¼ë¡œ ì „í™˜í•˜ëŠ” ì†”ë¡œ ì„±ëŠ¥ í”„ë¡¬í”„íŠ¸(SPP)ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤. ì¸ì§€ì  ì‹œë„ˆì§€ë€ ì—¬ëŸ¬ ì‚¬ëŒê³¼ í˜‘ì—…í•˜ì—¬ ê°ìì˜ ê°•ì ê³¼ ì§€ì‹ì„ ê²°í•©í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì—ì„œ ë¬¸ì œ í•´ê²° ë° ì „ë°˜ì ì¸ ì„±ê³¼ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ì§€ëŠ¥í˜• ì—ì´ì „íŠ¸ë¥¼ ë§í•©ë‹ˆë‹¤. SPPëŠ” ì‘ì—… ì…ë ¥ì— ë”°ë¼ ë‹¤ì–‘í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ë™ì ìœ¼ë¡œ ì‹ë³„í•˜ê³  ì‹œë®¬ë ˆì´ì…˜í•¨ìœ¼ë¡œì¨ LLMì—ì„œ ì¸ì§€ì  ì‹œë„ˆì§€ì˜ ì ì¬ë ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” LLMì—ì„œ ì—¬ëŸ¬ ê°œì˜ ì„¸ë¶„í™”ëœ í˜ë¥´ì†Œë‚˜ë¥¼ í• ë‹¹í•˜ë©´ ë‹¨ì¼ ë˜ëŠ” ê³ ì •ëœ ìˆ˜ì˜ í˜ë¥´ì†Œë‚˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ë‚˜ì€ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ ì´ëŒì–´ë‚¸ë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì„¸ ê°€ì§€ ë„ì „ì ì¸ ê³¼ì œë¥¼ í†µí•´ SPPë¥¼ í‰ê°€í•©ë‹ˆë‹¤: ì§€ì‹ ì§‘ì•½ì  ìœ í˜•ê³¼ ì¶”ë¡  ì§‘ì•½ì  ìœ í˜•ì„ ëª¨ë‘ ì•„ìš°ë¥´ëŠ” í€´ì¦ˆ ì°½ì˜ì  ê¸€ì“°ê¸°, ì½”ë“œë„¤ì„ í˜‘ì—…, ë…¼ë¦¬ ê²©ì í¼ì¦ì´ ê·¸ê²ƒì…ë‹ˆë‹¤. ì—°ì‡„ì‚¬ê³ ë ¥(Chain-of-Thought)ê³¼ ê°™ì´ ë‹¨ìˆœíˆ ì¶”ë¡  ëŠ¥ë ¥ë§Œ ê°•í™”í•˜ëŠ” ê¸°ì¡´ ì‘ì—…ê³¼ ë‹¬ë¦¬, SPPëŠ” ë‚´ì  ì§€ì‹ ìŠµë“ ëŠ¥ë ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ì´ëŒì–´ë‚´ê³ , í™˜ê°ì„ ì¤„ì´ë©°, ê°•ë ¥í•œ ì¶”ë¡  ëŠ¥ë ¥ì„ ìœ ì§€í•˜ë„ë¡ í•©ë‹ˆë‹¤.
```
- ë…¼ë¬¸ https://arxiv.org/abs/2307.05300
- ê¹ƒí—ˆë¸Œ https://github.com/MikeWangWZHL/Solo-Performance-Prompting

## AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning (23.7, Shanghai AI Laboratoryì™¸)
íŠ¹ë³„í•œ íŠœë‹ ì—†ì´ ê°œì¸í™”ëœ í…ìŠ¤íŠ¸-to-ì´ë¯¸ì§€ ë””í“¨ì „ ëª¨ë¸ì— ì• ë‹ˆë©”ì´ì…˜ ì ìš©í•˜ê¸°
paper : https://arxiv.org/abs/2307.04725
site : https://animatediff.github.io
ì†ŒìŠ¤ : https://github.com/guoyww/animatediff/
(ì„¤ëª…, deepl ë²ˆì—­) í…ìŠ¤íŠ¸-ëŒ€-ì´ë¯¸ì§€ ëª¨ë¸(ì˜ˆ: Stable Diffusion)ê³¼ ì´ì— ëŒ€ì‘í•˜ëŠ” ê°œì¸í™” ê¸°ìˆ (ì˜ˆ: DreamBooth, LoRA)ì˜ ë°œì „ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ì €ë ´í•œ ë¹„ìš©ìœ¼ë¡œ ìì‹ ì˜ ìƒìƒë ¥ì„ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼ ìƒì„±ëœ ì •ì  ì´ë¯¸ì§€ì— ëª¨ì…˜ ë‹¤ì´ë‚´ë¯¹ìŠ¤ë¥¼ ë”í•˜ê¸° ìœ„í•œ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ ê¸°ë²•ì— ëŒ€í•œ ìš”êµ¬ê°€ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë³¸ ë³´ê³ ì„œì—ì„œëŠ” ê¸°ì¡´ì˜ ëŒ€ë¶€ë¶„ì˜ ê°œì¸í™”ëœ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì„ í•œ ë²ˆì— ì• ë‹ˆë©”ì´ì…˜í™”í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ì—¬ ëª¨ë¸ë³„ íŠœë‹ì— ëŒ€í•œ ìˆ˜ê³ ë¥¼ ëœì–´ì¤ë‹ˆë‹¤.
ì œì•ˆëœ í”„ë ˆì„ì›Œí¬ì˜ í•µì‹¬ì€ ê³ ì •ëœ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì— ìƒˆë¡œ ì´ˆê¸°í™”ëœ ëª¨ì…˜ ëª¨ë¸ë§ ëª¨ë“ˆì„ ì‚½ì…í•˜ê³  ì´ë¥¼ ë¹„ë””ì˜¤ í´ë¦½ì— í•™ìŠµì‹œì¼œ í•©ë¦¬ì ì¸ ëª¨ì…˜ í”„ë¦¬í¼ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•™ìŠµì´ ì™„ë£Œë˜ë©´ ì´ ëª¨ì…˜ ëª¨ë¸ë§ ëª¨ë“ˆì„ ì‚½ì…í•˜ê¸°ë§Œ í•˜ë©´ ë™ì¼í•œ ê¸°ë³¸ T2Iì—ì„œ íŒŒìƒëœ ëª¨ë“  ê°œì¸í™”ëœ ë²„ì „ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë¸ì´ ë˜ì–´ ë‹¤ì–‘í•˜ê³  ê°œì¸í™”ëœ ì• ë‹ˆë©”ì´ì…˜ ì´ë¯¸ì§€ë¥¼ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ìš°ë¦¬ëŠ” ì• ë‹ˆë©”ì´ì…˜ ì‚¬ì§„ê³¼ ì‹¤ì œ ì‚¬ì§„ì— ê±¸ì³ ëª‡ ê°€ì§€ ëŒ€í‘œì ì¸ ê³µê°œ ê°œì¸í™” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì— ëŒ€í•œ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³ , ìš°ë¦¬ê°€ ì œì•ˆí•œ í”„ë ˆì„ì›Œí¬ê°€ ì´ëŸ¬í•œ ëª¨ë¸ì´ ì¶œë ¥ë¬¼ì˜ ì˜ì—­ê³¼ ë‹¤ì–‘ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì‹œê°„ì ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜ í´ë¦½ì„ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì„ ì…ì¦í•©ë‹ˆë‹¤.

ì†ŒìŠ¤ì—ì„œ í™•ì¸í•œ ë‚´ìš©
1) ì¤€ë¹„ ì‚¬í•­
- ì¸í¼ëŸ°ìŠ¤ì— ì•½ 60GB í•„ìš”, NVIDIA A100 ì¶”ì²œ (ê°œì¸ìš© GPUë¡œëŠ” ë¶ˆê°€....)
- Base T2I ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ : stable-diffusion-v1-4, v1-5
- Motion ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ : mm_sd_v15.ckpt , mm_sd_v14.ckpt (ì´ê²Œ ì´ ë…¼ë¬¸ì—ì„œ í•™ìŠµëœ í•µì‹¬ ì²´í¬í¬ì¸íŠ¸ ì¸ ë“¯)
- Prepare Personalize T2I ë‹¤ìš´(civitai ì²´í¬í¬ì¸íŠ¸): ToonYou, RealisticVision ...
2) ì‹¤í–‰(ì¸í¼ëŸ°ìŠ¤) ëª…ë ¹
- python -m scripts.animate --config configs/prompts/1-ToonYou.yaml
python -m scripts.animate --config configs/prompts/5-RealisticVision.yaml

## Thought Cloning: Learning to Think while Acting by Imitating Human Thinking (University of British Columbia, June 2023)
Paper: https://arxiv.org/abs/2306.00323
Abstract:
"Language is often considered a key aspect of human thinking, providing us with exceptional abilities to generalize, explore, plan, replan, and adapt to new situations. However, Reinforcement Learning (RL) agents are far from human-level performance in any of these abilities. We hypothesize one reason for such cognitive deficiencies is that they lack the benefits of thinking in language and that we can improve AI agents by training them to think like humans do. We introduce a novel Imitation Learning framework, Thought Cloning, where the idea is to not just clone the behaviors of human demonstrators, but also the thoughts humans have as they perform these behaviors. While we expect Thought Cloning to truly shine at scale on internet-sized datasets of humans thinking out loud while acting (e.g. online videos with transcripts), here we conduct experiments in a domain where the thinking and action data are synthetically generated. Results reveal that Thought Cloning learns much faster than Behavioral Cloning and its performance advantage grows the further out of distribution test tasks are, highlighting its ability to better handle novel situations. Thought Cloning also provides important benefits for AI Safety and Interpretability, and makes it easier to debug and improve AI. Because we can observe the agent's thoughts, we can (1) more easily diagnose why things are going wrong, making it easier to fix the problem, (2) steer the agent by correcting its thinking, or (3) prevent it from doing unsafe things it plans to do. Overall, by training agents how to think as well as behave, Thought Cloning creates safer, more powerful agents."
- GitHub: https://github.com/ShengranHu/Thought-Cloning
- Article: https://bdtechtalks.com/2023/07/03/ai-thought-cloning/

## LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance (23.7, HuggingFace)
ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¡œ íŠ¹ì • ë¬¼ì²´ë¥¼ ì¶”ê°€ ë° ì‚­ì œí•˜ê±°ë‚˜ ìŠ¤íƒ€ì¼ì„ ë°”ê¾¸

ì²«ë²ˆì§¸ ì²¨ë¶€ ì´ë¯¸ì§€ëŠ” ì§ì ‘ ë°ëª¨ì—ì„œ í•´ë³¸ ê²ƒ, ì›ë³¸ ì–¼êµ´ ì´ë¯¸ì§€ ë„£ê³ , "glasses" ì™€ "painting" ì¶”ê°€í•´ ë³¸ í›„ ê²°ê³¼
(ìˆ˜ì • ì¶”ê°€) ë‘ë²ˆì§¸ ì²¨ë¶€ ì´ë¯¸ì§€ëŠ” ê¶Œíˆ¬ ì¸ë¬¼ ì‚¬ì§„ ë„£ê³  "Elon Musk" face ì…ë ¥ ê²°ê³¼.  
ì„¸ë²ˆì§¸ ì²¨ë¶€ ì´ë¯¸ì§€ëŠ” ë…¼ë¬¸ì— ìˆëŠ” ì´ë¯¸ì§€
paper: https://arxiv.org/abs/2307.00522
project: https://editing-images-project.hf.space/index.html
demo: https://huggingface.co/spaces/editing-images/ledits
(ë…¼ë¬¸ ì„¤ëª… deepl ë²ˆì—­)
ìµœê·¼ì˜ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ìœ ë„ í™•ì‚°(diffusion) ëª¨ë¸ì€ ê°•ë ¥í•œ ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. í˜„ì¬ëŠ” ì§ê´€ì ì´ê³  ë‹¤ì–‘í•œ í¸ì§‘ì„ ì œê³µí•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë° ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì´ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì›ë³¸ ì´ë¯¸ì§€ì˜ íŠ¹ì • ì½˜í…ì¸ ë¥¼ ë³´ì¡´í•´ì•¼ í•˜ëŠ” í¸ì§‘ ê¸°ìˆ ì˜ ë³¸ì§ˆì ì¸ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ì´ëŸ¬í•œ ìƒì„± ëª¨ë¸ì—ì„œëŠ” í¸ì§‘ì´ ì–´ë ¤ìš´ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë¸ì—ì„œëŠ” í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ê¸ˆë§Œ ìˆ˜ì •í•´ë„ ì „í˜€ ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì— ì‚¬ìš©ìì˜ ì˜ë„ì— ì •í™•í•˜ê²Œ ë¶€í•©í•˜ëŠ” ì›ìƒ· ìƒì„±ì„ ë‹¬ì„±í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤. ë˜í•œ ì´ëŸ¬í•œ ìµœì²¨ë‹¨ íˆ´ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ í¸ì§‘í•˜ë ¤ë©´ ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì˜ì—­ìœ¼ë¡œ ë°˜ì „ì‹œì¼œì•¼ í•˜ë¯€ë¡œ ì§€ì—° ì‹œê°„ë¿ë§Œ ì•„ë‹ˆë¼ í¸ì§‘ í’ˆì§ˆì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë˜ ë‹¤ë¥¸ ìš”ì†Œê°€ ì¶”ê°€ë©ë‹ˆë‹¤. ì´ íƒìƒ‰ ë³´ê³ ì„œì—ì„œëŠ” ì‹¤ì œ ì´ë¯¸ì§€ í¸ì§‘ì„ ìœ„í•œ ê²½ëŸ‰ ì ‘ê·¼ ë°©ì‹ì¸ LEDITSë¥¼ ì œì•ˆí•˜ë©°, í¸ì§‘ ì¹œí™”ì ì¸ DDPM ë°˜ì „ ê¸°ë²•ê³¼ ì‹œë§¨í‹± ê°€ì´ë˜ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ì‹œë§¨í‹± ê°€ì´ë˜ìŠ¤ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ í¸ì§‘ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ë™ì‹œì— DDPM ë°˜ì „ì˜ í¸ì§‘ ê¸°ëŠ¥ë„ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ êµ¬ë„ ë° ìŠ¤íƒ€ì¼ ë³€ê²½ì€ ë¬¼ë¡  ë¯¸ë¬˜í•˜ê³  ê´‘ë²”ìœ„í•œ í¸ì§‘ì„ ë‹¤ì–‘í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©° ì•„í‚¤í…ì²˜ë¥¼ ìµœì í™”í•˜ê±°ë‚˜ í™•ì¥í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.

## Towards Healthy AI: Large Language Models Need Therapists Too

ì´ ë…¼ë¬¸ì—ì„œëŠ” AI ì±—ë´‡ì˜ ìœ í•´í•œ í–‰ë™ì„ ìˆ˜ì •í•˜ê³  ì¸ê°„ì˜ ê°€ì¹˜ì— ë¶€í•©í•˜ë„ë¡ ê°œì„ í•˜ê¸° ìœ„í•´ ì‹¬ë¦¬ì¹˜ë£Œë¥¼ í†µí•©í•˜ëŠ” SafeguardGPT í”„ë ˆì„ì›Œí¬ë¥¼ ì œì•ˆí•˜ê³ , ì†Œì…œ ëŒ€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ì‘ì—… ì‚¬ë¡€ë¥¼ í†µí•´ ê·¸ íš¨ê³¼ë¥¼ ì…ì¦í•©ë‹ˆë‹¤.
PDF: https://arxiv.org/pdf/2304.00416.pdf
## Transformer/Attention Tutorial/Survey in Other Disciplines
* Everything You Need to Know about Transformers: Architectures, Optimization, Applications, and Interpretation, in *AAAI Tutorial* 2023. [\[link\]](https://transformer-tutorial.github.io/aaai2023/)  
* Transformer Architectures for Multimodal Signal Processing and Decision Making, in *ICASSP Tutorial* 2022. [\[link\]](https://transformer-tutorial.github.io/icassp2022/)  
* Efficient transformers: A survey, in *ACM Computing Surveys* 2022. [\[paper\]](https://dl.acm.org/doi/10.1145/3530811) [\[paper\]](https://arxiv.org/abs/2009.06732)
* A survey on visual transformer, in *IEEE TPAMI* 2022. [\[paper\]](https://arxiv.org/abs/2012.12556)
* A General Survey on Attention Mechanisms in Deep Learning, in *IEEE TKDE* 2022. [\[paper\]](https://personal.eur.nl/frasincar/papers/TKDE2022/tkde2022.pdf)
* Attention, please! A survey of neural attention models in deep learning, in *Artificial Intelligence Review* 2022. [\[paper\]](https://link.springer.com/article/10.1007/s10462-022-10148-x)
* Attention mechanisms in computer vision: A survey, in *Computational Visual Media* 2022. [\[paper\]](https://link.springer.com/article/10.1007/s41095-022-0271-y)
* Survey: Transformer based video-language pre-training, in _AI Open_ 2022. [\[paper\]](https://www.sciencedirect.com/science/article/pii/S2666651022000018)
* Transformers in vision: A survey, in *ACM Computing Surveys* 2021. [\[paper\]](https://arxiv.org/abs/2101.01169)
* Pre-trained models: Past, present and future, in *AI Open* 2021. [\[paper\]](https://www.sciencedirect.com/science/article/pii/S2666651021000231)
* An attentive survey of attention models, in *ACM TIST* 2021. [\[paper\]](https://arxiv.org/abs/1904.02874)
* Attention in natural language processing, in *IEEE TNNLS* 2020. [\[paper\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9194070)
* Pre-trained models for natural language processing: A survey, in *Science China Technological Sciences* 2020. [\[paper\]](https://link.springer.com/article/10.1007/s11431-020-1647-3)
* A review on the attention mechanism of deep learning, in *Neurocomputing* 2021. [\[paper\]](https://www.sciencedirect.com/science/article/abs/pii/S092523122100477X)
* A Survey of Transformers, in _arXiv_ 2021. [\[paper\]](https://arxiv.org/abs/2106.04554)
* A Survey of Vision-Language Pre-Trained Models, in _arXiv_ 2022. [\[paper\]](https://arxiv.org/abs/2202.10936)
* Video Transformers: A Survey, in *arXiv* 2022. [\[paper\]](https://arxiv.org/abs/2201.05991)
* Transformer for Graphs: An Overview from Architecture Perspective, in _arXiv_ 2022. [\[paper\]](https://arxiv.org/abs/2202.08455)
* Transformers in Medical Imaging: A Survey, in _arXiv_ 2022. [\[paper\]](https://arxiv.org/abs/2201.09873) 
* A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models, in _arXiv_ 2022. [\[paper\]](https://arxiv.org/abs/2201.05337) 

## Segment Anything: 
https://arxiv.org/abs/2304.02643

## OpenAi's GPT-2
 - 345m ì§œë¦¬ ëª¨ë¸ì„ ê³µê°œ
 - 762m, 1.5bëŠ” ì¼ë¶€ì—ê²Œ ê³µê°œ
 - links : https://openai.com/blog/better-language-models
 
## Download LLaMA from meta.
To download all model weights, then run this:

Linux:
```sh
curl -o- https://raw.githubusercontent.com/shawwn/llama-dl/56f50b96072f42fb2520b1ad5a1d6ef30351f23c/llama.sh | bash
```
Mac:
```sh
brew install bash
curl -o- https://raw.githubusercontent.com/shawwn/llama-dl/56f50b96072f42fb2520b1ad5a1d6ef30351f23c/llama.sh | $(brew --prefix)/bin/bash
```

