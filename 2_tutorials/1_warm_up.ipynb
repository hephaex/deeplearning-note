{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to Michael Terry and Shan Carter for sharing this exercise with us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-Up\n",
    "\n",
    "\n",
    "## Review: TensorFlow's Computational Model\n",
    "\n",
    "TensorFlow uses directed graphs to describe computations. Understanding how this computational model works (and how to write graphs that do what you want) requires a slight change in thinking from normal\n",
    "programming.\n",
    "\n",
    "To help you form a correct mental model, let's walk through a simple example\n",
    "that performs the equivalent of the following Python code, but in TensorFlow:\n",
    "\n",
    "```python\n",
    "x = 1.0\n",
    "x = x + 1.5\n",
    "```\n",
    "\n",
    "### Defining a Graph is Like Creating a Blueprint\n",
    "\n",
    "The first thing to keep in mind when writing TensorFlow code is that most of\n",
    "your code serves to *define the computational graph*, which you can think of as\n",
    "a kind of **blueprint**. As a blueprint, the graph can't do anything -- it isn't\n",
    "until you run ops in the graph (within the context of a `Session`) that it can\n",
    "actually do work. This will become clearer as we step through this example.\n",
    "\n",
    "To get things started, we'll import TensorFlow and create the `Graph` object\n",
    "that will hold variables and operations:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "  # Our TensorFlow code\n",
    "```\n",
    "\n",
    "Here, the `as_default()` function simply says that all subsequent `Variable`s\n",
    "and operations should be added to the graph created with the `tf.Graph()` call.\n",
    "\n",
    "Next, let's create a constant:\n",
    "\n",
    "```python\n",
    "  c = tf.constant(1.5)\n",
    "```\n",
    "\n",
    "When Python executes this line of code, it starts defining the blueprint for our\n",
    "graph:\n",
    "\n",
    "![A constant node](images/graph-01-01.png)\n",
    "\n",
    "Next, let's create a `Variable`:\n",
    "\n",
    "```python\n",
    "  x = tf.Variable(1.0, name=\"x\")\n",
    "```\n",
    "\n",
    "Executing this line creates a slot for a `Variable` in the graph:\n",
    "\n",
    "![Adding a variable to the graph](images/graph-01-02.png)\n",
    "\n",
    "Actually, as you can see, this single line of code creates *three* things in the\n",
    "graph:\n",
    "\n",
    "1. A node for the `Variable`.\n",
    "1. Another constant.\n",
    "1. An assign op.\n",
    "\n",
    "When Python executes the code `x = tf.Variable(1.0, name=\"x\")`, the `Variable`\n",
    "is declared, but has not been allocated or initialized. The `Variable` is also\n",
    "assigned the name we passed in. As you can see in the figure, TensorFlow takes\n",
    "the name and appends \":0\" to it to get \"x:0\" as the final Tensor's name.\n",
    "\n",
    "It can help to understand how objects are named in TensorFlow. Each operation is\n",
    "given a unique name. In the case of the node for the `Variable`, we've created\n",
    "an operation of type `VariableOp` that is named \"x\" that produces a Tensor. This\n",
    "tensor is a writable reference type (`tf.float32_ref`) named \"x:0\".\n",
    "\n",
    "* `Tensors` are named after the operation and are sequentially numbered. A\n",
    "    `VariableOp` always has one output, so the Tensor is named \"x:0\". Some\n",
    "    operations, such as `tf.split` produce multiple outputs. For example,\n",
    "    `tf.split(0, 2, input, name='x')` would produce two output Tensors named\n",
    "    \"x:0\" and \"x:1\".\n",
    "    \n",
    "* If an operation is assigned a name that already exists in the graph, then\n",
    "    TensorFlow ensures uniqueness by appending an underscore and number. For\n",
    "    example, declaring a second Variable named \"x\" would yield a name of\n",
    "    \"x_1:0\".\n",
    "\n",
    "The **Python variable** `x` contains a reference to that node, but at this\n",
    "point, you cannot access the value of the `Variable` in TensorFlow (because it\n",
    "hasn't been instantiated, yet). The addition of the constant and `assign` op\n",
    "lays the groundwork for initializing the `Variable`.\n",
    "\n",
    "The reference returned by `assign` allows you to access the new value of the `Variable`. Note\n",
    "that this returned reference *must* be run to trigger the `assign` op to run. In\n",
    "this case, the `assign` op will be automatically run for us when we run the\n",
    "`tf.initialize_all_variables()` op later.\n",
    "\n",
    "Now let's specify our addition:\n",
    "\n",
    "```python\n",
    "  add_op = tf.add(x, c)\n",
    "```\n",
    "\n",
    "The add op is also added to the graph and connected to the previously defined\n",
    "constant and `Variable`:\n",
    "\n",
    "![Add an add op](images/graph-01-03.png)\n",
    "\n",
    "Finally, let's assign the result back to the `Variable` represented by `x`:\n",
    "\n",
    "```python\n",
    "  assign_op = tf.assign(x, add_op)\n",
    "```\n",
    "\n",
    "Our graph now looks like this:\n",
    "\n",
    "![Add assign op](images/graph-01-04.png)\n",
    "\n",
    "If you inspect the graph above, you'll notice that our `Variable` is attached to\n",
    "two different `assign` ops, but there is no sense of order of operations for the\n",
    "two `assign` ops (e.g., which `assign` op will execute first, and\n",
    "why?). (However, there *is* an order of operations specified for the other,\n",
    "connected nodes -- for example, `tf.add` needs to run before the top-most\n",
    "`tf.assign` op.) Clearly, we want to initialize the `Variable` before we try to\n",
    "add a number and assign the result back to the `Variable`. We'll explicitly\n",
    "order these operations below when we call `Session.run()`.\n",
    "\n",
    "On the topic of initialization, we add one last op to initialize all variables:\n",
    "\n",
    "```python\n",
    "  init = tf.initialize_all_variables()\n",
    "```\n",
    "\n",
    "This op will cause our variable to be allocated and initialized through the\n",
    "`assign()` op automatically created for us (the one on the bottom of the\n",
    "figure).\n",
    "\n",
    "Our final graph looks like this (note the addition of the\n",
    "`tf.initialize_all_variables()` op):\n",
    "\n",
    "![Add initialization op](images/graph-01-05.png)\n",
    "\n",
    "But, remember, this is still just a blueprint! No computation has yet occurred\n",
    "in the graph -- **we still need to run the graph** to initialize the `Variable`,\n",
    "perform the addition, and assign the result back.\n",
    "\n",
    "To run the graph, we create a `Session`:\n",
    "\n",
    "```python\n",
    "  with tf.Session() as sess:\n",
    "    # ...\n",
    "```\n",
    "\n",
    "Creating a `Session` brings our blueprint to life:\n",
    "\n",
    "![Create graph](images/graph-01-06.png)\n",
    "\n",
    "We can now call our init op to initialize the `Variable`:\n",
    "\n",
    "```python\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "```\n",
    "\n",
    "This causes the following subgraph to come to life...\n",
    "\n",
    "![Call init](images/graph-01-07.png)\n",
    "\n",
    "\n",
    "...and initialize the `Variable`:\n",
    "\n",
    "![Init result](images/graph-01-08.png)\n",
    "\n",
    "As the figure suggests, only the subgraph connected to the\n",
    "`tf.initialize_all_variables` op executes.\n",
    "\n",
    "We can now perform the addition and assignment. However, instead of calling each\n",
    "operation individually, we can simply run the topmost `assign` op -- TensorFlow\n",
    "will automatically determine the dependencies and execute them. In this case,\n",
    "the `assign` op depends on the result of the `add` op, so it runs that first:\n",
    "\n",
    "```python\n",
    "    sess.run(assign_op)\n",
    "```\n",
    "\n",
    "Calculating the subgraph to run:\n",
    "\n",
    "![Assign op dependencies](images/graph-01-09.png)\n",
    "\n",
    "Performing the addition:\n",
    "\n",
    "![Add op running](images/graph-01-10.png)\n",
    "\n",
    "Performing the assignment back to our `Variable`:\n",
    "\n",
    "![Assignment op running](images/graph-01-11.png)\n",
    "\n",
    "At this point, we can now retrieve the new value of the `Variable`, if we'd\n",
    "like:\n",
    "\n",
    "```python\n",
    "print(sess.run(x))  # Should print out 2.5\n",
    "```\n",
    "\n",
    "The final code:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "  x = tf.Variable(1.0, name=\"x\")\n",
    "  add_op = tf.add(x, tf.constant(1.5))\n",
    "  assign_op = tf.assign(x, add_op)\n",
    "  init = tf.initialize_all_variables()\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_op)\n",
    "    print(sess.run(x))\n",
    "```\n",
    "\n",
    "Normally, you won't need to worry about explicitly creating a `Graph` or\n",
    "`Session`, as we've done here -- these objects will be created for you\n",
    "automatically by high-level APIs like `tf.learn`. And, in many cases, you won't\n",
    "need to worry about defining really low-level operations like we illustrated\n",
    "here. However, it's still useful to have a basic model of how to define\n",
    "computation in TensorFlow, and how TensorFlow actually performs those\n",
    "computations. (For another walkthrough on these concepts, you may find this\n",
    "[tutorial useful](https://www.tensorflow.org/versions/r0.10/get_started/basic_usage.html).)\n",
    "\n",
    "In the next section, you'll get practice in writing some basic TensorFlow code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implement the Fibonacci Sequence in TensorFlow\n",
    "\n",
    "In this exercise, your goal is to calculate the Fibonacci sequence using\n",
    "tensors, where $fib(n) = fib(n-1) + fib(n-2)$, and $fib(0) = 0$ and\n",
    "$fib(1) = 1$. \n",
    "\n",
    "**Spend about 10 minutes on this exercise, then check the solution**\n",
    "\n",
    "To calculate this sequence, use the following two tensors:\n",
    "\n",
    "*   `fib_seq`, a 2x1 2D tensor `Variable` that represents the latest two values\n",
    "    of the Fibonacci sequence (the nth and (n-1)th). Initialize `fib_seq` with\n",
    "    the following two values: $\\begin{bmatrix}0.0\\\\1.0\\end{bmatrix}$\n",
    "*   `fib_matrix`, a constant 2x2 2D tensor that generates the next entries in\n",
    "    the Fibonacci sequence: $\\begin{bmatrix}0.0 & 1.0\\\\1.0 & 1.0\\end{bmatrix}$\n",
    "\n",
    "If you perform a matrix multiplication of `fib_matrix` and `fib_seq`, you get\n",
    "the next value in the sequence (the nth and the (n+1)th):\n",
    "\n",
    "$$\\begin{bmatrix}0.0 & 1.0\\\\1.0 & 1.0\\end{bmatrix}\n",
    "\\begin{bmatrix}0.0\\\\1.0\\end{bmatrix} = \\begin{bmatrix}1.0\\\\1.0\\end{bmatrix}$$\n",
    "\n",
    "Using matrix multiplication on `fib_matrix` and the previous result produces the\n",
    "next value: $\\begin{bmatrix}1.0\\\\2.0\\end{bmatrix}$. And so on.\n",
    "\n",
    "In the `fibonacci_seq` function (below), perform the following steps:\n",
    "\n",
    "*   Create `fib_seq`, the 2x1 2D tensor `Variable` to hold the current values of\n",
    "    the Fibonacci sequence.\n",
    "*   Perform the matrix multiplication of `fib_matrix` and `fib_seq` using\n",
    "    `tf.matmul()`, and assign the result back to `fib_seq` using `tf.assign()`.\n",
    "    [Examples here](https://www.tensorflow.org/versions/r0.10/get_started/basic_usage.html).\n",
    "\n",
    "Make sure you add the correct tensors to the `output_dict` so that the\n",
    "computations are actually performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "\n",
    "    # Add code that will calculate and output the Fibonacci sequence\n",
    "    # using TF. You will need to make use of tf.matmul() and\n",
    "    # tf.assign() to perform the multiplications and assign the result\n",
    "    # back to the variable fib_seq.\n",
    "\n",
    "    fib_matrix = tf.constant([[0.0, 1.0],\n",
    "                              [1.0, 1.0]])\n",
    "\n",
    "    ### SOLUTION START ###\n",
    "    # Put your solution code here.\n",
    "\n",
    "    # Change this line to initialize fib_seq to a 2x1 TensorFlow\n",
    "    # tensor *Variable* with the initial values of 0.0 and 1.0. Hint:\n",
    "    # You'll need to make sure you specify a 2D tensor of shape 2x1,\n",
    "    # not a 1D tensor. See fib_matrix above (a 2x2 2D tensor) to guide\n",
    "    # you.\n",
    "    fib_sequence = None\n",
    "    \n",
    "    # Change this line to multiply fib_matrix and fib_sequence using tf.matmul()\n",
    "    next_fib = None\n",
    "    \n",
    "    # Change this line to assign the result back to fib_sequence using tf.assign()\n",
    "    assign_op = None\n",
    "    \n",
    "    ### SOLUTION END ###\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(10):\n",
    "            sess.run(assign_op)\n",
    "            print(sess.run(fib_sequence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
