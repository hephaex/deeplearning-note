# Computational Vision

Computational Imaging is a the process of indirectly forming images from measurements using algorithms that rely on a significant amount of computing. In contrast to traditional imaging, computational imaging systems involve a tight integration of the sensing system and the computation in order to form the images of interest. The ubiquitous availability of fast computing platforms (such as multi-core CPUs and GPUs), the advances in algorithms and modern sensing hardware is resulting in imaging systems with significantly enhanced capabilities. Computational Imaging systems cover a broad range of applications include computational microscopy,[1] tomographic imaging, MRI, ultrasound imaging, computational photography, Synthetic Aperture Radar (SAR), seismic imaging etc. The integration of the sensing and the computation in computational imaging systems allows for accessing information which was otherwise not possible.


## satellite-image-deep-learning
https://github.com/robmarkcole/satellite-image-deep-learning

## DeepHarmonization

Project webpage: https://sites.google.com/site/yihsuantsai/research/cvpr17-harmonization 
Contact: Yi-Hsuan Tsai (wasidennis at gmail dot com)
https://github.com/wasidennis/DeepHarmonization

## DETReg
Researchers From Tel Aviv University, UC Berkeley and NVIDIA Introduce ‘DETReg’, A Novel Unsupervised AI For Object Detection
Quick Read: https://www.marktechpost.com/.../researchers-from-tel.../
Codes: https://github.com/amirbar/DETReg
Project: https://www.amirbar.net/detreg/
Paper: https://arxiv.org/pdf/2106.04550.pdf

## DeeoHDR

CCV'18: Deep High Dynamic Range Imaging with Large Foreground Motions
[Deep High Dynamic Range Imaging with Large Foreground Motions](https://arxiv.org/abs/1711.08937), Shangzhe Wu, Jiarui Xu, Yu-Wing Tai, Chi-Keung Tang, in ECCV, 2018. More results can be found on our [project page](https://elliottwu.com/projects/hdr/). 
https://github.com/elliottwu/DeepHDR

## ResTS: Residual Deep interpretable architecture for plant disease detection
https://www.sciencedirect.com/science/article/pii/S2214317321000482/pdfft?md5=6b049240ca4d7569bd16b2b05ce4e247&pid=1-s2.0-S2214317321000482-main.pdf

## General Light Microscopy 
- https://www.ibiology.org/online-biology-courses/microscopy-series/

## UC Berkeley Prof. Laura Waller
- https://www.youtube.com/watch?v=nlMqwWDLnfA&t=1540s

##  Exposure: A White-Box Photo Post-Processing Framework
#### ACM Transactions on Graphics (presented at SIGGRAPH 2018)
[Yuanming Hu](http://taichi.graphics/me/)<sup>1,2</sup>, [Hao He](https://github.com/hehaodele)<sup>1,2</sup>, Chenxi Xu<sup>1,3</sup>, [Baoyuan Wang](https://sites.google.com/site/zjuwby/)<sup>1</sup>, [Stephen Lin](https://www.microsoft.com/en-us/research/people/stevelin/)<sup>1</sup>

#### [[Paper](https://arxiv.org/abs/1709.09602)] [[PDF Slides](https://github.com/yuanming-hu/exposure/releases/download/slides/exposure-slides.pdf)] [[PDF Slides with notes](https://github.com/yuanming-hu/exposure/releases/download/slides/exposure-slides-with-notes.pdf)] [[SIGGRAPH 2018 Fast Forward](https://www.youtube.com/watch?v=JdTkKhm0LVU)]

## MIT Optics Class 
- Prof.George Barbastathis (https://www.youtube.com/watch?v=IYBYmOVmICg)

## VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer


* Arxiv: https://arxiv.org/abs/2107.02681
* https://github.com/zinengtang/VidLanKD
## attention-cnn
- [code](https://epfml.github.io/attention-cnn/)

#### Image Recognition 
* End-to-End Object Detection with Transformers (ECCV 2020)
    * [Original Paper Link](https://arxiv.org/abs/2005.12872) / [Paper Review Video](https://www.youtube.com/watch?v=hCWUTvVrG7E) / [Summary PDF](/lecture_notes/DETR.pdf) / Code Practice
    * 
* Searching for MobileNetV3 (ICCV 2019)
    * [Original Paper Link](https://arxiv.org/abs/1905.02244) / Paper Review Video / Summary PDF / Code Practice
* Deep Residual Learning for Image Recognition (CVPR 2016)
    * [Original Paper Link](https://arxiv.org/abs/1512.03385) / [Paper Review Video](https://www.youtube.com/watch?v=671BsKl8d0E) / [Summary PDF](/lecture_notes/ResNet.pdf) / [MNIST](/code_practices/ResNet18_MNIST_Train.ipynb) / [CIFAR-10](/code_practices/ResNet18_CIFAR10_Train.ipynb) / [ImageNet](/code_practices/Pretrained_ResNet18_ImageNet_Test.ipynb)
    
* Image Style Transfer Using Convolutional Neural Networks (CVPR 2016)
    * [Original Paper Link](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf) / Paper Review Video / Summary PDF / Code Practice
* Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (NIPS 2015)
    * [Original Paper Link](https://arxiv.org/abs/1506.01497) / Paper Review Video / Summary PDF / Code Practice

### ReLabel:
소설 프레임워크로 이미지넷 평가를 멀티 레이블 작업으로 돌릴 수 있습니다.
페이퍼: https://arxiv.org/pdf/2101.05022.pdf
Github: https://github.com/naver-ai/relabel_imagenet

## ML-HyperSim
Quick Read: https://www.marktechpost.com/.../apples-machine-learning.../
Paper: https://arxiv.org/pdf/2011.02523.pdf
Codes: https://github.com/apple/ml-hypersim

### Video Frame Interpolation 
* RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation
    * [paper link[(https://arxiv.org/pdf/2011.06294) 
https://github.com/hzwer/arXiv2020-RIFE

## MIT Researchers Propose Patch-Based Inference to Reduce the Memory Usage for Tiny Deep Learning
Quick Read: https://www.marktechpost.com/.../mit-researchers-propose.../
Paper: https://arxiv.org/abs/2110.15352
Project: https://mcunet.mit.edu/

## 시카고 대학과 텔아비브 대학의 연구진은 ‘텍스트2메쉬’를 소개했다: 텍스트 대상에 따라 3D 메쉬의 색과 기하학을 모두 바꾸는 소설 프레임워크
논문 요약: https://www.marktechpost.com/.../researchers-from-the.../
페이퍼: https://arxiv.org/pdf/2112.03221.pdf
GitHub: https://github.com/threedle/text2mesh
프로젝트 페이지: https://threedle.github.io/text2mesh/

## : A New Neural Network-Based Method To Build Animatable 3D Models From Videos
Quick Read: https://www.marktechpost.com/.../meta-ai-and-cmu.../
Paper: https://arxiv.org/pdf/2112.12761.pdf
Project: https://banmo-www.github.io/

## Stanford University/NVIDIA, via Sergio Valmorisco Sierra:
" Current state-of-the-art GANs have seen immense progress, but they commonly operate in 2D and do not explicitly model the underlying 3D scenes. Recent work on 3D-aware GANs has begun to tackle the problem of multi-view-consistent image synthesis and, to a lesser extent, extraction of 3D shapes without being supervised on geometry or multi-view image collections. However, the image quality and resolution of existing 3D GANs have lagged far behind those of 2D GANs. One of the primary reasons for this gap is the computational inefficiency of previously employed 3D generators and neural rendering architectures.
The authors of this paper introduce a novel generator architecture for unsupervised 3D representation learning from a collection of single-view 2D photographs that seeks to improve the computational efficiency of rendering while remaining true to 3D-grounded neural rendering.
For this purpose, the authors introduce an expressive hybrid explicit-implicit network architecture that, together with other design choices, synthesizes not only high-resolution multi-view-consistent images in real-time but also produces high-quality 3D geometry. By decoupling feature generation and neural rendering, their framework is able to leverage state-of-the-art 2D CNN generators, such as StyleGAN2, and inherit their efficiency and expressiveness."
 - Project: https://lnkd.in/dCV3t4qG
 - Code: https://lnkd.in/dRf8S-4n
 - Video: https://lnkd.in/d4hp2WAh
 - Paper: https://lnkd.in/datCy3HN
 - Authors: Eric R. Chan, Connor Lin, Matthew A. Chan, Koki Nagano, Boxiao (Leo) Pan, Shalini De Mello, Orazio Gallo, Leonidas Guibas, Jonathan Tremblay, Sameh Khamis, Tero Karras, Gordon Wetzstein

## Researchers at Meta and the University of Texas at Austin Propose ‘Detic’: A Method to Detect Twenty-Thousand Classes using Image-Level Supervision
Quick Read: https://www.marktechpost.com/.../researchers-at-meta-and.../
Paper: https://arxiv.org/pdf/2201.02605v2.pdf
Github: https://github.com/facebookresearch/Detic

## Apple ML Researchers Introduce ARKitScenes: A Diverse Real-World Dataset For 3D Indoor Scene Understanding Using Mobile RGB-D Data
Quick Read: https://www.marktechpost.com/.../apple-ml-researchers.../
Paper: https://arxiv.org/pdf/2111.08897.pdf
Github: https://github.com/apple/ARKitScenes

## Researchers From China Propose A Pale-Shaped Self-Attention (PS-Attention) And A General Vision Transformer Backbone, Called Pale Transformer
Quick Read: https://www.marktechpost.com/.../researchers-from-china.../
Paper: https://arxiv.org/pdf/2112.14000v1.pdf
Github: https://github.com/BR-IDL/PaddleViT

## Meta AI and CMU Researchers Present ‘BANMo’: A New Neural Network-Based Method To Build Animatable 3D Models From Videos
Quick Read: https://www.marktechpost.com/.../meta-ai-and-cmu.../
Paper: https://arxiv.org/pdf/2112.12761.pdf
Project: https://banmo-www.github.io/

## UNETR’: A Novel Architecture for Semantic Segmentation of Brain Tumors Using Multi-Modal MRI Images
Quick Read: https://www.marktechpost.com/.../researchers-from-nvidia.../
Paper: https://arxiv.org/pdf/2201.01266v1.pdf
Github: https://github.com/.../research.../tree/master/SwinUNETR

## 비전 기반 제스처 제어 드론
젯슨나노2GB에 단안카메라로 제스쳐 모양에 따라 드론이 스탠드 후버링은 물론 좌/우로 제어가 되네요!
* 공헌자(저자): A FINDELAIR
* 데모 동영상: https://youtu.be/FZAUPmKiSXg 
* GitHub: https://github.com/ArthurFDLR/drone-gesture-control 
* 프로젝트 보고서: https://github.com/.../blob/main/.github/Project_Report.pdf 
* 데브토크: https://forums.developer.nvidia.com/.../vision.../187072 

## Google AI Introduces ‘StylEx’: A New Approach For A Visual Explanation Of Classifiers
Quick Read: https://www.marktechpost.com/.../google-ai-introduces.../
Paper: https://arxiv.org/pdf/2104.13369.pdf
Project: https://explaining-in-style.github.io/
Github: https://github.com/google/explaining-in-style
