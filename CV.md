### DeepMind Introduces the Perception Test, a New Multimodal Benchmark Using Real-World Videos to Help Evaluate the Perception Capabilities of a Machine Learning Model
Paper: https://storage.googleapis.com/.../perception_test_report...
Github link: https://github.com/deepmind/perception_test

## Latest Computer Vision Research Proposes Lumos for Relighting Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation
Paper: https://arxiv.org/pdf/2209.10510.pdf
Demo: http://imaginaire.cc/Lumos/
Project: https://deepimagination.cc/Lumos/

## Google AI Introduces Frame Interpolation for Large Motion (FILM): A New Neural Network Architecture To Create High-Quality Slow-Motion Videos From Near-Duplicate Photos
Paper: https://arxiv.org/pdf/2202.04901.pdf
Github: https://github.com/google-research/frame-interpolation
Project: https://film-net.github.io/

## Latest Computer Vision Research at Nanyang Technological University Introduces VToonify Framework for Style Controllable High-Resolution Video Toonification
Paper: https://arxiv.org/pdf/2209.11224v2.pdf
Github: https://github.com/williamyang1991/vtoonify

## Salesforce AI Open-Sources â€˜LAVIS,â€™ A Deep Learning Library For Language-Vision Research/Applications
Paper: https://arxiv.org/pdf/2209.09019.pdf
Github link: https://github.com/salesforce/LAVIS

## Researchers at Tencent Propose GFP-GAN that Leverages Rich and Diverse Priors Encapsulated in a Pretrained Face GAN for Blind Face Restoration
Paper: https://arxiv.org/pdf/2101.04061v2.pdf
Github link: https://github.com/TencentARC/GFPGAN

## Latest Computer Vision Research at Google and Boston University Proposes â€˜DreamBooth,â€™ 
A Technique for Fine-Tuning a Text-to-Image Model with a very Limited Set of Images
Paper: https://arxiv.org/pdf/2208.12242.pdf?
Project: https://dreambooth.github.io/

## Researchers from McGill University and Microsoft Introduces Convolutional vision Transformer (CvT) that improves Vision Transformer (ViT) in Performance and Efficiency by Introducing Convolutions into ViT
Paper: https://openaccess.thecvf.com/.../Wu_CvT_Introducing...
GIthub: https://github.com/microsoft/CvT

## Microsoft Research Introduces a General-Purpose Multimodal Foundation Model â€˜BEIT-3,â€™ that Achieves State-of-the-Art Transfer Performance on Both Vision and Vision Language Tasks
Paper: https://arxiv.org/pdf/2208.10442.pdf
Github: https://github.com/microsoft/unilm/tree/master/beit

## Apple Researchers Develop NeuMan
A Novel Computer Vision Framework that can Generate Neural Human Radiance Field from a Single Video
Paper: https://arxiv.org/pdf/2203.12575v1.pdf
Github: https://github.com/apple/ml-neuman

## Researchers from the Alibaba Group added their newly developed â€˜YOLOX-PAIâ€™ into EasyCV, which is an all-in-one Computer Vision Toolbox
Quick Read: https://www.marktechpost.com/.../researchers-from-the.../
Paper: https://arxiv.org/pdf/2208.13040v1.pdf
Github link: https://github.com/alibaba/EasyCV

## Deepmind Researchers Introduce â€˜Transframerâ€™: 
A General-Purpose AI Framework For Image Modelling And Computer Vision Tasks Based On Probabilistic Frame Prediction
Paper: https://arxiv.org/pdf/2203.09494.pdf

## Researchers at Apple Develop Texturify: A GAN-based Approach for Generating Textures on 3D Shape Surfaces
Paper: https://nihalsid.github.io/texturify/static/Texturify.pdf
Project: https://nihalsid.github.io/texturify/

## Latest Computer Vision Research At Microsoft Explains How This Proposed Method Adapts The Pretrained Language Image Models To Video Recognition
Paper Summary: https://www.marktechpost.com/.../latest-computer-vision.../
Paper: https://arxiv.org/pdf/2208.02816v1.pdf
Github: https://github.com/microsoft/VideoX/tree/master/X-CLIP

## Salesforce AI Propose A Novel Framework That Trains An Open Vocabulary Object Detector With Pseudo Bounding-Box Labels Generated From Large-Scale Image-Caption Pairs
Paper: https://arxiv.org/pdf/2111.09452.pdf
GItHub link: https://arxiv.org/pdf/2111.09452.pdf

## Researchers Present A Survey Report on Using 100+ Transformer-based Methods in Computer Vision for Different 3D Vision Tasks
Paper:  https://arxiv.org/pdf/2208.04309v1.pdf
Github link: https://github.com/lahoud/3d-vision-transformers

## Researchers Propose Easter2.0, a Novel Convolutional Neural Network CNN-Based Architecture for the Task of End-to-End Handwritten Text Line Recognition that Utilizes Only 1D Convolutions
Paper Summary: https://www.marktechpost.com/.../researchers-propose.../
Paper: https://arxiv.org/pdf/2205.14879v1.pdf
Github link: https://github.com/kartikgill/easter2

## Researchers at Meta AI Develop Multiface: A Dataset for Neural Face Rendering
Paper: https://arxiv.org/pdf/2207.11243v1.pdf
Github link: https://github.com/facebookresearch/multiface

## Research From China Propose a Novel Context-Aware Vision Transformer (CA-ViT) For Ghost-Free High Dynamic Range Imaging
They propose a novel vision transformer termed CA-ViT that can fully utilize both global and local picture context dependencies while outperforming its predecessors by a wide margin.
They introduce a unique HDR-Transformer that can reduce processing costs, ghosting artifacts, and recreating high-quality HDR photos. This is the first Transformer-based HDR de-ghosting framework to be developed. 
They undertake in-depth tests on three sample benchmark HDR datasets to compare HDR-performance Transformers to current state-of-the-art techniques.
Paper: https://arxiv.org/pdf/2208.05114v1.pdf
Github link: https://github.com/megvii-research/HDR-Transformer

## DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation (CVPR 2022) 
Abstract: Recently, GAN inversion methods combined with Contrastive Language-Image Pretraining (CLIP) enables zero-shot image manipulation guided by text prompts. However, their applications to diverse real images are still difficult due to the limited GAN inversion capability. Specifically, these approaches often have difficulties in reconstructing images with novel poses, views, and highly variable contents compared to the training data, altering object identity, or producing unwanted image artifacts. To mitigate these problems and enable faithful manipulation of real images, we propose a novel method, dubbed DiffusionCLIP, that performs text-driven image manipulation using diffusion models. Based on full inversion capability and high-quality image generation power of recent diffusion models, our method performs zero-shot image manipulation successfully even between unseen domains and takes another step towards general application by manipulating images from a widely varying ImageNet dataset. Furthermore, we propose a novel noise combination method that allows straightforward multi-attribute manipulation. Extensive experiments and human evaluation confirmed robust and superior manipulation performance of our methods compared to the existing baselines. 

Source: https://openaccess.thecvf.com/.../Kim_DiffusionCLIP_Text...
Slides: https://www.slideshare.net/.../diffusionclip-textguided...
Video: https://youtu.be/YVCtaXw6fw8
Code: https://github.com/gwang-kim/DiffusionCLIP.git

## NVIDIA AI Researchers Propose â€˜MinVIS,â€™ 
A Minimal Video Instance Segmentation (VIS) Framework That Achieves SOTA Performance With Neither Video-Based Architectures Nor Training Procedures
Paper: https://arxiv.org/pdf/2208.02245v1.pdf
Github link: https://github.com/nvlabs/minvis

## Researchers from China Propose DAT: a Deformable Vision Transformer to Compute Self-Attention in a Data-Aware Fashion
Paper: https://openaccess.thecvf.com/.../Xia_Vision_Transformer...
Github: https://github.com/LeapLabTHU/DAT

## Researchers From CMU And Stanford Develop OBJECTFOLDER 2.0: A Multisensory Object Dataset For Sim2Real Transfer
Paper: https://arxiv.org/pdf/2204.02389.pdf
Github: https://github.com/rhgao/ObjectFolder
Project: https://ai.stanford.edu/~rhgao/objectfolder2.0/

## image classification on small-datasets in Pytorch
https://github.com/Harry-KIT/Image-Classification-on-small-datasets-in-Pytorch


## Alibaba AI Research Team Introduces â€˜DCT-Netâ€™
A Novel Image Translation Architecture For Few-Shot Portrait Stylization
Paper: https://arxiv.org/pdf/2207.02426v1.pdf
Project: https://menyifang.github.io/projects/DCTNet/DCTNet.html
Github link: https://github.com/menyifang/dct-net

## NeurIPS2021 spotlight work PCAN-â€œPrototypical Cross-Attention Networks for Multiple Object Tracking and Segmentationâ€.
- PCAN uses test-time prototypes to memorize instance appearance and achieve impressive seg tracking accuracy on YT-VIS and BDD100K.
- Project website: https://vis.xyz/pub/pcan/
- Code: https://github.com/SysCV/pcan
- Paper: https://arxiv.org/abs/2106.11958

## yolo v7
YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors
ê³µí—Œì(ì €ì): Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao
ë…¼ë¬¸: https://arxiv.org/abs/2207.02696
GitHub: https://github.com/wongkinyiu/yolov7

ì´ˆë¡: YOLOv7ì€ 5FPS~160FPS ë²”ìœ„ì—ì„œ ì†ë„ì™€ ì •í™•ë„ ëª¨ë‘ì—ì„œ ì•Œë ¤ì§„ ëª¨ë“  ê°ì²´ ê°ì§€ê¸°ë¥¼ ëŠ¥ê°€í•˜ë©° GPU V100ì—ì„œ 30FPS ì´ìƒì˜ ì•Œë ¤ì§„ ëª¨ë“  ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ê¸° ì¤‘ ê°€ì¥ ë†’ì€ ì •í™•ë„ 56.8% APë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. YOLOv7-E6 ë¬¼ì²´ ê°ì§€ê¸°(56 FPS V100, 55.9% AP)ëŠ” ë³€ì••ê¸° ê¸°ë°˜ ê°ì§€ê¸°ì¸ SWIN-L Cascade-Mask R-CNN(9.2 FPS A100, 53.9% AP)ë³´ë‹¤ ì†ë„ 509%, ì •í™•ë„ 2%, ì»¨ë³¼ë£¨ì…˜ ê¸°ë°˜ ê²€ì¶œê¸° ConvNeXt-XL Cascade-Mask R-CNN(8.6 FPS A100, 55.2% AP)ì€ ì†ë„ 551%, AP ì •í™•ë„ 0.7% í–¥ìƒ ë° YOLOv7 ì„±ëŠ¥ í–¥ìƒ: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B ë° ê¸°íƒ€ ì—¬ëŸ¬ ë¬¼ì²´ ê°ì§€ê¸°ì˜ ì†ë„ì™€ ì •í™•ë„. ë˜í•œ ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ë‚˜ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì²˜ìŒë¶€í„° MS COCO ë°ì´í„° ì„¸íŠ¸ì—ì„œë§Œ YOLOv7ì„ í›ˆë ¨í•©ë‹ˆë‹¤.

## Diffusion Model
Diffusion ì…ë¬¸
https://lilianweng.github.io/.../2021-07-11-diffusion.../
https://youtu.be/d_x92vpIWFM
================================
Diffusion Models Beat GANs on Image Synthesis
í™•ì‚° ëª¨ë¸ì— classifierë¥¼ ì¶”ê°€í•´ ë‹¤ì–‘ì„±-í’ˆì§ˆ trade-offë¥¼ ë‹¬ì„±
Classifier-Free Diffusion Guidance
Classifier ì—†ì´ ë‹¨ì¼ í™•ì‚° ëª¨ë¸ë¡œ ê°™ì€ ëª©í‘œ ë‹¬ì„±
Cascaded Diffusion Models for High Fidelity Image Generation
ì—¬ëŸ¬ í•´ìƒë„ì˜ í™•ì‚° ëª¨ë¸ì´ í¬í•¨ëœ ê³„ì¸µì  cascading pipelineìœ¼ë¡œ ì´ì „ë³´ë‹¤ ë” ë†’ì€ í•´ìƒë„ì—ì„œ ê³ í’ˆì§ˆ ìƒ˜í”Œ ìƒì„±
Pretraining is All You Need for Image-to-Image Translation (PITI)
ì‚¬ì „ í›ˆë ¨ëœ í™•ì‚° ëª¨ë¸ì„ ì´ìš©í•´ ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì‘ì—… ì…ë ¥ ì¡°ê±´(e.g. semantic map + text)ì—ì„œ Image-to-Image translation ìˆ˜í–‰

## akka-stream
ë‹¤ì´ë‚˜ë¯¹ ë°°ì¹˜ë¥¼ êµ¬í˜„í•˜ê³  ìˆê³  ì¶©ë¶„íˆ ì‘ì€ ëª¨ë¸ì´ë¼ë©´ 10000 ~ 20000  requests / sec ìˆ˜ì¤€ì˜ ì‘ë‹µ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
êµ¬í˜„ì— ì‚¬ìš©ëœ akkaëŠ” í”„ë ˆì„ì›Œí¬ê°€ ì•„ë‹Œ ê³ ë„ì˜ ë™ì‹œì„±, ë³‘ë ¬ì„±, ë¶„ì‚°ì„±ì„ ê°€ì§€ê³  ìˆëŠ” ë©”ì„¸ì§€ ê¸°ë°˜ ì–´í”Œë ˆì¼€ì´ì…˜ êµ¬ì¶• íˆ´í‚·ìœ¼ë¡œ ê°„ì£¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶©ë¶„íˆ ìƒì‚°ì„±ì´ ìˆëŠ” ì–¸ì–´ë¥¼ ë² ì´ìŠ¤ë¡œ í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì§ì ‘ ì„œë¹™ ë°ëª¬ì—ì„œ monolithic í•œ êµ¬ì¡°ë¡œ ë¹„ì§€ë‹ˆìŠ¤ ì½”ë“œë¥¼ ë‚´ì¬í™” í•˜ëŠ”ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. 
ì˜ˆì œì˜ ì½”ë“œëŸ‰ì´ ì ê³  ì¶”ìƒí™”ê°€ ê±°ì˜ ì—†ëŠ” naiveí•œ êµ¬í˜„ì´ê¸° ë•Œë¬¸ì— ë™ì‘ì— ê´€ë ¨í•œ ê±°ì˜ ëŒ€ë¶€ë¶„ì˜ ìš”ì†Œë¥¼ ë¸”ë™ë°•ìŠ¤ ì—†ì´ í™•ì¸í•˜ê³  ë™ì‹œì— í™˜ê²½ íŠœë‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
ì‹¤ì œ ì˜ˆì œì˜ ì‚¬ìš©ì„±ì€ ì›¹ê³¼ ìƒí˜¸ ì‘ìš©ì„ í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ ë³´ë‹¤ëŠ” ê²€ìƒ‰, ì¶”ì²œ, ëŒ€í™” ì‹œìŠ¤í…œë“± ë‹¤ìˆ˜ì˜ ëª¨ë¸ì„ ì»¨íŠ¸ë¡¤í•˜ëŠ” ê¸°ë°˜ í”Œë«í¼ ì‹œìŠ¤í…œì— ì í•©í•©ë‹ˆë‹¤.
https://github.com/go-noah/akka-dynamic-batch-serving/tree/main/akka-dynamic-batch-onnx-gpu-bert
https://github.com/go-noah/akka-dynamic-batch-serving/tree/main/akka-dynamic-batch-tensorflow-gpu-bert

## AI2â€™s PRIOR Team Introduces Unified-IO:
The First Neural Model To Execute Various AI Tasks Spanning Classical Computer Vision, Image Synthesis, Vision-and-Language, and Natural Language Processing NLP
Quick Read: https://www.marktechpost.com/.../ai2s-prior-team.../
Demo: https://unified-io.allenai.org/

## AI Researchers From China Introduce a New Vision GNN (ViG) Architecture to Extract Graph Level Feature for Visual Tasks
Paper: https://arxiv.org/pdf/2206.00272v1.pdf
Github: https://github.com/huawei-noah/Efficient-AI-Backbones

## Researchers at Stanford have developed an Artificial Intelligence (AI) model,
EG3D, that can generate random images of faces and other objects with high resolution together with underlying geometric structures
[Quick Read: https://www.marktechpost.com/2022/07/04/researchers-at-stanford-have-developed-an-artificial-intelligence-ai-model-eg3d-that-can-generate-random-images-of-faces-and-other-objects-with-high-resolution-together-with-underlying-geometric-s/?fbclid=IwAR3s59QXgJsrYG0uIiDTIIQl784LAUe48NrfJ6Vk6kTVVOjjHAzod7DRAEc
Paper: https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.pdf?fbclid=IwAR2oL0AvGr_0uBamWB67pHl_KNSAuhxN2VKpyzLcpGiIBVIyJiy7211j_8M
Github: https://github.com/NVlabs/eg3d

## Stanford and TRI AI Researchers Propose the Atemporal Probe (ATP), A New ML Model For Video-Language Analysis
Quick Read: https://www.marktechpost.com/.../stanford-and-tri-ai.../
Paper: https://arxiv.org/pdf/2206.01720.pdf
Project: https://stanfordvl.github.io/atp-revisit-video-lang/

## A New Technique to Train Diffusion Model in Latent Space Using Limited Computational Resources While Maintaining High-Resolution Quality
Paper Summary: [https://www.marktechpost.com/.../a-new-technique-to.../
](https://www.marktechpost.com/2022/06/28/a-new-technique-to-train-diffusion-model-in-latent-space-using-limited-computational-resources-while-maintaining-high-resolution-quality/?fbclid=IwAR1n777ssnw4C5oQ-TR8OcWug4jwXZ3uK-3LnCuFME2IgTi6VkqhoALBD_Y)
Paper: https://arxiv.org/pdf/2112.10752.pdf
Github: https://github.com/CompVis/latent-diffusion

## MPViT
ArxivğŸ‘‰ https://arxiv.org/abs/2112.11010
CodeğŸ‘‰ https://github.com/youngwanLEE/MPViT

## DN-DETR: Accelerate DETR Training by Introducing Query DeNoising
## DAB-DETR : Dynamic Anchor Boxes are Better Queries for DETR 

## Dynamic Gender Classification
code : https://github.com/CChenLi/Dynamic_Gender_Classification

## NVIDIAì˜ Efficient Geometry-aware 3D Generative Adversarial Networks(EG3D)
code: https://github.com/NVlabs/eg3d
paper: https://arxiv.org/abs/2112.07945
page: https://nvlabs.github.io/eg3d/
youtube: https://youtu.be/cXxEwI7QbKg

## Salesforce AI Research has proposed a new video-and-language representation learning framework called ALPRO. 
This framework can be used for pre-training models to achieve state-of-the-art performance on tasks such as video-text retrieval and question answering.
Quick Read: https://www.marktechpost.com/.../salesforce-ai-research.../
Paper: https://arxiv.org/pdf/2112.09583.pdf
Github: https://github.com/salesforce/alpro

## Warehouse Apparel Detection using YOLOv5 end to end project
Kindly Like and Share and subscribe to the YT channel !!
Project Code: https://github.com/Ashishkumar-hub/Warehouse-Apparel-Detection-using...

## Researchers From MIT and Cornell Develop STEGO 
(Self-Supervised Transformer With Energy-Based Graph Optimization): A Novel AI Framework That Distills Unsupervised Features Into High-Quality Discrete Semantic Labels
Paper: https://arxiv.org/pdf/2203.08414.pdf
Github: https://github.com/mhamilton723/STEGO

## UTokyo Researchers Introduce 
A Novel Synthetic Training Data Called Self-Blended Images (SBIs) To Detect Deepfakes
Paper: https://arxiv.org/pdf/2204.08376.pdf
Github: https://github.com/mapooon/SelfBlendedImages

## Meta AI Introduces â€˜Make-A-Sceneâ€™: 
A Deep Generative Technique Based On An Autoregressive Transformer For Text-To-Image Synthesis With Human Priors
Paper Summary: https://www.marktechpost.com/.../meta-ai-introduces-make.../
Paper: https://arxiv.org/pdf/2203.13131v1.pdf

## Bytedance Researchers Propose CLIP-GEN: 
A New Self-Supervised Deep Learning Generative Approach Based On CLIP And VQ-GAN To Generate Reliable Samples From Text Prompts
Quick Read: https://www.marktechpost.com/.../bytedance-researchers.../
Paper: https://arxiv.org/pdf/2203.00386v1.pdf

## Warehouse Apparel Detection using YOLOv5 end to end project
Kindly Like and Share and subscribe to the YT channel !!
Project Code: https://github.com/.../Warehouse-Apparel-Detection-using...

## Learning to Estimate Robust 3D Human Mesh from In-the-Wild Crowded Scenes / 3DCrowdNet
https://arxiv.org/abs/2104.07300
github: https://github.com/hongsukchoi/3DCrowdNet_RELEASE

## Google AI Researchers Propose SAVi++: 
An Object-Centric Video Model Trained To Predict Depth Signals From A Slot-Based Video Representation
Quick Read: https://www.marktechpost.com/.../google-ai-researchers.../
Paper: https://arxiv.org/pdf/2206.07764.pdf
Project: https://slot-attention-video.github.io/savi++/

## Meta AI Research Proposes â€˜OMNIVOREâ€™: 
A Single Vision (Computer Vision) Model For Many Different Visual Modalities
Quick Read: https://www.marktechpost.com/2022/01/30/meta-ai-research-proposes-omnivore-a-single-vision-computer-vision-model-for-many-different-visual-modalities/
Paper: https://arxiv.org/abs/2201.08377
Github: https://github.com/facebookresearch/omnivore

## ì ¯ìŠ¨ë‚˜ë…¸ë¥¼ ì´ìš©í•´ì„œ ë…¹ìƒ‰ ì´êµ¬ì•„ë‚˜ì˜ ì™¸ë˜ ì¢…ì˜ ì‹¤ì‹œê°„ íƒì§€ ë° ëª¨ë‹ˆí„°ë§
ê³µí—Œì(ì €ì): NVIDIA(íƒ€ì´ì™„)
GitHub: https://github.com/.../Iguana-detection-on-Nvidia-Jetson...
ë¸”ë¡œê·¸ ë§í¬: https://blogs.nvidia.com.tw/.../green-iguana-detection.../
'
