## Accelerating physics simulators for Robotics Reinforcement Learning - Erwin Coumans @ ICRA22 | 2/8
Pybulletì„ ë§Œë“œì‹  ë¶„ìœ¼ë¡œë„ ìœ ëª…í•œ Erwin Coumansë‹˜ì˜ ICRA 22 Tutorial:
ê°•í™”í•™ìŠµì„ ë¡œë´‡ì— ì ìš©í•  ë•Œ ê°€ì¥ ë§ì´ ê³ ë¯¼í•˜ëŠ” ì‹œë®¬ë ˆì´í„°ì— ê´€í•œ ì¢‹ì€ ë°œí‘œì…ë‹ˆë‹¤. 
Website : https://araffin.github.io/tools-for-robotic-rl-icra2022/
Slides : https://drive.google.com/.../19ImRxp8SfbTLtMDdFwYY.../view
Youtube : https://youtu.be/WOwLquiFbPE## Interested in multiple object tracking and segmentation and self-driving?

## Researchers Propose Easter2.0, a Novel Convolutional Neural Network CNN-Based Architecture for the Task of End-to-End Handwritten Text Line Recognition that Utilizes Only 1D Convolutions
Paper Summary: https://www.marktechpost.com/.../researchers-propose.../
Paper: https://arxiv.org/pdf/2205.14879v1.pdf
Github link: https://github.com/kartikgill/easter2

## Researchers at Meta AI Develop Multiface: A Dataset for Neural Face Rendering
Quick Read: https://www.marktechpost.com/.../researchers-at-meta-ai.../
Paper: https://arxiv.org/pdf/2207.11243v1.pdf
Github link: https://github.com/facebookresearch/multiface

## DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation (CVPR 2022) 
Abstract: Recently, GAN inversion methods combined with Contrastive Language-Image Pretraining (CLIP) enables zero-shot image manipulation guided by text prompts. However, their applications to diverse real images are still difficult due to the limited GAN inversion capability. Specifically, these approaches often have difficulties in reconstructing images with novel poses, views, and highly variable contents compared to the training data, altering object identity, or producing unwanted image artifacts. To mitigate these problems and enable faithful manipulation of real images, we propose a novel method, dubbed DiffusionCLIP, that performs text-driven image manipulation using diffusion models. Based on full inversion capability and high-quality image generation power of recent diffusion models, our method performs zero-shot image manipulation successfully even between unseen domains and takes another step towards general application by manipulating images from a widely varying ImageNet dataset. Furthermore, we propose a novel noise combination method that allows straightforward multi-attribute manipulation. Extensive experiments and human evaluation confirmed robust and superior manipulation performance of our methods compared to the existing baselines. 
Source: https://openaccess.thecvf.com/.../Kim_DiffusionCLIP_Text...
Slides: https://www.slideshare.net/.../diffusionclip-textguided...
Video: https://youtu.be/YVCtaXw6fw8
Code: https://github.com/gwang-kim/DiffusionCLIP.git

## Researchers from China Propose DAT: a Deformable Vision Transformer to Compute Self-Attention in a Data-Aware Fashion
Paper Summary: https://www.marktechpost.com/.../researchers-from-china.../
Paper: https://openaccess.thecvf.com/.../Xia_Vision_Transformer...
Github: https://github.com/LeapLabTHU/DAT

## Researchers From CMU And Stanford Develop OBJECTFOLDER 2.0: A Multisensory Object Dataset For Sim2Real Transfer
Quick Read: https://www.marktechpost.com/.../researchers-from-cmu.../
Paper: https://arxiv.org/pdf/2204.02389.pdf
Github: https://github.com/rhgao/ObjectFolder
Project: https://ai.stanford.edu/~rhgao/objectfolder2.0/

## image classification on small-datasets in Pytorch
https://github.com/Harry-KIT/Image-Classification-on-small-datasets-in-Pytorch


## Alibaba AI Research Team Introduces â€˜DCT-Netâ€™
A Novel Image Translation Architecture For Few-Shot Portrait Stylization
Paper Summary: https://www.marktechpost.com/.../alibaba-ai-research.../
Paper: https://arxiv.org/pdf/2207.02426v1.pdf
Project: https://menyifang.github.io/projects/DCTNet/DCTNet.html
Github link: https://github.com/menyifang/dct-net

## NeurIPS2021 spotlight work PCAN-â€œPrototypical Cross-Attention Networks for Multiple Object Tracking and Segmentationâ€.
- PCAN uses test-time prototypes to memorize instance appearance and achieve impressive seg tracking accuracy on YT-VIS and BDD100K.
- Project website: https://vis.xyz/pub/pcan/
- Code: https://github.com/SysCV/pcan
- Paper: https://arxiv.org/abs/2106.11958

## yolo v7
YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors
ê³µí—Œì(ì €ì): Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao
ë…¼ë¬¸: https://arxiv.org/abs/2207.02696
GitHub: https://github.com/wongkinyiu/yolov7

ì´ˆë¡: YOLOv7ì€ 5FPS~160FPS ë²”ìœ„ì—ì„œ ì†ë„ì™€ ì •í™•ë„ ëª¨ë‘ì—ì„œ ì•Œë ¤ì§„ ëª¨ë“  ê°ì²´ ê°ì§€ê¸°ë¥¼ ëŠ¥ê°€í•˜ë©° GPU V100ì—ì„œ 30FPS ì´ìƒì˜ ì•Œë ¤ì§„ ëª¨ë“  ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ê¸° ì¤‘ ê°€ì¥ ë†’ì€ ì •í™•ë„ 56.8% APë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. YOLOv7-E6 ë¬¼ì²´ ê°ì§€ê¸°(56 FPS V100, 55.9% AP)ëŠ” ë³€ì••ê¸° ê¸°ë°˜ ê°ì§€ê¸°ì¸ SWIN-L Cascade-Mask R-CNN(9.2 FPS A100, 53.9% AP)ë³´ë‹¤ ì†ë„ 509%, ì •í™•ë„ 2%, ì»¨ë³¼ë£¨ì…˜ ê¸°ë°˜ ê²€ì¶œê¸° ConvNeXt-XL Cascade-Mask R-CNN(8.6 FPS A100, 55.2% AP)ì€ ì†ë„ 551%, AP ì •í™•ë„ 0.7% í–¥ìƒ ë° YOLOv7 ì„±ëŠ¥ í–¥ìƒ: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B ë° ê¸°íƒ€ ì—¬ëŸ¬ ë¬¼ì²´ ê°ì§€ê¸°ì˜ ì†ë„ì™€ ì •í™•ë„. ë˜í•œ ë‹¤ë¥¸ ë°ì´í„° ì„¸íŠ¸ë‚˜ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì²˜ìŒë¶€í„° MS COCO ë°ì´í„° ì„¸íŠ¸ì—ì„œë§Œ YOLOv7ì„ í›ˆë ¨í•©ë‹ˆë‹¤.

## akka-stream
ë‹¤ì´ë‚˜ë¯¹ ë°°ì¹˜ë¥¼ êµ¬í˜„í•˜ê³  ìˆê³  ì¶©ë¶„íˆ ì‘ì€ ëª¨ë¸ì´ë¼ë©´ 10000 ~ 20000  requests / sec ìˆ˜ì¤€ì˜ ì‘ë‹µ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
êµ¬í˜„ì— ì‚¬ìš©ëœ akkaëŠ” í”„ë ˆì„ì›Œí¬ê°€ ì•„ë‹Œ ê³ ë„ì˜ ë™ì‹œì„±, ë³‘ë ¬ì„±, ë¶„ì‚°ì„±ì„ ê°€ì§€ê³  ìˆëŠ” ë©”ì„¸ì§€ ê¸°ë°˜ ì–´í”Œë ˆì¼€ì´ì…˜ êµ¬ì¶• íˆ´í‚·ìœ¼ë¡œ ê°„ì£¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì¶©ë¶„íˆ ìƒì‚°ì„±ì´ ìˆëŠ” ì–¸ì–´ë¥¼ ë² ì´ìŠ¤ë¡œ í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì§ì ‘ ì„œë¹™ ë°ëª¬ì—ì„œ monolithic í•œ êµ¬ì¡°ë¡œ ë¹„ì§€ë‹ˆìŠ¤ ì½”ë“œë¥¼ ë‚´ì¬í™” í•˜ëŠ”ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤. 
ì˜ˆì œì˜ ì½”ë“œëŸ‰ì´ ì ê³  ì¶”ìƒí™”ê°€ ê±°ì˜ ì—†ëŠ” naiveí•œ êµ¬í˜„ì´ê¸° ë•Œë¬¸ì— ë™ì‘ì— ê´€ë ¨í•œ ê±°ì˜ ëŒ€ë¶€ë¶„ì˜ ìš”ì†Œë¥¼ ë¸”ë™ë°•ìŠ¤ ì—†ì´ í™•ì¸í•˜ê³  ë™ì‹œì— í™˜ê²½ íŠœë‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
ì‹¤ì œ ì˜ˆì œì˜ ì‚¬ìš©ì„±ì€ ì›¹ê³¼ ìƒí˜¸ ì‘ìš©ì„ í•˜ëŠ” ì–´í”Œë¦¬ì¼€ì´ì…˜ ë³´ë‹¤ëŠ” ê²€ìƒ‰, ì¶”ì²œ, ëŒ€í™” ì‹œìŠ¤í…œë“± ë‹¤ìˆ˜ì˜ ëª¨ë¸ì„ ì»¨íŠ¸ë¡¤í•˜ëŠ” ê¸°ë°˜ í”Œë«í¼ ì‹œìŠ¤í…œì— ì í•©í•©ë‹ˆë‹¤.
https://github.com/go-noah/akka-dynamic-batch-serving/tree/main/akka-dynamic-batch-onnx-gpu-bert
https://github.com/go-noah/akka-dynamic-batch-serving/tree/main/akka-dynamic-batch-tensorflow-gpu-bert

## AI2â€™s PRIOR Team Introduces Unified-IO:
The First Neural Model To Execute Various AI Tasks Spanning Classical Computer Vision, Image Synthesis, Vision-and-Language, and Natural Language Processing NLP
Quick Read: https://www.marktechpost.com/.../ai2s-prior-team.../
Demo: https://unified-io.allenai.org/

## AI Researchers From China Introduce a New Vision GNN (ViG) Architecture to Extract Graph Level Feature for Visual Tasks
Paper Summary: https://www.marktechpost.com/.../ai-researchers-from.../
Paper: https://arxiv.org/pdf/2206.00272v1.pdf
Github: https://github.com/huawei-noah/Efficient-AI-Backbones

## Researchers at Stanford have developed an Artificial Intelligence (AI) model,
EG3D, that can generate random images of faces and other objects with high resolution together with underlying geometric structures
[Quick Read: https://www.marktechpost.com/2022/07/04/researchers-at-stanford-have-developed-an-artificial-intelligence-ai-model-eg3d-that-can-generate-random-images-of-faces-and-other-objects-with-high-resolution-together-with-underlying-geometric-s/?fbclid=IwAR3s59QXgJsrYG0uIiDTIIQl784LAUe48NrfJ6Vk6kTVVOjjHAzod7DRAEc
Paper: https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.pdf?fbclid=IwAR2oL0AvGr_0uBamWB67pHl_KNSAuhxN2VKpyzLcpGiIBVIyJiy7211j_8M
Github: https://github.com/NVlabs/eg3d

## Stanford and TRI AI Researchers Propose the Atemporal Probe (ATP), A New ML Model For Video-Language Analysis
Quick Read: https://www.marktechpost.com/.../stanford-and-tri-ai.../
Paper: https://arxiv.org/pdf/2206.01720.pdf
Project: https://stanfordvl.github.io/atp-revisit-video-lang/

## A New Technique to Train Diffusion Model in Latent Space Using Limited Computational Resources While Maintaining High-Resolution Quality
Paper Summary: [https://www.marktechpost.com/.../a-new-technique-to.../
](https://www.marktechpost.com/2022/06/28/a-new-technique-to-train-diffusion-model-in-latent-space-using-limited-computational-resources-while-maintaining-high-resolution-quality/?fbclid=IwAR1n777ssnw4C5oQ-TR8OcWug4jwXZ3uK-3LnCuFME2IgTi6VkqhoALBD_Y)
Paper: https://arxiv.org/pdf/2112.10752.pdf
Github: https://github.com/CompVis/latent-diffusion

## MPViT
ArxivğŸ‘‰ https://arxiv.org/abs/2112.11010
CodeğŸ‘‰ https://github.com/youngwanLEE/MPViT

## DN-DETR: Accelerate DETR Training by Introducing Query DeNoising
## DAB-DETR : Dynamic Anchor Boxes are Better Queries for DETR 

## Dynamic Gender Classification
code : https://github.com/CChenLi/Dynamic_Gender_Classification

## NVIDIAì˜ Efficient Geometry-aware 3D Generative Adversarial Networks(EG3D)
code: https://github.com/NVlabs/eg3d
paper: https://arxiv.org/abs/2112.07945
page: https://nvlabs.github.io/eg3d/
youtube: https://youtu.be/cXxEwI7QbKg

## Salesforce AI Research has proposed a new video-and-language representation learning framework called ALPRO. 
This framework can be used for pre-training models to achieve state-of-the-art performance on tasks such as video-text retrieval and question answering.
Quick Read: https://www.marktechpost.com/.../salesforce-ai-research.../
Paper: https://arxiv.org/pdf/2112.09583.pdf
Github: https://github.com/salesforce/alpro

## Warehouse Apparel Detection using YOLOv5 end to end project
Kindly Like and Share and subscribe to the YT channel !!
Project Code: https://github.com/Ashishkumar-hub/Warehouse-Apparel-Detection-using...

## Researchers From MIT and Cornell Develop STEGO 
(Self-Supervised Transformer With Energy-Based Graph Optimization): A Novel AI Framework That Distills Unsupervised Features Into High-Quality Discrete Semantic Labels
Quick Read: https://www.marktechpost.com/.../researchers-from-mit.../
Paper: https://arxiv.org/pdf/2203.08414.pdf
Github: https://github.com/mhamilton723/STEGO

## UTokyo Researchers Introduce 
A Novel Synthetic Training Data Called Self-Blended Images (SBIs) To Detect Deepfakes
Quick Read: https://www.marktechpost.com/.../utokyo-researchers.../
Paper: https://arxiv.org/pdf/2204.08376.pdf
Github: https://github.com/mapooon/SelfBlendedImages

## Meta AI Introduces â€˜Make-A-Sceneâ€™: 
A Deep Generative Technique Based On An Autoregressive Transformer For Text-To-Image Synthesis With Human Priors
Paper Summary: https://www.marktechpost.com/.../meta-ai-introduces-make.../
Paper: https://arxiv.org/pdf/2203.13131v1.pdf

## Bytedance Researchers Propose CLIP-GEN: 
A New Self-Supervised Deep Learning Generative Approach Based On CLIP And VQ-GAN To Generate Reliable Samples From Text Prompts
Quick Read: https://www.marktechpost.com/.../bytedance-researchers.../
Paper: https://arxiv.org/pdf/2203.00386v1.pdf

## Warehouse Apparel Detection using YOLOv5 end to end project
Kindly Like and Share and subscribe to the YT channel !!
Project Code: https://github.com/.../Warehouse-Apparel-Detection-using...

## Learning to Estimate Robust 3D Human Mesh from In-the-Wild Crowded Scenes / 3DCrowdNet
https://arxiv.org/abs/2104.07300
github: https://github.com/hongsukchoi/3DCrowdNet_RELEASE

## Google AI Researchers Propose SAVi++: 
An Object-Centric Video Model Trained To Predict Depth Signals From A Slot-Based Video Representation
Quick Read: https://www.marktechpost.com/.../google-ai-researchers.../
Paper: https://arxiv.org/pdf/2206.07764.pdf
Project: https://slot-attention-video.github.io/savi++/

## Meta AI Research Proposes â€˜OMNIVOREâ€™: 
A Single Vision (Computer Vision) Model For Many Different Visual Modalities
Quick Read: https://www.marktechpost.com/2022/01/30/meta-ai-research-proposes-omnivore-a-single-vision-computer-vision-model-for-many-different-visual-modalities/
Paper: https://arxiv.org/abs/2201.08377
Github: https://github.com/facebookresearch/omnivore

## ì ¯ìŠ¨ë‚˜ë…¸ë¥¼ ì´ìš©í•´ì„œ ë…¹ìƒ‰ ì´êµ¬ì•„ë‚˜ì˜ ì™¸ë˜ ì¢…ì˜ ì‹¤ì‹œê°„ íƒì§€ ë° ëª¨ë‹ˆí„°ë§
ê³µí—Œì(ì €ì): NVIDIA(íƒ€ì´ì™„)
GitHub: https://github.com/.../Iguana-detection-on-Nvidia-Jetson...
ë¸”ë¡œê·¸ ë§í¬: https://blogs.nvidia.com.tw/.../green-iguana-detection.../
